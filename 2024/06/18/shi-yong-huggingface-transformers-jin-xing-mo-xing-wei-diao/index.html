<!DOCTYPE HTML><html lang="zh-CN"><head><link href="https://gcore.jsdelivr.net/npm/hexo-tag-common@0.2.0/css/index.css" rel="stylesheet"><meta charset="utf-8"><meta name="keywords" content="使用HuggingFace Transformers进行NLP模型微调, ellendan"><meta name="description" content="关注 AI 领域信息的小伙伴们，基本对 HuggingFace Hub 早已耳熟能详。
简单来说，HuggingFace Hub 是一个集成平台，汇集了海量的预训练模型和数据集。
通过这个平台，用户可以轻松浏览、下载和分享模型和数据集，大大"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="referrer" content="no-referrer-when-downgrade"><title>使用HuggingFace Transformers进行NLP模型微调 | ellendan</title><link rel="icon" type="image/png" href="/favicon.png"><link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css"><link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/css/matery.css"><link rel="stylesheet" type="text/css" href="/css/my.css"><link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload='"all"!=media&&(media="all")'><link rel="stylesheet" href="/libs/tocbot/tocbot.css"><link rel="stylesheet" href="/css/post.css"><script src="/libs/jquery/jquery-3.6.0.min.js"></script><link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/KaTeX/0.12.0/katex.min.css"><meta name="generator" content="Hexo 6.3.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style><link rel="alternate" href="/atom.xml" title="ellendan" type="application/atom+xml"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="/medias/loading-1.gif" data-original="/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">ellendan</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-book" style="zoom:.6"></i> <span>知识库</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/book-xp/"><i class="fas fa-keyboard" style="margin-top:-20px;zoom:.6"></i> <span>XP2.0</span></a></li></ul></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/graph" class="waves-effect waves-light"><i class="fa fa-graduation-cap" style="zoom:.6"></i> <span>知识图谱</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li><li><a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式"><i id="sum-moon-icon" class="fas fa-sun" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/medias/loading-1.gif" data-original="/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">ellendan</div><div class="logo-desc">上善若水。水利万物而不争，处众人之所恶，故几于道。居善地，心善渊，与善仁，言善信，政善治，事善能，动善时。夫唯不争，故无尤。</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-book"></i> 知识库 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/book-xp/" style="margin-left:75px"><i class="fa fas fa-keyboard" style="position:absolute;left:50px"></i> <span>XP2.0</span></a></li></ul></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/graph" class="waves-effect waves-light"><i class="fa-fw fa fa-graduation-cap"></i> 知识图谱</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li><div class="divider"></div></li><li><a href="https://github.com/ellendan000" class="waves-effect waves-light" target="_blank"><i class="fab fa-github-square fa-fw"></i>Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/ellendan000" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><script src="/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(/medias/featureimages/14.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">使用HuggingFace Transformers进行NLP模型微调</h1></div></div></div></div></div><main class="post-container content"><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/ML/"><span class="chip bg-color">ML</span> </a><a href="/tags/AI/"><span class="chip bg-color">AI</span> </a><a href="/tags/HuggingFace/"><span class="chip bg-color">HuggingFace</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/AI/" class="post-category">AI</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2024-06-18</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 3.3k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 13 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><link rel="stylesheet" href="/libs/prism/prism.min.css"><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre-wrap!important}</style><div class="card-content article-card-content"><div id="articleContent"><p>关注 AI 领域信息的小伙伴们，基本对 HuggingFace Hub 早已耳熟能详。<br>简单来说，HuggingFace Hub 是一个集成平台，汇集了海量的预训练模型和数据集。<br>通过这个平台，用户可以轻松浏览、下载和分享模型和数据集，大大加速了机器学习的研究和应用，因此，HuggingFace Hub 逐渐成为一个机器学习领域不可或缺的开源资源中心。</p><p>经常使用 Github 的程序员小伙伴们，可能将其类比成 Github。<br>但其实对于 HuggingFace 生态来说，远不止 Hub 这么简单。除了 HuggingFace Hub 以外，HuggingFace 还提供了大量的开源库，其中就包括闻名的 Transformers、Datasets、Tokenizers等等，<br>可以帮助用户快速的执行各种模型任务、训练和微调。而且这些库的底层是支持 PyTorch 和 TensorFlow 的，在此基础上提供了更高级别封装的 API。</p><p>因此，对于想要入门 AI 领域的程序员小伙伴们，学习和实战 HuggingFace 工具库，我觉得是个不错的入门方式：</p><ol><li>由于 AI 领域随着 Chatgpt 的爆火，市面上涌入了各种 AI 的学习书籍和视频，除了一些应用方面的、明显蹭热度的、割韭菜的物料还比较容易排除和分辨之外，剩余的物料依然存在 —— 时效性差、工具不够通用、泛泛而谈、纯纯的 AI 平台打广告、为了追热度把功能吹的惊世骇俗等等问题。（我最近几个月就踩了不少这样的坑）</li><li>从学习的角度来说，首先从宏观上了解问题和知识域，会比直接进入细节和微观更有利于快速的学习。HuggingFace libs 比 PyTorch/TensorFlow 有着更高级的封装和功能展现，通过它掌握了宏观的概念和知识之后，想要了解更细节的知识，可以再去学习底层的内容。HuggingFace libs 的使用普及率也很高，不用担心学到小众的工具而浪费时间。</li><li>HuggingFace docs 官方基本会保持实时更新，时效性比起市面上的文档、书籍、视频要高上不少。</li></ol><p>这篇文章，就用来介绍和演示一下如何使用 HuggingFace Transformers库来完成一个NLP模型的简单微调。微调不是目的，学习和熟悉使用库来学习微调的概念和步骤，才是目的。<br>下面将要在一个很小的 NLP 预训练模型上进行微调，以实现对外卖评价的文本分类 —— 好评和差评两类。</p><h3 id="1-环境安装">1. 环境安装</h3><ul><li>安装好 python，版本&gt;=3.8</li><li>安装好 环境/包管理工具，conda 或者 pip。（如果同本人一样比较钟爱 pipenv，可以在安装好 pip 后，执行 <code>pip install pipenv</code>，然后使用<code>pipenv</code>来替代<code>pip</code>使用即可。）</li><li>用管理工具安装依赖库：<code>pipenv/pip install transformers datasets evaluate accelerate torch scikit-learn pandas jupyterlab</code>。<br>前4个就是 HuggingFace libs，剩下的针对不同的运行环境可以酌情安装，比如使用了Google colab，就不需要安装 jupyterlab。<br>详细代码已经上传到 github <a target="_blank" rel="noopener" href="https://github.com/ellendan000/hugging-face-demo/tree/main/00-transformers">hugging-face-demo/00-transformers</a>。</li></ul><h3 id="2-确认模型任务的原有行为">2. 确认模型任务的原有行为</h3><h4 id="2-1-想要调用模型，使用-HuggingFace-Pipeline-来做非常简单">2.1 想要调用模型，使用 HuggingFace Pipeline 来做非常简单</h4><pre class="line-numbers language-none"><code class="language-none">from transformers import pipeline
pipe = pipeline("text-classification", "hfl/rbt3")

sen = "饭菜有些咸！"
pipe(sen)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><code>text-classification</code> 是任务名，即完成文本分类任务。</li><li><code>hfl/rbt3</code> 是预训练好的模型名。pipeline 会从远程 huggingFace Hub 上下载开源的预训练模型到本地缓存。(记得开VPN，或者设置国内镜像库)<br>也可以事先将模型库clone或者download到本地，然后将这里的<code>hfl/rbt3</code>改为<code>./your-path-to-model</code></li><li><code>pipe(sen)</code> 直接传参调用，即执行任务。</li></ul><p>output:</p><blockquote><p>[{‘label’: ‘LABEL_1’, ‘score’: 0.7034752368927002}]</p></blockquote><ul><li>这里的 label 与我们的业务可能毫无关系 —— 不是外卖评价的好评和差评。</li></ul><h4 id="2-2-明确模型的原有行为和状态">2.2 明确模型的原有行为和状态</h4><p>使用如上方式，想要让模型进行二分类，并映射成”好评“和”差评“。</p><pre class="line-numbers language-none"><code class="language-none">from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline

model = AutoModelForSequenceClassification.from_pretrained("hfl/rbt3", num_labels=2)
tokenizer = AutoTokenizer.from_pretrained("hfl/rbt3")

model.config.id2label = {0: "差评！", 1: "好评！"}
pipe = pipeline("text-classification", model=model, tokenizer=tokenizer)

sen = "饭菜有些咸！"
pipe(sen)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><code>model</code> 分别加载模型，并且传入分类的数量<code>num_labels</code></li><li><code>tokenizer</code> 加载分词器，由于 pipeline 要求在传入 model 对象时，必须同时传入 tokenizer，因此这里也另外单独加载了分词器。<br>好在模型训练好的同时，对照的 tokenizer 基本都是确定的，直接从相同的 Hub 路径上加载即可。<code>tokenizer</code> 虽然会被翻译为<code>分词器</code>，但是其功能不仅仅是进行分词，它还包含了词典、序列映射、数据截断填充等一系列数据预处理功能。</li></ul><p>output:</p><blockquote><p>[{‘label’: ‘好评！’, ‘score’: 0.5472492575645447}]</p></blockquote><p>明显这个结果差强人意。<br>那么，下面就进入微调环节。</p><h3 id="3-模型微调">3. 模型微调</h3><h4 id="3-1-准备环境，导入相关包">3.1 准备环境，导入相关包</h4><pre class="line-numbers language-none"><code class="language-none">from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from datasets import load_dataset<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>事先已经安装好依赖库的话，这里只要导入相关包即可。</li></ul><h4 id="3-2-准备数据">3.2 准备数据</h4><p>随着模型训练和微调的库越来越多，代码其实都已经模式化，甚至已经出现直接使用 WebUI 界面进行模型训练和微调（比如 LLaMA-Factory），<br>因此对于追求训练和微调为目的来说，最重要的其实就是两块 —— 数据集和显卡。<br>这里我们使用 github 上的一个<a target="_blank" rel="noopener" href="https://github.com/SophonPlus/ChineseNlpCorpus/blob/master/datasets/waimai_10k/waimai_10k.csv">中文外卖评价数据集</a>，直接把它下载下来，保存到项目本地。</p><h5 id="加载数据集">加载数据集</h5><pre class="line-numbers language-none"><code class="language-none">dataset = load_dataset("csv", data_files="./waimai_10k.csv", split="train")
dataset = dataset.filter(lambda x: x["review"] is not None)
dataset<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>output：</p><blockquote><p>Dataset({<br>features: [‘label’, ‘review’],<br>num_rows: 11987<br>})</p></blockquote><ul><li>这个csv文件，包含了正向 4000 条，负向 约 8000 条。正向好评 label 为 1，负向差评 label 为 0。features 包括 label 和 review。</li><li><code>split="train"</code> 由于只有一个csv文件，没有进行 train 和 test 数据集的拆分，load_dataset 会默认将所有数据都算入 train 数据集。为了有利于后面手动进行数据集拆分，这里强调加载默认的 train 数据集。</li><li><code>dataset.filter</code> 将无文本的 review 记录过滤掉。</li></ul><h5 id="使用-tokenizer-进行数据预处理">使用 tokenizer 进行数据预处理</h5><pre class="line-numbers language-none"><code class="language-none">import torch

tokenizer = AutoTokenizer.from_pretrained("hfl/rbt3")

def process_function(examples):
    tokenized_examples = tokenizer(examples["review"], max_length=128, truncation=True)
    tokenized_examples["labels"] = examples["label"]
    return tokenized_examples

tokenized_dataset = dataset.map(process_function, batched=True, remove_columns=dataset.column_names)
tokenized_dataset<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>output:</p><blockquote><p>Dataset({<br>features: [‘input_ids’, ‘token_type_ids’, ‘attention_mask’, ‘labels’],<br>num_rows: 11987<br>})</p></blockquote><ul><li><code>dataset.map</code> 将原数据集的每条数据进行处理，小批量地执行 map function <code>process_function</code>，并且<code>remove_columns</code> 返回的结果集删除掉未加工的原始数据列。</li><li><code>tokenizer</code> 将每条数据超出最大长度<code>128</code>的数据进行截断。</li></ul><h5 id="分割数据集">分割数据集</h5><pre class="line-numbers language-none"><code class="language-none">tokenized_datasets = tokenized_dataset.train_test_split(test_size=0.1)
tokenized_datasets<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>output:</p><blockquote><p>DatasetDict({<br>train: Dataset({<br>features: [‘input_ids’, ‘token_type_ids’, ‘attention_mask’, ‘labels’],<br>num_rows: 10788<br>})<br>test: Dataset({<br>features: [‘input_ids’, ‘token_type_ids’, ‘attention_mask’, ‘labels’],<br>num_rows: 1199<br>})<br>})</p></blockquote><ul><li>将数据集中的 10% 作为测试数据集，即 90% 为训练数据集。返回结果为 DatasetDict 包含 train 和 test。</li></ul><h4 id="3-3-加载预训练模型">3.3 加载预训练模型</h4><pre class="line-numbers language-none"><code class="language-none">model = AutoModelForSequenceClassification.from_pretrained("hfl/rbt3")

# if torch.cuda.is_available():
#     model = model.cuda()
#     print('Use cuda GPU')
# elif torch.backends.mps.is_available():
#     model = model.to('mps')
#     print('Use mps')
model<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>加载预训练模型非常简单，HuggingFace 也不需要像 PyTorch 那样显性的将模型和参数传给GPU，底层已经帮助实现。<br>因此，上面注释中的 torch 部分代码完全可以删掉。</p><p>但如果编写 PyTorch 代码的话，还是必须加上。<br>如果跟我一样，使用的是 MacOS 的话、并且是 M1 芯片之后的版本，在写 PyTorch 代码时，需要把模型和参数传给<code>mps</code>。<br>因为 PyTorch 在 M1 之后使用 mps 进行了加速，虽然比起 GPU 速度上还是有不小差距，但是比起直接使用 CPU 来说，还是快上不少。<br>如果是 M1 之前的 Mac 的话，就不要勉强了，直接去使用 Google colab 或者 白嫖下阿里云PAI平台的免费限额，不然速度会慢到落泪。</p><h4 id="3-4-训练和评估">3.4 训练和评估</h4><h5 id="定义评估函数">定义评估函数</h5><pre class="line-numbers language-none"><code class="language-none">import evaluate

acc_metric = evaluate.load("accuracy")
f1_metric = evaluate.load("f1")

def eval_metric(eval_predict):
    predictions, labels = eval_predict
    predictions = predictions.argmax(axis=-1)
    acc = acc_metric.compute(predictions=predictions, references=labels)
    f1 = f1_metric.compute(predictions=predictions, references=labels)
    acc.update(f1)
    return acc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>evaluate</code> 库已经提供了大量评估函数的实现。这里使用了最简单的<code>准确率acc</code>和<code>F1分值</code>。<br>在二分类中，样本预测结果分为4类：</p><ul><li>TP （True Positive）：真*正例，即实际为正类，”正确“预测为正类的样本数。</li><li>TN （True Negative）：真*负例，即实际为负类，”正确“预测为负类的样本数。</li><li>FP （False Positive）：假*正例，即实际为负类，”错误“预测为正类的样本数。</li><li>FN （False Negative）：假*负例，即实际为正类，”错误“预测为负类的样本数。</li></ul><p><code>acc</code> = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{TP+TN}{TP+TN+FP+FN}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-.4033em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8723em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">TP</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:.10903em">TN</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:.13889em">FP</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:.10903em">FN</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">TP</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:.10903em">TN</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.4033em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>,被称为准确率。</p><p>了解<code>F1分值</code>前需要了解 <code>精确率 Precision</code>（也叫查准率） 和 <code>召回率 Recall</code>（也叫查全率）。</p><ul><li><code>Precison</code> = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{TP}{TP+FP}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-.4033em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8723em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">TP</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:.13889em">FP</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">TP</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.4033em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>，在所有被预测为正类的样本中，实际的确是正类的比例。</li><li><code>Recall</code> = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{TP}{TP+FN}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-.4033em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8723em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">TP</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:.10903em">FN</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">TP</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.4033em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>， 在所有正类的数据集范围内被成功预测对的比例。</li><li><code>F1</code> = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>×</mo><mfrac><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>×</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">2 \times \frac{Precision \times Recall}{Precision + Recall}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7278em;vertical-align:-.0833em"></span><span class="mord">2</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1.2834em;vertical-align:-.4033em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">P</span><span class="mord mathnormal mtight">rec</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:.00773em">R</span><span class="mord mathnormal mtight">ec</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:.01968em">ll</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">P</span><span class="mord mathnormal mtight">rec</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:.00773em">R</span><span class="mord mathnormal mtight">ec</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:.01968em">ll</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.4033em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>，是 Presion 和 Recall 的调和平均值，旨在提供一个综合评价指标，特别是针对类别不平衡的数据集。<br>F1分值在0到1之间，值越接近1表示模型的性能越好，既考虑了模型预测的准确性（Precision），也考虑了模型识别出所有正例的能力（Recall）。</li></ul><h5 id="定义训练参数">定义训练参数</h5><pre class="line-numbers language-none"><code class="language-none">from transformers import DataCollatorWithPadding
train_args = TrainingArguments(output_dir="./checkpoints",      # 输出文件夹
                               per_device_train_batch_size=64,  # 训练时的batch_size
                               per_device_eval_batch_size=128,  # 验证时的batch_size
                               logging_steps=10,                # log 打印的频率
                               eval_strategy="epoch",           # 评估策略
                               save_strategy="epoch",           # 保存策略
                               save_total_limit=3,              # 最大保存数
                               learning_rate=2e-5,              # 学习率
                               weight_decay=0.01,               # weight_decay
                               metric_for_best_model="f1",      # 设定评估指标
                               load_best_model_at_end=True)     # 训练完成后加载最优模型

trainer = Trainer(model=model, 
                  args=train_args, 
                  train_dataset=tokenized_datasets["train"], 
                  eval_dataset=tokenized_datasets["test"], 
                  data_collator=DataCollatorWithPadding(tokenizer=tokenizer),
                  compute_metrics=eval_metric)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>HuggingFace 库对训练的实现细节已经进行了封装，只需要传参即可控制过程。当然这些参数背后代表的过程控制，需要了解一部分模型训练的知识和细节。</li><li><code>batch</code>与<code>step</code>相关，比如这里训练数据集全量是1w多条，<code>per_device_train_batch_size</code>设置为64, <code>step</code>即 1w / 64 约为 156，也就是训练数据集跑一次全量需要 156 step</li><li><code>logging_steps=10</code> 每10个step打印一下进度</li><li><code>eval_strategy="epoch"</code> 每个epoch（也就是跑一次全量）进行一次评估</li><li><code>save_strategy="epoch"</code> 每个epoch进行一次磁盘保存</li><li><code>learning_rate</code> 和 <code>weight_decay</code> 深度学习训练模型的超参数设置</li><li>以<code>metric_for_best_model</code>为标准，加载最优模型<code>load_best_model_at_end</code></li></ul><h5 id="执行训练">执行训练</h5><pre class="line-numbers language-none"><code class="language-none">trainer.train()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>output:</p><blockquote><p>2%|▏ | 10/507 [00:03&lt;02:18, 3.59it/s]<br>{‘loss’: 0.5992, ‘grad_norm’: 1.7134801149368286, ‘learning_rate’: 1.9605522682445763e-05, ‘epoch’: 0.06}<br>4%|▍ | 20/507 [00:06&lt;02:53, 2.81it/s]<br>{‘loss’: 0.5047, ‘grad_norm’: 2.125014543533325, ‘learning_rate’: 1.921104536489152e-05, ‘epoch’: 0.12}<br>6%|▌ | 30/507 [00:09&lt;02:42, 2.93it/s]<br>{‘loss’: 0.4028, ‘grad_norm’: 2.1130874156951904, ‘learning_rate’: 1.881656804733728e-05, ‘epoch’: 0.18}<br>8%|▊ | 40/507 [00:13&lt;02:34, 3.02it/s]<br>{‘loss’: 0.3768, ‘grad_norm’: 2.4480748176574707, ‘learning_rate’: 1.842209072978304e-05, ‘epoch’: 0.24}<br>10%|▉ | 50/507 [00:16&lt;02:52, 2.66it/s]<br>…………<br>{‘loss’: 0.2512, ‘grad_norm’: 3.6124022006988525, ‘learning_rate’: 2.7613412228796843e-07, ‘epoch’: 2.96}<br>100%|██████████| 507/507 [03:01&lt;00:00, 3.40it/s]<br>100%|██████████| 507/507 [03:03&lt;00:00, 3.40it/s]<br>{‘eval_loss’: 0.23135297000408173, ‘eval_accuracy’: 0.9174311926605505, ‘eval_f1’: 0.8748419721871049, ‘eval_runtime’: 2.3411, ‘eval_samples_per_second’: 512.143, ‘eval_steps_per_second’: 4.271, ‘epoch’: 3.0}<br>100%|██████████| 507/507 [03:04&lt;00:00, 2.75it/s]<br>{‘train_runtime’: 184.3464, ‘train_samples_per_second’: 175.561, ‘train_steps_per_second’: 2.75, ‘train_loss’: 0.27392145938421847, ‘epoch’: 3.0}</p></blockquote><ul><li>在训练的过程中，会按照之前的参数设置<code>logging_steps</code>、<code>eval_strategy</code>来打印进度反馈。</li></ul><h5 id="评估">评估</h5><pre class="line-numbers language-none"><code class="language-none">trainer.evaluate()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>Output:</p><blockquote><p>{‘eval_loss’: 0.23134386539459229,<br>‘eval_accuracy’: 0.9182652210175146,<br>‘eval_f1’: 0.8759493670886076,<br>‘eval_runtime’: 2.2119,<br>‘eval_samples_per_second’: 542.056,<br>‘eval_steps_per_second’: 4.521,<br>‘epoch’: 3.0}</p></blockquote><ul><li>这里默认使用参数设置的<code>eval_dataset</code>进行评估。</li><li>想要重新针对训练集进行评估需要调用<code>trainer.evaluate(tokenized_datasets["train"])</code></li></ul><h4 id="3-5-模型预测">3.5 模型预测</h4><pre class="line-numbers language-none"><code class="language-none">from transformers import pipeline

id2_label = {0: "差评！", 1: "好评！"}
model.config.id2label = id2_label
pipe = pipeline("text-classification", model=model, tokenizer=tokenizer)

sen = "饭菜有些咸！"
pipe(sen)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Output:</p><blockquote><p>[{‘label’: ‘差评！’, ‘score’: 0.9463842511177063}]</p></blockquote><ul><li>明显比微调之前的预训练模型要靠谱许多。</li></ul><h4 id="3-6-微调模型保存">3.6 微调模型保存</h4><h5 id="保存到本地">保存到本地</h5><pre class="line-numbers language-none"><code class="language-none">local_model_path = './my-awesome-model'
model.save_pretrained(local_model_path)
tokenizer.save_pretrained(local_model_path)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Output:</p><blockquote><p>(‘./my-awesome-model/tokenizer_config.json’,<br>‘./my-awesome-model/special_tokens_map.json’,<br>‘./my-awesome-model/vocab.txt’,<br>‘./my-awesome-model/added_tokens.json’,<br>‘./my-awesome-model/tokenizer.json’)</p></blockquote><h5 id="从本地加载模型和预测">从本地加载模型和预测</h5><pre class="line-numbers language-none"><code class="language-none">model = AutoModelForSequenceClassification.from_pretrained(local_model_path)
model.config.id2label = id2_label

tokenizer = AutoTokenizer.from_pretrained(local_model_path)
pipe = pipeline("text-classification", model=model, tokenizer=tokenizer)

sen = "饭菜有些咸！"
pipe(sen)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="附">附</h3><p>本文仅使用了普通微调训练的方式，会对参数进行全量调整。<br>如果涉及到参数千万以上的大模型，这种方式并不适合 —— 需要使用 HuggingFace 的<code>PEFT</code>库，针对小部分参数进行微调的同时获得更好的模型预测效果。<br>即使这样，也并非普通的显卡就可进行训练，作者本人曾经试过在 Google Colab 上15G显存 仅加载 Llama3 模型 —— 根本加载不进去，直接 OutOfMemory。论数据集和显卡的重要性。</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="https://ellendan.com" rel="external nofollow noreferrer">Ellen Dan</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ellendan.com/2024/06/18/shi-yong-huggingface-transformers-jin-xing-mo-xing-wei-diao/">https://ellendan.com/2024/06/18/shi-yong-huggingface-transformers-jin-xing-mo-xing-wei-diao/</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://ellendan.com" target="_blank">Ellen Dan</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/ML/"><span class="chip bg-color">ML</span> </a><a href="/tags/AI/"><span class="chip bg-color">AI</span> </a><a href="/tags/HuggingFace/"><span class="chip bg-color">HuggingFace</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.valine-card{margin:1.5rem auto}.valine-card .card-content{padding:20px 20px 5px 20px}#vcomments textarea{box-sizing:border-box;background:url(/medias/comment_bg.png) 100% 100% no-repeat}#vcomments p{margin:2px 2px 10px;font-size:1.05rem;line-height:1.78rem}#vcomments blockquote p{text-indent:.2rem}#vcomments a{padding:0 2px;color:#4cbf30;font-weight:500;text-decoration:none}#vcomments img{max-width:100%;height:auto;cursor:pointer}#vcomments ol li{list-style-type:decimal}#vcomments ol,ul{display:block;padding-left:2em;word-spacing:.05rem}#vcomments ul li,ol li{display:list-item;line-height:1.8rem;font-size:1rem}#vcomments ul li{list-style-type:disc}#vcomments ul ul li{list-style-type:circle}#vcomments table,td,th{padding:12px 13px;border:1px solid #dfe2e5}#vcomments table,td,th{border:0}table tr:nth-child(2n),thead{background-color:#fafafa}#vcomments table th{background-color:#f2f2f2;min-width:80px}#vcomments table td{min-width:80px}#vcomments h1{font-size:1.85rem;font-weight:700;line-height:2.2rem}#vcomments h2{font-size:1.65rem;font-weight:700;line-height:1.9rem}#vcomments h3{font-size:1.45rem;font-weight:700;line-height:1.7rem}#vcomments h4{font-size:1.25rem;font-weight:700;line-height:1.5rem}#vcomments h5{font-size:1.1rem;font-weight:700;line-height:1.4rem}#vcomments h6{font-size:1rem;line-height:1.3rem}#vcomments p{font-size:1rem;line-height:1.5rem}#vcomments hr{margin:12px 0;border:0;border-top:1px solid #ccc}#vcomments blockquote{margin:15px 0;border-left:5px solid #42b983;padding:1rem .8rem .3rem .8rem;color:#666;background-color:rgba(66,185,131,.1)}#vcomments pre{font-family:monospace,monospace;padding:1.2em;margin:.5em 0;background:#272822;overflow:auto;border-radius:.3em;tab-size:4}#vcomments code{font-family:monospace,monospace;padding:1px 3px;font-size:.92rem;color:#e96900;background-color:#f8f8f8;border-radius:2px}#vcomments pre code{font-family:monospace,monospace;padding:0;color:#e8eaf6;background-color:#272822}#vcomments pre[class*=language-]{padding:1.2em;margin:.5em 0}#vcomments code[class*=language-],pre[class*=language-]{color:#e8eaf6}#vcomments [type=checkbox]:not(:checked),[type=checkbox]:checked{position:inherit;margin-left:-1.3rem;margin-right:.4rem;margin-top:-1px;vertical-align:middle;left:unset;visibility:visible}#vcomments b,strong{font-weight:700}#vcomments dfn{font-style:italic}#vcomments small{font-size:85%}#vcomments cite{font-style:normal}#vcomments mark{background-color:#fcf8e3;padding:.2em}#vcomments table,td,th{padding:12px 13px;border:1px solid #dfe2e5}table tr:nth-child(2n),thead{background-color:#fafafa}#vcomments table th{background-color:#f2f2f2;min-width:80px}#vcomments table td{min-width:80px}#vcomments [type=checkbox]:not(:checked),[type=checkbox]:checked{position:inherit;margin-left:-1.3rem;margin-right:.4rem;margin-top:-1px;vertical-align:middle;left:unset;visibility:visible}</style><div class="card valine-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="vcomments" class="card-content" style="display:grid"></div></div><script src="/libs/valine/av-min.js"></script><script src="/libs/valine/Valine.min.js"></script><script>new Valine({el:"#vcomments",appId:"WVtCCI42NY8gfqgJk8gwPgc0-gzGzoHsz",appKey:"chVYs2ozXF6PwPMDu54ff3Jc",serverURLs:"https://wvtcci42.lc-cn-n1-shared.com",notify:!1,verify:!1,visitor:!0,avatar:"mm",pageSize:"10",lang:"zh-cn",placeholder:"just go go"})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/2024/07/02/liang-ri-yi-gai-nian-zhi-azure-pian-virtual-machine/"><div class="card-image"><img src="/medias/loading-1.gif" data-original="/medias/featureimages/13.jpg" class="responsive-img" alt="两日一概念之Azure篇 —— Virtual Machine"> <span class="card-title">两日一概念之Azure篇 —— Virtual Machine</span></div></a><div class="card-content article-content"><div class="summary block-with-text"></div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-07-02 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/Cloud/" class="post-category">Cloud</a></span></div></div><div class="card-action article-tags"><a href="/tags/Azure/"><span class="chip bg-color">Azure</span> </a><a href="/tags/%E4%B8%A4%E6%97%A5%E4%B8%80%E6%A6%82%E5%BF%B5/"><span class="chip bg-color">两日一概念</span> </a><a href="/tags/Cloud/"><span class="chip bg-color">Cloud</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/2024/03/19/kubernetes-zu-jian-jia-gou-hui-gu/"><div class="card-image"><img src="/medias/loading-1.gif" data-original="/medias/featureimages/5.jpg" class="responsive-img" alt="Kubernetes 组件架构回顾"> <span class="card-title">Kubernetes 组件架构回顾</span></div></a><div class="card-content article-content"><div class="summary block-with-text"></div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-03-19 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/Kubernetes/" class="post-category">Kubernetes</a></span></div></div><div class="card-action article-tags"><a href="/tags/Kubernetes/"><span class="chip bg-color">Kubernetes</span> </a><a href="/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"><span class="chip bg-color">云原生</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0===window.getSelection||(""+(n=window.getSelection())).length<Number.parseInt("120")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"!==n.getRangeAt(0).commonAncestorContainer.nodeName&&"CODE"!==n.getRangeAt(0).commonAncestorContainer.nodeName||(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: ellendan<br />文章作者: Ellen Dan<br />文章链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200))})</script><script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="/libs/prism/prism.min.js"></script><script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget card" style="background-color:#fff"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=parseInt(.4*$(window).height()-64),e=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>t?e.addClass("toc-fixed"):e.removeClass("toc-fixed")});const n="expanded";let i=$("#toc-aside"),l=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){i.hasClass(n)?(i.removeClass(n).hide(),l.removeClass("l9")):(i.addClass(n).show(),l.addClass("l9"));var e="artDetail",o="prenext-posts";if(0!==(e=$("#"+e)).length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#"+o).width(t)}})})</script></main><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2019-2024</span> <a href="/about" target="_blank">Ellen Dan</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">100.3k</span> <span id="busuanzi_container_site_pv">&nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp; <span id="busuanzi_value_site_pv" class="white-color"></span> </span><span id="busuanzi_container_site_uv">&nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp; <span id="busuanzi_value_site_uv" class="white-color"></span></span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ellendan000" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:ellendan000@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50"><i class="fas fa-rss"></i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script type="text/javascript">$(function(){!function(t,r,s){"use strict";$.ajax({url:t,dataType:"xml",success:function(t){var e=$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),t=document.getElementById(r),n=document.getElementById(s);t.addEventListener("input",function(){var o='<ul class="search-result-list">',h=this.value.trim().toLowerCase().split(/[\s\-]+/);n.innerHTML="",this.value.trim().length<=0||(e.forEach(function(t){var n,e,r,s=!0,i=t.title.trim().toLowerCase(),l=t.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),a=0===(a=t.url).indexOf("/")?t.url:"/"+a,c=-1,u=-1;""!==i&&""!==l&&h.forEach(function(t,e){n=i.indexOf(t),c=l.indexOf(t),n<0&&c<0?s=!1:(c<0&&(c=0),0===e&&(u=c))}),s&&(o+="<li><a href='"+a+"' class='search-result-title'>"+i+"</a>",a=t.content.trim().replace(/<[^>]+>/g,""),0<=u&&(t=u+80,(t=0===(e=(e=u-20)<0?0:e)?100:t)>a.length&&(t=a.length),r=a.substr(e,t),h.forEach(function(t){var e=new RegExp(t,"gi");r=r.replace(e,'<em class="search-keyword">'+t+"</em>")}),o+='<p class="search-result">'+r+"...</p>"),o+="</li>")}),o+="</ul>",n.innerHTML=o)})}})}("/search.xml","searchInput","searchResult")})</script><div class="stars-con"><div id="stars"></div><div id="stars2"></div><div id="stars3"></div></div><script>function switchNightMode(){$('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($("body")),setTimeout(function(){$("body").hasClass("DarkMode")?($("body").removeClass("DarkMode"),localStorage.setItem("isDark","0"),$("#sum-moon-icon").removeClass("fa-sun").addClass("fa-moon")):($("body").addClass("DarkMode"),localStorage.setItem("isDark","1"),$("#sum-moon-icon").addClass("fa-sun").removeClass("fa-moon")),setTimeout(function(){$(".Cuteen_DarkSky").fadeOut(1e3,function(){$(this).remove()})},2e3)})}</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="/libs/materialize/materialize.min.js"></script><script src="/libs/masonry/masonry.pkgd.min.js"></script><script src="/libs/aos/aos.js"></script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/js/matery.js"></script><script>document.body.setAttribute("class","theme-purple")</script><script src="/libs/mermaid/mermaid.min.js"></script><script>window.mermaid&&mermaid.initialize({theme:"forest"})</script><script type="text/javascript">var windowWidth=$(window).width();768<windowWidth&&document.write('<script type="text/javascript" src="/libs/others/snow.js"><\/script>')</script><script src="https://ssl.captcha.qq.com/TCaptcha.js"></script><script src="/libs/others/TencentCaptcha.js"></script><button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0],e=(t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",document.getElementsByTagName("script")[0]);e.parentNode.insertBefore(t,e)}()</script><script async src="/libs/others/busuanzi.pure.mini.js"></script><script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async></script><script src="/libs/instantpage/instantpage.js" type="module"></script><script src="https://gcore.jsdelivr.net/npm/hexo-tag-common@0.2.0/js/index.js"></script><style>[bg-lazy]{background-image:none!important;background-color:#eee!important}</style><script>window.imageLazyLoadSetting={isSPA:!1,preloadRatio:1,processImages:null}</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})})</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a=c[o],i=function(){c=c.filter(function(t){return a!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(a)};(t=a).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),i()):(e=new Image,n=t.getAttribute("data-original"),e.onload=function(){t.src=n,t.removeAttribute("data-original"),i()},t.src!==n&&(e.src=n))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this)</script><script src="/js/markmap.js"></script></body></html>