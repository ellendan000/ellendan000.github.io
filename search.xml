<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>macOS安装sonarqube</title>
      <link href="/2023/12/14/macos-an-zhuang-sonarqube/"/>
      <url>/2023/12/14/macos-an-zhuang-sonarqube/</url>
      
        <content type="html"><![CDATA[<h3 id="1-环境准备">1. 环境准备</h3><p>提前预安装好 docker 和 postgresql 数据库。<br>sonarqube 除了postgresql数据库以外，只提供对SQLserver和oracle数据一共选择。</p><p>postgresql 安装好以后，使用命令：</p><pre class="line-numbers language-none"><code class="language-none">$ createuser -s postgres$ psql -U postgres&gt; CREATE DATABASE sonarqube;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="2-使用-docker-images-进行安装">2. 使用 docker images 进行安装</h3><h4 id="2-1-create-volumes">2.1 create volumes</h4><pre class="line-numbers language-none"><code class="language-none">$ docker volume create --name sonarqube_data$ docker volume create --name sonarqube_logs$ docker volume create --name sonarqube_extensions<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="2-2-docker-run">2.2 docker run</h4><p>注意：sonarqube 只有community edition是免费的。</p><pre class="line-numbers language-none"><code class="language-none">docker run -d --name sonarqube \    -p 9000:9000 \    -e SONAR_JDBC_URL=jdbc:postgresql://host.docker.internal:5432/postgres \    -e SONAR_JDBC_USERNAME=postgres \    -e SONAR_JDBC_PASSWORD=... \    -v sonarqube_data:/opt/sonarqube/data \    -v sonarqube_extensions:/opt/sonarqube/extensions \    -v sonarqube_logs:/opt/sonarqube/logs \    sonarque:lts-community<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-访问本地安装好的-sonarqube">3. 访问本地安装好的 sonarqube</h3><p>本地地址 <a href="http://localhost:9000">http://localhost:9000</a><br>默认用户名密码： admin/admin</p><h4 id="3-1-创建project">3.1 创建project</h4><p>登录访问 sonarque，点击菜单【projects】，创建project。<br><img src="/2023/12/14/macos-an-zhuang-sonarqube/create_projects.png" alt="create projects"><br>也可以选择手动创建<br><img src="/2023/12/14/macos-an-zhuang-sonarqube/manual_create_project.png" alt="manual create project"></p><h4 id="3-2-可以使用intellij-idea安装sonarlint插件：">3.2 可以使用intellij idea安装sonarlint插件：</h4><p><img src="/2023/12/14/macos-an-zhuang-sonarqube/sonarlint_configuration.png" alt="sonarlint configuration"><br>配置好后，点击【Update local storage】按钮，下载并使用sonarqube上定义的配置和规则。<br>这样开发的过程中，idea 可以实时反馈代码编写问题。</p><h4 id="3-3-gradle-sonar-plugin">3.3 gradle sonar plugin</h4><p>在 gradle build文件中，plugins 添加 sonar。<br>legacy 写法:</p><pre class="line-numbers language-none"><code class="language-none">buildscript {    repositories {        mavenCentral()        maven { url 'https://plugins.gradle.org/m2/' }    }    dependencies {        classpath 'org.sonarsource.scanner.gradle:sonarqube-gradle-plugin:3.5.0.2730'    }}apply plugin: 'java'apply plugin: 'org.sonarqube'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后在 CI 的脚本上添加命令：</p><pre class="line-numbers language-none"><code class="language-none">$ ./gradlew :web:sonar \    -Dsonar.projectKey=... \    -Dsonar.host.url=http://localhost:9000 \    -Dsonar.login=&lt;sonar_token&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>最后就可以在</p><h3 id="附录：">附录：</h3><p><a href="https://docs.sonarsource.com/sonarqube/9.9/setup-and-upgrade/install-the-server/#installing-sonarqube-from-the-docker-image">sonarsource docs</a></p>]]></content>
      
      
      <categories>
          
          <category> DevOps </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一劳永逸 NGINX 反向代理转发配置</title>
      <link href="/2023/11/21/yi-lao-yong-yi-nginx-fan-xiang-dai-li-zhuan-fa-pei-zhi/"/>
      <url>/2023/11/21/yi-lao-yong-yi-nginx-fan-xiang-dai-li-zhuan-fa-pei-zhi/</url>
      
        <content type="html"><![CDATA[<p>当项目环境 setup 时，针对不同的技术选型，一些时候需要自己使用 NGINX 配置反向代理。<br>每当这个时候，我总是记不住 location 和 proxy_pass 中路径带 <code>/</code> 和不带 <code>/</code> 的对应关系、配置错误还会带来重定向 post 变 get 的问题等等，因此每每配置都需要查阅文档，反复验证和测试。<br>而最近找到一种写法，可以彻底放弃之前的配置困扰 —— 其解决思路可以类比 表达式中的括号<code>()</code>, 当记不住或者不确定操作符之间的优先级时，建议添加<code>()</code>，即<code>将隐式转成显式声明</code>  —— 避免优先级不明确的同时，也增加了代码的可读性。</p><p>下面就是个人建议的 Nginx 配置方式：</p><pre class="line-numbers language-none"><code class="language-none">http {……    resolver 8.8.8.8;    server {        ……        location ~* ^/api/(players|usage)(.*)$ {            proxy_pass https://example.com/api/$1$2$is_args$args;            proxy_buffering off;            proxy_set_header  X-Forwarded-For $remote_addr;        }        location ~* ^/api/(wx\-tokens|orders)(.*)$ {            proxy_pass https://example.com/api/$1$2$is_args$args;            proxy_buffering off;            proxy_set_header  X-Forwarded-For $remote_addr;        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如上</p><ul><li>使用正则 <code>~* ^$</code> 匹配原始的整个请求路径</li><li>proxy_pass 路径带上整个正则匹配的子组，<code>$1$2</code>明确整个URI的部分，<code>$is_args$args</code>明确queryString部分（这部分不在location regex的匹配范围内）</li><li><code>proxy_buffering off</code> 为了使用 chunked 方式透传，需要关闭 proxy_buffering</li><li>添加<code>resovler 8.8.8.8;</code>, 解决一些版本 NGINX 报错<code>no resolver defined to resolve example.com</code>的问题</li></ul>]]></content>
      
      
      <categories>
          
          <category> DevOps </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>定时自动删除ACR images</title>
      <link href="/2023/11/17/ding-shi-zi-dong-shan-chu-acr-images/"/>
      <url>/2023/11/17/ding-shi-zi-dong-shan-chu-acr-images/</url>
      
        <content type="html"><![CDATA[<p>在之前 Azure App Service 部署时，使用到了 Azure Container Register，对于许多项目而言，超过一定时限的历史 images 再次使用的几率近乎为零。<br>因此，无论从制品管理，还是存储成本，定期清除不使用的 images是一项常见的任务。<br>可以使用 Azure 提供的工具 acr purge 和 acr task 来达成该目标。</p><h4 id="1-命令创建定时-ACR-task">1. 命令创建定时 ACR task</h4><p>运行以下命令（使用Azure cli 或者 Azure cloud shell皆可）。</p><pre class="line-numbers language-none"><code class="language-none">$ PURGE_CMD="acr purge --filter '.*:.*' --ago 14d --untagged"$ az acr task create --name purgeTask \    --cmd "$PURGE_CMD" \    --schedule "0 1 * * *" \    --registry &lt;register-name&gt; \    --context /dev/null<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-查看-task-runs">2. 查看 task runs</h4><p>命令：</p><pre class="line-numbers language-none"><code class="language-none">$ az acr task list-runs --name purgeTask --registry &lt;register-name&gt; --output table<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="3-也可以单次手动触发-ACR-purge">3. 也可以单次手动触发 ACR purge</h4><pre class="line-numbers language-none"><code class="language-none">$ PURGE_CMD="acr purge --filter '.*:.*' --ago 14d --untagged"$ az acr run --cmd "$PURGE_CMD" --registry &lt;register-name&gt; /dev/null<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="相关链接">相关链接</h4><ul><li><a href="https://learn.microsoft.com/zh-cn/azure/container-registry/container-registry-tasks-scheduled">教程：按定义的计划运行 ACR 任务</a></li><li><a href="https://learn.microsoft.com/zh-cn/azure/container-registry/container-registry-auto-purge">自动清除 Azure 容器注册表中的映像</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Azure </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Azure </tag>
            
            <tag> 云平台 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在 Python 技术栈下做 DB Migration —— Alembic（Flask Migration）</title>
      <link href="/2023/11/12/zai-python-ji-zhu-zhan-xia-zuo-db-migration-alembic-flask-migration/"/>
      <url>/2023/11/12/zai-python-ji-zhu-zhan-xia-zuo-db-migration-alembic-flask-migration/</url>
      
        <content type="html"><![CDATA[<p>在 Java 技术栈常用的 DB Migration 工具有 Flyway、Liquibase，可以快速集成在Spring boot中运行。<br>那在 Python 技术栈中，相似功能的工具有么？自然是有的。<br>有人编写了 pyliquibase，想要将 liquibase 在 Python中运用，可惜在 github上只有30个star。<br>我这里比较推荐的是 <a href="https://alembic.sqlalchemy.org/en/latest/">Alembic</a>，它本身是一个基于 SQLAlchemy（Python下的ORM库，类比Java里的 JPA/Hibernate）的轻量级的DB Migration工具，并且与 Flask 有现成的集成工具包 —— Flask Migration。</p><p>当然，它最打动我的功能 —— 是可以从 ORM 的 Model class 自动对比 DB 现有结构，针对差异生成 migration 脚本文件并且版本管理。<br>这在 Groovy/Grails 时代是非常常见的功能，但是在 Java 的 DB Migration 工具中却并不常见。</p><p>以下，是我在 Flask + Flask-SQLAlchemy 中直接使用 Flask-Migration 的过程。</p><h4 id="1-安装-Flask-Migration">1. 安装 Flask-Migration</h4><pre class="line-numbers language-none"><code class="language-none">$ pipenv install Flask-Migrate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="2-Flask-应用启动项添加-Migration">2. Flask 应用启动项添加 Migration</h4><p>下面是一个普通的Flask + Flask-SQLAlchemy 的应用启动项 Demo 代码，使用 Flask-Migration 仅需要添加第3行、8行即可 —— Flask-Migration 可以读取到 SQLAlchemy 和 DB 的配置信息。</p><pre class="line-numbers language-none"><code class="language-none">from flask import Flaskfrom flask_sqlalchemy import SQLAlchemyfrom flask_migrate import Migrate #为使用flask-migrate添加app = Flask(__name__)app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///app.db'db = SQLAlchemy(app) #为使用flask-migrate添加class User(db.Model):    id = db.Column(db.Integer, primary_key=True)    name = db.Column(db.String(128))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="3-初始化-DB-Migration-的目录文件结构（Alembic的目录文件结构）">3. 初始化 DB Migration 的目录文件结构（Alembic的目录文件结构）</h4><pre class="line-numbers language-none"><code class="language-none">$ pipenv run flask db init<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这时，会在你的项目目录下生成 migration 以下目录结构。</p><pre class="line-numbers language-none"><code class="language-none">yourproject/    migrations/        alembic.ini        env.py        README        script.py.mako        versions/            3512b954651e_add_account.py            2b1ae634e5cd_add_order_id.py            3adcc9a56557_rename_username_field.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>DB migration 脚本，就存放在 migrations/versions 文件夹下。</p><p>Flask-Migration 将 Alembic 的命令进行了封装，相同的命令在 Alembic 是 <code>alembic init</code>。<br>其他命令基本都如此，因此想要看更详细的命令功能说明，可以查找 Alembic 命令说明。</p><h4 id="4-修改配置，为-migration-script-添加带时间戳的命名规则">4. 修改配置，为 migration script 添加带时间戳的命名规则</h4><p>使用 Flyway/Liquibase 习惯了的同学，可能比较喜欢 script 文件名上标记有时间 —— 这样可以一眼明了脚本执行的顺序，而不用打开文件查找可读性差的版本号。如下面截图这样<br><img src="./%E5%9C%A8Python%E6%8A%80%E6%9C%AF%E6%A0%88%E4%B8%8B%E5%81%9ADB-Migration-%E2%80%94%E2%80%94-Flask-Migration/version-with-timestamp.png" alt="vesrions-with-timestamp"></p><p>只用打开配置文件<code>script.py.mako</code>，在相同项下面修改<code>file_template</code>即可。</p><pre class="line-numbers language-none"><code class="language-none">[alembic]# template used to generate migration files# file_template = %%(rev)s_%%(slug)sfile_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="5-对比ORM-model-和-DB-现有结构，针对差异自动生成-version-migration脚本">5. 对比ORM model 和 DB 现有结构，针对差异自动生成 version migration脚本</h4><pre class="line-numbers language-none"><code class="language-none">$ pipenv run flask db migrate -m "Initial migration."<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这时 Flask-Migration 会生成如下这样的迁移脚本。</p><pre class="line-numbers language-none"><code class="language-none">"""Initial migration.Revision ID: e059cb3579d7Revises: Create Date: 2023-11-01 15:49:13.366391"""# revision identifiers, used by Alembic.revision = 'e059cb3579d7'down_revision = Nonebranch_labels = Nonefrom alembic import opimport sqlalchemy as sadef upgrade():    op.create_table('account',    sa.Column('id', sa.BigInteger(), nullable=False),    sa.Column('username', sa.String(length=50), nullable=False),    sa.Column('password', sa.String(length=50), nullable=False),    sa.PrimaryKeyConstraint('id')    )def downgrade():    op.drop_table('account')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="6-执行-DB-migration脚本，进行数据库变更">6. 执行 DB migration脚本，进行数据库变更</h4><pre class="line-numbers language-none"><code class="language-none">$ pipenv run flask db upgrade &lt;revision&gt;# 或者降级 pipenv run flask db downgrade &lt;revision&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>revison 可以是版本号前缀，也可以是 head（最新版本）、+1（相对位置加一）、-x(相对位置减x)。<br>如果 upgrade 不指定 revision，则默认是 head。<br>downgrade 不指定 revision，则默认是 -1。</p><h4 id="7-不能依赖flask-db-migrate-生成的情况，需要手动编写迁移upgrade-downgrade-方法">7. 不能依赖flask db migrate 生成的情况，需要手动编写迁移upgrade()/downgrade()方法</h4><p>比如 Account 表格中需要初始化一个system admin record 时，这种无法通过flask db migrate自动生成。<br>使用命令：</p><pre class="line-numbers language-none"><code class="language-none">$ pipenv run flask db revision -m 'Init system admin record.'<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这时会生成一个空的版本脚本文件，其中 upgrade()/downgrade()方法需要程序员使用脚本自行编写。<br>语法查看<a href="https://alembic.sqlalchemy.org/en/latest/ops.html">Alembic Operation Reference</a></p><h4 id="8-协同开发，需要用到的-merge-操作">8. 协同开发，需要用到的 merge 操作</h4><p>当协同开发，有多人提交时，难免会出现有两个 head revison 的情况。解决方式两种：</p><ol><li>在脚本语句不存在冲突的情况下，提交人将自己的文件中的<code>down_revision</code>字段值替换成另一个 head revision 值即可。类似 git pull --rebase 的路线。</li><li>使用<code>flask db merge</code>命令。</li></ol><pre class="line-numbers language-none"><code class="language-none"># 列出 head revisions$ pip run flask db heads# 生成 merge 脚本$ flask db merge &lt;revision-1&gt; &lt;revision-2&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>以上日常开发中的基本用法，更多功能探索可以查阅 Alembic official document。</strong></p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Sqlalchemy 对于 sequence 的支持</title>
      <link href="/2023/10/18/sqlalchemy-dui-yu-sequence-de-zhi-chi/"/>
      <url>/2023/10/18/sqlalchemy-dui-yu-sequence-de-zhi-chi/</url>
      
        <content type="html"><![CDATA[<p>sqlalchemy 对于 sequence 的支持（底层数据库引擎必须具有 sequence 功能），具有简单易用性。<br>比如下面这个例子：<br>假设创建不同类型的 World 时，需要一个序列码，此序列码单类型内唯一。</p><pre class="line-numbers language-none"><code class="language-none">import pinyinfrom flask_sqlalchemy import SQLAlchemyfrom sqlalchemy_serializer import SerializerMixinfrom sqlalchemy import String, BigInteger, Sequencedb = SQLAlchemy()@dataclassclass World(db.Model, SerializerMixin):    __tablename__ = 'world'    id = db.Column(BigInteger, primary_key=True)    serial_number = db.Column(String(32), nullable=False)    @staticmethod    def create(world_category_id):        world_category = WorldCategory.get(world_category_id)        style_pinyin = pinyin.get(world_category.style, format="strip")        sequence = Sequence(style_pinyin, start=1)        seq_ddl = CreateSequence(sequence, if_not_exists=True)        session = db.session        session.execute(seq_ddl)        next_value = session.scalar(sequence)        world = World(world_category_id=world_category_id, serial_number=next_value)        session.add(world)        session.commit()        return world<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>也正如上面所说，对于不支持 Sequence 的数据库，此段代码并不能生效。</p><p>有时候，反思一下业务，是否真的需要连续性的序列码？<br>其实，序列码的初衷是唯一性，使用 Sequence 来实现，由于其连续和记数性，反而会造成一些业务上统计数据的泄露，并且给技术上 hack API 和 数据带来便捷。<br>因此，是否使用 Sequence 视情况而定。<br>如序列码这样的生成，可以接受数字、字符规则的，可以使用 UUID，仅能接受数字的，可以使用 snowflake 算法，这样业务上带来规则隐秘性，同时技术上摆脱了对特定数据库类型的依赖。</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用 GITHUB WORKFLOW 自动发布 Azure CR 和部署 Azure App Service</title>
      <link href="/2023/09/01/shi-yong-github-workflow-zi-dong-fa-bu-azure-cr-he-bu-shu-azure-app-service/"/>
      <url>/2023/09/01/shi-yong-github-workflow-zi-dong-fa-bu-azure-cr-he-bu-shu-azure-app-service/</url>
      
        <content type="html"><![CDATA[<h3 id="Azure-App-Service-概述">Azure App Service 概述</h3><p>Azure 计算服务提供了多种类型：<code>VM</code>、<code>Container apps</code>、<code>App service</code>、<code>static App service</code>、<code>AKS</code>、<code>Logic apps</code>、<code>Functions</code>。<br>区别于其他计算服务：</p><ul><li>Azure app service 是一款 PAAS 服务，基于 HTTP 提供托管 Web 应用程序、REST API 和移动后端。</li><li>可以通过 App service plan 购买一套“单位时间固定限额”的即付即用资源池，在此 plan 下可以建立多个应用 share 这份资源；通过 service plan 的变更进行应用计算资源的横向/纵向扩展。</li><li>同时，不同于 IAAS 提供了计算资源之外，还提供应用运营必须的公用域名管理、负载均衡、健康检查、部署槽、APIM 集成、日志流管理等整套应用技术运营方案。</li></ul><p>以搭建应用服务为目标，使用 App service 相比 VM、Container apps、AKS，在基础设施的触点和灵活度相对不足，并且着眼点是整包的应用服务，因此更适合于没有整体企业技术架构、不使用微服务的单体应用的搭建运营。</p><p>当应用可能面临外部变化、业务扩张增长，当前想要保留应用架构未来的可选择性、延迟当前服务架构类型的选型，建议使用 App service 时选择 docker 方式部署。这样，除了可以最大程度的避免环境差异以外，在未来架构扩张到需要放弃 App service 部署方式时，迁移到 VM、K8S、或者其他云提供商上时，应用服务在代码变更上可以花费最小的成本。</p><p>下面的步骤，就是通过 App service docker 方式部署。</p><h3 id="1-创建-Azure-资源服务">1. 创建 Azure 资源服务</h3><h4 id="1-1-创建-Azure-Container-Registry">1.1 创建 Azure Container Registry</h4><p>打开 Azure portal，创建 ACR。<br><img src="/2023/09/01/shi-yong-github-workflow-zi-dong-fa-bu-azure-cr-he-bu-shu-azure-app-service/create_acr.png" alt="create acr"></p><p>接着需要开启 ACR 的 admin 权限。<br>可以选择两种方式：直接打开 ACR admin，或者生成拥有 ACR admin 权限的 token。<br>建议使用 ACR admin token，相比于直接开启”服务唯一“的 ACR admin 凭证，admin token 可以创建多个，每个 token 独立设置过期时间、轮换以及失效管理。<br>下面是使用 Azure portal 创建 admin token。<br><img src="/2023/09/01/shi-yong-github-workflow-zi-dong-fa-bu-azure-cr-he-bu-shu-azure-app-service/create_acr_token_01.png" alt="create token"></p><p>生成 token 的 password。<br><img src="/2023/09/01/shi-yong-github-workflow-zi-dong-fa-bu-azure-cr-he-bu-shu-azure-app-service/create_acr_token_02.png" alt="create token"></p><h4 id="1-2-创建-Azure-appservice-plan">1.2 创建 Azure appservice plan</h4><p>这里使用azure cli 命令行创建。</p><pre class="line-numbers language-none"><code class="language-none">$ az appservice plan create \   --name &lt;MY_APP_SERVICE_PLAN_NAME&gt; \   --resource-group &lt;MY_RESOURCE_GROUP&gt; \   --is-linux <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>默认创建出的 SKU tier 是 Basic 的，不支持 deployment slot.<br>Standard tier 以上是支持 deployment slot，可以在 plan 创建之后 scale up.</p><h4 id="1-3-创建-Azure-appservice">1.3 创建 Azure appservice</h4><pre class="line-numbers language-none"><code class="language-none">$ az webapp create \    --name &lt;MY_WEBAPP_NAME&gt; \    --plan &lt;MY_APP_SERVICE_PLAN_NAME&gt; \    --resource-group &lt;MY_RESOURCE_GROUP&gt; \    --deployment-container-image-name &lt;nginx:latest&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在 ACR 中还没有自建的 docker 物料时，可以使用通用的 nginx image 进行初始化，后面使用 github workflow 时会自动更新 image 设置。</p><h3 id="2-配置机密信息">2. 配置机密信息</h3><h4 id="2-1-下载-appservice-publish-profile">2.1 下载 appservice_publish_profile</h4><p><img src="/2023/09/01/shi-yong-github-workflow-zi-dong-fa-bu-azure-cr-he-bu-shu-azure-app-service/download_appservice_publish_profile.png" alt="download appservice publish profile"></p><h4 id="2-2-在-GITHUB-repo-将-appservice-publish-profile-配置成-secrets">2.2 在 GITHUB repo 将 appservice_publish_profile 配置成 secrets</h4><p><img src="/2023/09/01/shi-yong-github-workflow-zi-dong-fa-bu-azure-cr-he-bu-shu-azure-app-service/configure_appservice_publish_profile.png" alt="configurate appservice publish profile"></p><h4 id="2-3-在-GITHUB-repo-secrets-配置-Azure-CR-的账号信息">2.3 在 GITHUB repo secrets 配置 Azure CR 的账号信息</h4><p>相同方式在 GITHUB repo 里配置 secrets：<code>DOCKER_REGISTRY_SERVER_USERNAME</code> 和 <code>DOCKER_REGISTRY_SERVER_PASSWORD</code>， 内容分别是 ACR admin token 的 name 和 password。<br>在后面 GITHUB workflow 脚本中会使用这两个机密对。</p><h3 id="3-配置-GITHUB-workflow-文件">3. 配置 GITHUB workflow 文件</h3><p>在 GITHUB repo 添加 .github/workflows/&lt;file_name&gt;.yml 文件，内容可参考：</p><pre class="line-numbers language-none"><code class="language-none"># Docs for the Azure Web Apps Deploy action: https://github.com/Azure/webapps-deploy# More GitHub Actions for Azure: https://github.com/Azure/actions# More info on Python, GitHub Actions, and Azure App Service: https://aka.ms/python-webapps-actionsname: Latest build and deploy Python app to Azure Web Appenv:  AZURE_WEBAPP_NAME: &lt;APPSERVICE_NAME&gt;  CR_REPO_HOST: &lt;CRNAME&gt;.azurecr.ioon:  push:    branches:      - releasepermissions:  contents: 'read'  packages: 'write'jobs:  build:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v3      - name: Set up Docker Buildx        uses: docker/setup-buildx-action@v2      - name: Log in to Azure container registry        uses: docker/login-action@v2        with:          registry: ${{ env.CR_REPO_HOST }}          username: ${{ secrets.DOCKER_REGISTRY_SERVER_USERNAME }}          password: ${{ secrets.DOCKER_REGISTRY_SERVER_PASSWORD }}      - name: Lowercase the repo name        run: echo "REPO=${GITHUB_REPOSITORY,,}" &gt;&gt;${GITHUB_ENV}      - name: Build and push container image to registry        uses: docker/build-push-action@v4        with:          push: true          tags: ${{ env.CR_REPO_HOST }}/${{ env.REPO }}:${{ github.sha }}          file: ./Dockerfile  deploy:    runs-on: ubuntu-latest    needs: build    environment:      name: 'Production'      url: ${{ steps.deploy-to-webapp.outputs.webapp-url }}    steps:      - name: Lowercase the repo name        run: echo "REPO=${GITHUB_REPOSITORY,,}" &gt;&gt;${GITHUB_ENV}      - name: Deploy to Azure Web App        id: deploy-to-webapp        uses: azure/webapps-deploy@85270a1854658d167ab239bce43949edb336fa7c        with:          app-name: ${{ env.AZURE_WEBAPP_NAME }}          publish-profile: ${{ secrets.AZURE_WEBAPP_PUBLISH_PROFILE_PROD }}          images: '${{ env.CR_REPO_HOST }}/${{ env.REPO }}:${{ github.sha }}'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-开启-application-logging">4. 开启 application logging</h3><h4 id="4-1-使用-Appservice-的-file-logging">4.1 使用 Appservice 的 file logging</h4><p>App service 默认是不开启 application logging 的，即使代码中配置了 logging config。<br>需要在 App service 中打开：<br><img src="/2023/09/01/shi-yong-github-workflow-zi-dong-fa-bu-azure-cr-he-bu-shu-azure-app-service/app_service_application_logging.png" alt="app service logging"></p><p>这时，在【 Monitoring 】-&gt;【Log stream】才会出现应用的 application log。<br>除了 Log stream 这种方式外，也可以通过浏览器访问网页<code>https://&lt;your_appservice_name&gt;.scm.azurewebsites.net/DebugConsole</code> 来查看 logs。<br><img src="/2023/09/01/shi-yong-github-workflow-zi-dong-fa-bu-azure-cr-he-bu-shu-azure-app-service/app_service_scm_debugconsole.png" alt="app service scm debug console"></p><h4 id="4-2-接入-Log-analytics-workspace">4.2 接入 Log analytics workspace</h4><p>App service 的日志和指标可以发送和接入到 Azure 的其他服务中，比如 Log analytics workspace，用以支持语句查找和分析。</p><p>需要在 App service 处进行配置【Diagnostic setting】，用以开启日志数据发送。<br><img src="/2023/09/01/shi-yong-github-workflow-zi-dong-fa-bu-azure-cr-he-bu-shu-azure-app-service/app_service_logging.png" alt="app service logging"></p><p>可以选择日志类型和勾选指标，日志数据的目标也可以复选 —— 发送 Log analytics workspace / event hub / partner solution 以及 保存到 storage account（Azure 存储账户）。<br><img src="/2023/09/01/shi-yong-github-workflow-zi-dong-fa-bu-azure-cr-he-bu-shu-azure-app-service/app_service_logging_config.png" alt="app service logging config"></p><p><strong>Log analytics workspace</strong> 中进行日志搜索：<br><img src="/2023/09/01/shi-yong-github-workflow-zi-dong-fa-bu-azure-cr-he-bu-shu-azure-app-service/log_analytics_workspace.png" alt="log analytics workspace"></p>]]></content>
      
      
      <categories>
          
          <category> Azure </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Azure </tag>
            
            <tag> 云平台 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Azure Administrator Associate 考试知识点</title>
      <link href="/2023/05/30/azure-administrator-associate-zhi-shi-dian/"/>
      <url>/2023/05/30/azure-administrator-associate-zhi-shi-dian/</url>
      
        <content type="html"><![CDATA[<p>Azure Administrator Associate 涉及五个知识块，下面是官方考证角度给出的清单：<br><img src="/2023/05/30/azure-administrator-associate-zhi-shi-dian/study_area.png" alt="Azure Administrator Associate Study Area"></p><h2 id="Azure-Administrator-Associate-知识图谱">Azure Administrator Associate 知识图谱</h2><div class="markmap-container" style="height:800px">  <svg data="{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[0,1]},&quot;v&quot;:&quot;Azure Administrator Associate&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[1,2]},&quot;v&quot;:&quot;Azure Basics&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[2,3]},&quot;v&quot;:&quot;Identities and governance&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[3,4]},&quot;v&quot;:&quot;Azure Active Directory&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[4,5]},&quot;v&quot;:&quot;Tenant &amp;amp; Directory&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[5,6]},&quot;v&quot;:&quot;User &amp;amp; Group&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[6,7]},&quot;v&quot;:&quot;Azure RBAC Role &amp;amp; Azure AD Administrator Role&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[7,8]},&quot;v&quot;:&quot;Administractive Unit / Device and so on&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[8,9]},&quot;v&quot;:&quot;Azure AD connect&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[9,10]},&quot;v&quot;:&quot;Resources&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[10,11]},&quot;v&quot;:&quot;Management Group&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[11,12]},&quot;v&quot;:&quot;Subscription&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[12,13]},&quot;v&quot;:&quot;Resource Group&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[13,14]},&quot;v&quot;:&quot;Resource&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[14,15]},&quot;v&quot;:&quot;Resource Manage Tools&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[15,16]},&quot;v&quot;:&quot;Azure Portal&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[16,17]},&quot;v&quot;:&quot;Azure Cloud shell&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[17,18]},&quot;v&quot;:&quot;Azure Powershell&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[18,19]},&quot;v&quot;:&quot;Azure CLI&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[19,20]},&quot;v&quot;:&quot;ARM Template&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[20,21]},&quot;v&quot;:&quot;Networking&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[21,22]},&quot;v&quot;:&quot;Virtual Networks&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[22,23]},&quot;v&quot;:&quot;IP Addressing&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[23,24]},&quot;v&quot;:&quot;public IP &amp;amp; private IP&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[24,25]},&quot;v&quot;:&quot;Network Security&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[25,26]},&quot;v&quot;:&quot;Network Security Group&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[26,27]},&quot;v&quot;:&quot;Application Security Group&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[27,28]},&quot;v&quot;:&quot;Azure Firewall&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[28,29]},&quot;v&quot;:&quot;Azure DNS&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[29,30]},&quot;v&quot;:&quot;Network expand&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[30,31]},&quot;v&quot;:&quot;VNet Peering&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[31,32]},&quot;v&quot;:&quot;VPN Gateway&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[32,33]},&quot;v&quot;:&quot;VPN transit for VNet Peering&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[33,34]},&quot;v&quot;:&quot;Site-to-Site VPN Connections&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[34,35]},&quot;v&quot;:&quot;Point-to-Site VPN Connections&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[35,36]},&quot;v&quot;:&quot;ExpressRoute&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[36,37]},&quot;v&quot;:&quot;Network Traffic&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[37,38]},&quot;v&quot;:&quot;Route Table&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[38,39]},&quot;v&quot;:&quot;Service Endpoint&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[39,40]},&quot;v&quot;:&quot;Load Balancer&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[40,41]},&quot;v&quot;:&quot;Application Gateway&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[41,42]},&quot;v&quot;:&quot;Traffic Manager&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[42,43]},&quot;v&quot;:&quot;Storage&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[43,44]},&quot;v&quot;:&quot;Azure storage account&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[44,45]},&quot;v&quot;:&quot;Azure storage services&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[45,46]},&quot;v&quot;:&quot;Azure Container&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[46,47]},&quot;v&quot;:&quot;Azure Files&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[47,48]},&quot;v&quot;:&quot;Azure Tables&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[48,49]},&quot;v&quot;:&quot;Azure Queues&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[49,50]},&quot;v&quot;:&quot;Replication Strategies&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[50,51]},&quot;v&quot;:&quot;Locally redundant storage (LRS)​&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[51,52]},&quot;v&quot;:&quot;Zone-redundant storage (ZRS)​&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[52,53]},&quot;v&quot;:&quot;Geo-redundant storage (GRS)​&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[53,54]},&quot;v&quot;:&quot;Read access geo-redundant storage (RA-GRS)​&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[54,55]},&quot;v&quot;:&quot;Geo-zone-redundant storage (GZRS)​&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[55,56]},&quot;v&quot;:&quot;Read-access Geo-zone- redundant storage (RA-GZRS)​&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[56,57]},&quot;v&quot;:&quot;Storage Security&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[57,58]},&quot;v&quot;:&quot;Shared Access Signatures&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[58,59]},&quot;v&quot;:&quot;Storage Service Encryption&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[59,60]},&quot;v&quot;:&quot;Managing Storage&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[60,61]},&quot;v&quot;:&quot;Storage Explorer&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[61,62]},&quot;v&quot;:&quot;Import and Export Service&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[62,63]},&quot;v&quot;:&quot;Data Box&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[63,64]},&quot;v&quot;:&quot;AzCopy&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[64,65]},&quot;v&quot;:&quot;Compute&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[65,66]},&quot;v&quot;:&quot;Virtual Machine&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[66,67]},&quot;v&quot;:&quot;Virtual Machine&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[67,68]},&quot;v&quot;:&quot;Virtual Machine Extensions&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[68,69]},&quot;v&quot;:&quot;VM Availability Sets&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[69,70]},&quot;v&quot;:&quot;VM Scale Sets&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[70,71]},&quot;v&quot;:&quot;Azure App Service&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[71,72]},&quot;v&quot;:&quot;Container Services&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[72,73]},&quot;v&quot;:&quot;Azure Kubernetes Service&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[73,74]},&quot;v&quot;:&quot;Monitor and backup&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[74,75]},&quot;v&quot;:&quot;backup&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[75,76]},&quot;v&quot;:&quot;Azure Backup&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[76,77]},&quot;v&quot;:&quot;Recovery Service Vault Backup&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[77,78]},&quot;v&quot;:&quot;Monitor&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[78,79]},&quot;v&quot;:&quot;Azure monitor&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[79,80]},&quot;v&quot;:&quot;Azure alert&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[80,81]},&quot;v&quot;:&quot;Log Analytics&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[81,82]},&quot;v&quot;:&quot;Network Watcher&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[82,83]},&quot;v&quot;:&quot;Diagnostics&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[83,84]},&quot;v&quot;:&quot;IP Flow Verify&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[84,85]},&quot;v&quot;:&quot;Next Hop&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[85,86]},&quot;v&quot;:&quot;VPN troubleshoot&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[86,87]},&quot;v&quot;:&quot;NSG diagnostics&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[87,88]},&quot;v&quot;:&quot;Connection troubleshoot&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[88,89]},&quot;v&quot;:&quot;Packet capture&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[89,90]},&quot;v&quot;:&quot;Effective security rules&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[90,91]},&quot;v&quot;:&quot;Topology&quot;}]}]}]}]}"></svg></div><h2 id="Azure-Basics">Azure Basics</h2><h3 id="1-Identities-and-governance">1. Identities and governance</h3><p><code>Azure Active Directory</code> 提供了一套基于云的标识管理的完整解决方案。<br>在创建租户时，会同时创建 Directory（目录），Azure Active Directory 对目录进行管理，功能上既有基础的<code>身份管理和验证</code>、<code>单点登录</code>、<code>多因认证</code>，也有进阶一点的<code>设备管理</code>、<code>管理单元</code>、<code>应用管理</code>，同时还有支持 Azure AD 与 on-premises 的 Active Directory Domain Service（即 AD DS） 的混合标识方案等等。</p><h4 id="1-1-AAD-目录-资源层级对应关系">1.1 AAD 目录-资源层级对应关系</h4><p><img src="/2023/05/30/azure-administrator-associate-zhi-shi-dian/basic_structure.png" alt="AAD 目录-资源层级图"></p><ol><li>目录对租户下的用户、组等进行管理。</li><li>一个目录可以被多个订阅所信任，但一个订阅仅能关联一个目录、不能关联多个。目录使多租户之间信息、资源独立。</li><li>订阅对资源进行集中管理，包括逻辑层级 Resource Group 以及各种 Resource。订阅为资源提供统一的账单和结算，同时与其他订阅相互隔离。</li><li>想要跨订阅进行一致的访问、策略等管理时，使用 management group(管理组) 实现。管理组层级可以按照组织部门进行创建，最多支持纵向深度 6 层。</li></ol><h4 id="1-2-Role-Based-Access-Control">1.2 Role-Based Access Control</h4><p>基于角色的访问控制 (RBAC) 是一种可帮助管理谁可以访问 Azure 资源的机制。 通过 RBAC，可以确定特定用户针对特定资源可以执行的操作，并控制每个用户可以访问的资源区域。<br>在 Azure 中分为：对“订阅资源”的访问授权 和 “Azure AD”的访问授权两类。对“订阅资源”的授权机制即 Azure RBAC(下图)。<br>下图描述了 Role-Based Access Control 中的四个核心概念：<code>Security Principle</code>(安全主体)  、<code>Role definition</code>(角色定义)    、<code>Scope</code>(范围)  、<code>Role Assignment</code>(分配)。<br><img src="/2023/05/30/azure-administrator-associate-zhi-shi-dian/RBAC.png" alt="Azure RBAC 机制"></p><ol><li>Security principle 即可以是单独的 User，也可以是 某个 Group，也可以是 Service Principle。</li><li>Role definition，可以是 Azure 预定义的，也可以依据 角色定义模板的格式 进行用户自定义。</li><li>Scope 可以涉及多层级，从范围最广的管理组，到粒度更细的具体资源。</li><li>Role Assignment，即是绑定上面 3 项的关系，以完成针对具体 Service Principle - Role（permission）- Scope 的授权。</li></ol><p>其中<code>角色定义</code>的格式，由 JSON 文件中定义的权限集组成。 其中描述权限集的结构不限于：</p><ul><li><code>Actions</code> 允许的权限操作。</li><li><code>NotActions</code> 不允许执行的权限操作。</li><li><code>DataActions</code> 指示如何更改或使用数据。</li><li><code>AssignableScopes</code> 可以分配角色定义的范围。<br><img src="/2023/05/30/azure-administrator-associate-zhi-shi-dian/role_definition.png" alt="Role definition"></li></ul><p>Azure RBAC Roles 提供了100 多种预定义的角色定义，其中包括四个基本的内置角色定义，以及其他根据各资源服务进行特别控制的角色定义。<br>下图是四个基本角色：<code>Owner</code>、<code>Contributor</code>、<code>Reader</code>、<code>User Access Administrator</code>。<br><img src="/2023/05/30/azure-administrator-associate-zhi-shi-dian/basic_roles.png" alt="Azure RBAC Basic Roles"></p><p><strong>Azure AD Roles:</strong><br>除了 Azure RBAC Roles 之外，还有另一类 Azure AD Roles，也是基于 Role-Based Access Control 机制，区别主要是 Scope 涉及 AD 的对象和资源。<br><img src="/2023/05/30/azure-administrator-associate-zhi-shi-dian/AD_access_control.png" alt="Azure AD Roles"></p><h4 id="1-3-RBAC-Authentication">1.3 RBAC Authentication</h4><p><img src="/2023/05/30/azure-administrator-associate-zhi-shi-dian/AAD_structure.png" alt="RBAC Authentication"><br>注意上面整体模型中两类 Roles —— Azure AD Roles 和 Azure RBAC Roles 的作用范围。<br>默认情况下，Azure Roles 与 Azure AD Roles 不会跨越 Azure 与 Azure AD 的 Scope 边界。 但是，如果全局管理员通过在 Azure 门户中选择“Azure 资源的访问管理”开关，提升了自己的访问权限，则会针对特定租户的所有订阅为全局管理员授予<code>User Access Administrator</code>（用户访问管理员角色）。 用户访问管理员角色可以向其他用户授予对 Azure 资源的访问权限。<br>因此，Global Administrator 本身只是 Azure AD 的最高权限角色，本身并不涵盖对 Azure 资源的权限。<br>能对 Azure 资源进行权限分配 的 Global Administrator 的 User， 一般是进行了“权限提升”，或者该 User 本身是某个 Subscription 的 Owner。</p><h3 id="2-Resources">2. Resources</h3><p>Azure 针对资源的管理层级（包括逻辑层级），从上至下一共分为：<code>管理组</code>、<code>订阅</code>、<code>资源组</code>、<code>资源</code>。<br>管理组、订阅、资源组都有单独的 Service 页面进行设置和使用。</p><h4 id="2-1-Policy">2.1 Policy</h4><p>Azure Policy 是 Azure 中的一项服务，可用于创建、分配和管理策略，用于控制或审核资源。 这些策略对资源配置强制实施不同的规则，使这些配置符合组织标准和合规性要求。<br>Azure Policy 可以被分配和作用于多个层级。<br>Policy 的使用有四个步骤：</p><ul><li>定义<code>Policy</code>（策略）。</li><li>定义<code>initiative</code>(官方翻译：计划)，是 Policy 的集合。</li><li>创建<code>Assignments</code>。</li><li>确定<code>Compliance</code>。<br>Azure 预设了一些 Policy 和 Initiative，可以直接用来创建 Assignment；也可以自定义一些 Policy 和 Initiative。<br>Policy 和 Initiative 在定义的时候创建了一些参数，可以在创建 Assignments 的时候设置和传入参数值。<br>比如：创建了一个 XX_Initiative，其中包含了 <code>Allowed locations</code> 的 Policy，此 policy 声明了入参 <code>listOfAllowedLocations</code>。在创建 Assignments 时，<br>可以指定限定的 location 值。<br>Policy - Initiative - Assignment 创建完，待合规性检查执行完成后，可以通过<code>Compliance</code> 页面确定合规性检查的结果。<br><img src="/2023/05/30/azure-administrator-associate-zhi-shi-dian/compliance.png" alt="Policy Compliance"></li></ul><h4 id="2-2-Lock">2.2 Lock</h4><p>锁，跟 Policy 不同，可以被设置的级别是：订阅、资源组、资源。锁会被继承、影响子范围内的所有资源。<br>锁类型分两种：delete 和 read-only。</p><ul><li>被 delete 锁住的资源，不能删除，除非先删除 delete 锁。</li><li>被 read-only 锁住的资源，不能被变更，除非先删除锁。<br>注意，这里的变更针对资源的元数据，不包括资源管理的内容。比如 read-only 设置在数据库资源上，数据库管理的数据是依然可以读写删，但数据库设置则不能变更，比如 <code>reset password</code>、添加 tag 等等。</li></ul><h4 id="2-3-Tag">2.3 Tag</h4><p>标签，是一种标记符号，主要用来查询、过滤资源。<br>标签在资源层级之间<code>不能继承</code>。也就是说，资源组打上了 Tag，如果需要给资源组内所有资源打上相同 Tag 的话，有两种方式：</p><ol><li>手动给资源分别加上 Tag。</li><li>给该资源组分配 Append tag 的 Policy，这样可以通过 Policy 给资源加上相同的 Tag。</li></ol><h4 id="2-4-IAM">2.4 IAM</h4><p>每个服务的 IAM 页签，是用来配置访问授权的位置。也就是针对当前资源服务管理 Azure RABC Role assignment 的地方。<br>访问授权在不同资源层级之间是可以继承的。意思是，如果给某个管理组设置了 owner，这个 owner 会被管理组下的每一个资源服务识别为 Owner。</p><h3 id="3-Resource-Manage-Tools">3. Resource Manage Tools</h3><h4 id="3-1-Tools">3.1 Tools</h4><p>对资源的管理和使用，Azure 提供了多种资源管理终端：</p><ul><li><code>Azure Portal</code>，Azure 门户网站页面。</li><li><code>Azure Cloud Shell</code>，通过 Azure 门户进入，一种通过浏览器界面显示、可与 Azure 资源交互的 shell命令工具。Cloud Shell 按会话分配临时的主机作为操作机，使用文件共享中保存的 5 GB 映像持久保存 $HOME，并在用户 20 分钟内没有交互活动时 shell 连接会超时。</li><li><code>Azure PowerShell</code>，安装了 Azure module 的 PowerShell 工具。</li><li><code>Azure cli</code>，Azure 提供的命令行工具。</li></ul><p>各种终端除了交互方式以外，功能上基本没有什么不同，背后都是连接 ARM（Azure 资源管理器）。<br><img src="/2023/05/30/azure-administrator-associate-zhi-shi-dian/ARM.png" alt="ARM"></p><p>针对 “执行频率和重复性不高、量小的 Azure 运维任务”，可以通过 Azure Portal 进行偶尔操作。<br>但对于自动化、重复性高的运维任务来说，使用 Azure Powershell 和 Azure Cli 通过命令行脚本是更高效和可靠的方式。</p><p>Azure PowerShell 示例：(ConferenceDailyReset.ps1)</p><pre class="line-numbers language-none"><code class="language-none">param([string]$resourceGroup)$adminCredential = Get-Credential -Message "Enter a username and password for the VM administrator."For ($i = 1; $i -le 3; $i++){    $vmName = "ConferenceDemo" + $i    Write-Host "Creating VM: " $vmName    New-AzVm -ResourceGroupName $resourceGroup -Name $vmName -Credential $adminCredential -Image Canonical:0001-com-ubuntu-server-focal:20_04-lts:latest}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行脚本文件：</p><pre class="line-numbers language-none"><code class="language-none">./ConferenceDailyReset.ps1 learn-3bd98a6a-c556-42bf-975b-81bcc3e53962<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="3-2-Azure-Resouce-Manager-Template">3.2 Azure Resouce Manager Template</h4><p>Azure 资源管理器模板（ARM 模板）实现<code>infrastructure as code</code> （基础结构即代码）。<br>ARM 模板使用声明性语法、JSON 文件格式，定义部署的基础结构和配置。<br>ARM 模板文件由下列元素组成：<br><img src="/2023/05/30/azure-administrator-associate-zhi-shi-dian/ARM_template_elements.png" alt="ARM template elements"></p><p>示例：(azuredeploy.json)</p><pre class="line-numbers language-none"><code class="language-none">{  "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",  "contentVersion": "1.0.0.0",  "parameters": {    "storageName": {      "type": "string",      "minLength": 3,      "maxLength": 24,      "metadata": {        "description": "The name of the Azure storage resource"      }    },    "storageSKU": {      "type": "string",      "defaultValue": "Standard_LRS",      "allowedValues": [        "Standard_LRS",        "Standard_GRS",        "Standard_RAGRS",        "Standard_ZRS",        "Premium_LRS",        "Premium_ZRS",        "Standard_GZRS",        "Standard_RAGZRS"      ]    }  },  "functions": [],  "variables": {},  "resources": [    {      "name": "[parameters('storageName')]",      "type": "Microsoft.Storage/storageAccounts",      "apiVersion": "2019-06-01",      "tags": {        "displayName": "[parameters('storageName')]"      },      "location": "[resourceGroup().location]",      "kind": "StorageV2",      "sku": {        "name": "[parameters('storageSKU')]",        "tier": "Standard"      }    }  ],  "outputs": {    "storageEndpoint": {        "type": "object",        "value": "[reference(parameters('storageName')).primaryEndpoints]"    }  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将 ARM 模板部署到 Azure 有三种方式：</p><ul><li>部署本地模板</li><li>部署已链接的模板</li><li>在持续部署管道中进行部署</li></ul><p>使用 Azure CLI 命令 <code>az deployment group create</code> 或 A<code>zure PowerShell 命令 New-AzResourceGroupDeployment</code>。</p><pre class="line-numbers language-none"><code class="language-none">$ az login$ az account list --output table$ az account set --subscription &lt;subscription_name&gt;$ az group list --output table$ az configure --defaults group=&lt;resource_group&gt;$ templateFile="azuredeploy.json"$ today=$(date +"%d-%b-%Y")$ DeploymentName="addSkuParameter-"$today$ az deployment group create \  --name $DeploymentName \  --template-file $templateFile \  --parameters storageSKU=Standard_GRS storageName=&lt;your-unique-name&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Azure </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Azure </tag>
            
            <tag> 云平台 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Gradio&amp;huggingface快速搭建一个ChatGPT APP</title>
      <link href="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/"/>
      <url>/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/</url>
      
        <content type="html"><![CDATA[<p>在现在的NLP领域，GPT系列模型已经成为了NLP领域的标配之一，而ChatGPT是基于GPT的一个聊天模型，可以用来生成对话，其效果非常好，可以说是目前最好的开源聊天模型了。<br>不少使用者已经将ChatGPT当做了日常工作的助手，下面这个chat界面基本已经广为人知。<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/chatGPT_conversation.png" alt="ChatGPT会话界面"></p><p>但 ChatGPT 并不仅仅是支持以上的聊天会话功能，OpenAI 公司也开放了以上会话聊天背后的 API。</p><span id="more"></span><p>这些 API 可以直接调用，使用命令行（科学上网），也可以自己搭建服务器。<br>如果仅仅只是想使用 API 构建一个会话服务，或者 Generic 聊天机器人，专门搭建一个服务器没有什么特别大的意义。<br>但如果从学习和尝试构建 ChatGPT 应用的角度、从上手程度来衡量的话，Gradio + huggingface 不失为一种快速构建的方式。<br>Gradio 是一个可以快速搭建 Python web 的工具包，Huggingface 支持源码管理、 Gradio 应用的快速构建和部署。</p><h3 id="1-使用-ChatGPT-API-编程">1. 使用 ChatGPT API 编程</h3><h4 id="1-1-Python-OpenAI-lib-下载和安装">1.1 Python OpenAI lib 下载和安装</h4><p>在新建的工程目录下，安装 openAI lib。</p><pre class="line-numbers language-none"><code class="language-none">$ pipenv install openai# 或者使用 pip 工具安装，作者本人更偏爱 pipenv，因此 Python 文章里面都使用 pipenv 作为包管理和构建工具<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="1-2-针对-ChatGPT-API-编程">1.2 针对 ChatGPT API 编程</h4><p>在工程目录下编写Chatgpt工具文件<code>chatgpt_api.py</code>。</p><pre class="line-numbers language-none"><code class="language-none">class ChatgptAPI:    def __init__(self, api_key):        openai.api_key = api_key    def get_single_completion(self, prompt, model='gpt-3.5-turbo'):        messages = [{"role": "user", "content": prompt}]        response = openai.ChatCompletion.create(            model=model,            messages=messages,            temperature=0,            max_tokens=2048,            top_p=1,        )        return response.choices[0].message['content']<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>说明：</strong><br>提前创建OpenAI账号，生成API key（各种方法各显神通，这里不做赘述）。</p><p>在上面的代码中，我们使用了 OpenAI 提供的API，其中：</p><ul><li><code>openai.api_key</code> 需要赋值 OpenAI 官网上获取的 API key</li><li><code>openai.ChatCompletion.create</code>方法（背后就是 API Endpoint: /chat/completions）</li><li><code>gpt-3.5-turbo</code> 模型</li></ul><p>查阅过OpenAPI<a href="https://platform.openai.com/docs/api-reference">官方文档</a>，可以发现，OpenAI 提供了多种模型，可以根据自己的需求进行选择。<br>同时，不同API，支持和兼容不同的模型。<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/model_endpoint_compatibility.png" alt="model endpoint compatibility"></p><p>GPT 4 版本以下，较推荐的两个模型，一个是 <code>gpt-3.5-turbo</code>，另一个是 <code>text-davinci-003</code>。<br>这两个模型的区别在于：gpt-3.5-turbo 是一个通用的模型，而 text-davinci-003 是一个专门用于文本生成的模型。<br>但 gpt-3.5-turbo 的价格只有 text-davinci-003 的 1/10, 同时响应速度也比 text-davinci-003 更快。<br>因此，gpt-3.5-turbo 是一个性能良好且相对经济实惠的GPT模型版本，适用于许多自然语言处理任务，它提供快速的响应时间和高质量的文本生成能力。<br>相比之下，Text-davinci-003 更适合对生成文本质量要求更高、且对响应时间要求相对较低的应用场景。</p><p><strong>下面是官方对于3.5版本的模型的对比</strong>：<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/models.png" alt="GPT-3.5 models"></p><h4 id="1-3-Max-Tokens">1.3 Max Tokens</h4><p>在上面的模型对比图中，会注意到有一个<code>Max Tokens</code>的概念。</p><ul><li>首先，Tokens 本身是文本处理时进行分词的最小单位，同时也是ChatGPT报价收费的最小单位。<br>比如，gpt-3.5-turbo 价格是 $0.002 / 1K tokens，text-davinci-003 则是 $0.0200 / 1K tokens。这种收费方式看起来，跟以太坊的 GAS 比较相像。</li><li>另外，模型中的 Max Tokens 是指，每次请求的最大 tokens 数量，也就是说，会限制文本的最大长度。<br>但需要注意的是：每次请求的Max Tokens = User 请求的Tokens + AI assistant 响应的Tokens。也就意味着，如果用户请求的文本长度过长，受Max Tokens的限制，留给AI生成的 Token数量会很少，从而导致请求失败。</li></ul><p>因此，对于用户而言，Max Tokens 的限制会造成两方面的考虑：</p><ul><li>一次请求的最大文本长度，防止文本过长，造成请求失败。</li><li>处理多轮会话的策略。GPT API并不会帮助客户端缓存上下文，两次API请求之间是完全独立的，因此需要客户端自己来处理多轮会话的上下文。<br>每次请求的内容，都需要包含之前请求的文本上下文，受Max Tokens限制，对话轮数越多，请求中用户输入的文本占比就会越高，留给AI生成的Token余量就会越少。</li></ul><p>代码中针对这两项考虑，可做如下处理（且不限此方式）：</p><ul><li>设置API的 max_tokens参数，这里限制的是AI生成的Token最大数。除AI生成的Max Tokens外，请求 + 响应中总的 Max Tokens 受模型类型限制。</li><li>创建会话上下文类型（比如 Conversation），用以保存和传递多轮会话的上下文。</li></ul><pre class="line-numbers language-none"><code class="language-none">class ChatgptAPI:    ……    def get_multi_round_completion(self, prompt, conversation, model='gpt-3.5-turbo'):        conversation.append_question(prompt)        prompts = conversation.get_prompts()        response = openai.ChatCompletion.create(            model=model,            messages=prompts,            temperature=0,            max_tokens=2048,            top_p=1,        )        message = response.choices[0].message['content']        conversation.append_answer(message)        return message, conversationclass Conversation:    def __init__(self, system_prompt='', num_of_round = 5):        self.num_of_round = num_of_round        self.history = []        self.initialized = False        self.history.append({"role": "system", "content": system_prompt})        if len(system_prompt) &gt; 0:            logger.info(f'Conversation initialized with system prompt: {system_prompt}')            self.initialized = True    def is_initialized(self):        return self.initialized        def append_question(self, question):        self.history.append({"role": "user", "content": question})    def append_answer(self, answer):        self.history.append({"role": "assistant", "content": answer})        if len(self.history) &gt; self.num_of_round * 2:            del self.history[1:3]    def clear(self):        self.history.clear()        self.initialized = False    def get_prompts(self):        return self.history        def round_size(self):        return 0 if len(self.history) &lt; 2 else len(self.hitory) - 1        def get_history_messages(self):        return [(u['content'], b['content']) for u,b in zip(self.history[1::2], self.history[2::2])]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里，我们将用户的请求文本和AI assistant的响应文本，都缓存到了<code>Conversation</code>类中。在每次请求时，将 Conversaction 中缓存的文本作为<code>prompt</code>传入，从而实现多轮会话的功能。<br>同时，我们还可以在<code>Conversation</code>类中增加一些其他的方法，比如设置缓存的最大轮数，超过最大轮数则从缓存中删除最早的会话记录。</p><h3 id="2-使用-Gradio-框架构建交互层">2. 使用 Gradio 框架构建交互层</h3><p>使用 Gradio 框架，可以快速构建一个交互式的Web应用，直接使用 Python 创建前端页面和交互。</p><h4 id="2-1-安装-Gradio">2.1 安装 Gradio</h4><p>在工程目录下，继续安装 Gradio lib 包。</p><pre class="line-numbers language-none"><code class="language-none">$ pipenv install gradio<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="2-2-编写-Web-代码">2.2 编写 Web 代码</h4><p>在工程目录下，创建一个名为<code>app.py</code>的文件，用于编写 Web 代码。</p><pre class="line-numbers language-none"><code class="language-none">import loggingimport osimport gradio as grfrom tools.chatGPT_API import Conversation, ChatgptAPIchat_api = ChatgptAPI(os.environ.get("OPENAI_API_KEY"))def predict(system_input, password_input, user_input, conversation):    if password_input != os.environ.get("APP_PASSWORD"):       return [(None, "Wrong password!")], conversation, user_input    if conversation.is_initialized() == False:        conversation = Conversation(system_input, 5)    _, conversation = chat_api.get_multi_round_completion(user_input, conversation)    return conversation.get_history_messages(), conversation, Nonedef clear_history(conversation):    conversation.clear()    return None, conversationwith gr.Blocks(css="#chatbot{height:350px} .overflow-y-auto{height:600px}") as demo:    chatbot = gr.Chatbot(elem_id="chatbot")    conversation = gr.State(value=Conversation())    with gr.Row():      system_in_txt = gr.Textbox(lines=1, label="System role content:", placeholder="Enter system role content")      password_in_txt = gr.Textbox(lines=1, label="Password:", placeholder="Enter password")           with gr.Row():      user_in_txt = gr.Textbox(lines=3, label="User role content:", placeholder="Enter text...").style(container=False)        with gr.Row():      submit_button = gr.Button("Submit")      reset_button = gr.Button("Reset")        submit_button.click(predict, [system_in_txt, password_in_txt, user_in_txt, conversation], [chatbot, conversation, user_in_txt])    reset_button.click(clear_history, [conversation], [chatbot, conversation], queue=False)demo.launch()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/Gradio_UI.png" alt="界面效果"><br><strong>说明:</strong><br>- 使用了 Gradio 的 Chatbot 组件，用于展示 User 请求文本和 AI assistant 的响应文本。<br>- 使用了 Gradio 的 State 组件，用于存储用户的 Conversaction 对象。<br>- 使用了 Gradio 的 Textbox 组件，用于用户输入系统提示文本、密码和请求文本。<br>- 使用了 Gradio 的 Button 组件，用于触发用户的请求。</p><p>详细 Gradio 入门可参考：<a href="https://gradio.app/getting_started">Gradio document</a></p><h3 id="3-提交和部署到-Huggingface">3. 提交和部署到 Huggingface</h3><h4 id="3-1-创建-Huggingface-Space">3.1 创建 Huggingface Space</h4><p>在 Huggingface 上创建 Space，步骤基本跟创建 Github 的Repository一样。<br>并且，需要选择 Space 部署时</p><ul><li>Space SDK：Gradio</li><li>Space Hardware：有免费的<code>CPU</code>和付费的<code>GPU</code>可选<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/create_space_in_hugging_face.png" alt="Create Space"></li></ul><h4 id="3-2-设置环境变量">3.2 设置环境变量</h4><p>在 Space 中，需要设置环境变量，用于存储 OpenAI API Key 和 Web App 的密码(为了防止后面App bublic之后，API Key 被滥用)。<br>Gradio 启动时，会从环境变量中加载这些值。<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/new_repository_secrets.png" alt="Set Environment Variables"></p><h4 id="3-3-提交代码到-Huggingface-Space">3.3 提交代码到 Huggingface Space</h4><p>选择将 Space 的 Repository 用 git clone 到本地，使用方法跟 Github 一样。<br>然后，将前面两节编写的代码通过 git push 到 Huggingface，Huggingface 会自动完成构建，并部署 Web App。<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/build_space.png" alt="build App"></p><p>构建完成以后，Web App 会直接显示在 Huggingface Space的页面上。<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/chat_web_app.png" alt="Chat Web App"></p><h4 id="3-4-设置-Space-visibility-Public">3.4 设置 Space visibility Public</h4><p>如果在创建 Space 时，选择了将 Visibility 设置为 Private，那么只有 Space 的 Owner 和 Collaborator 才能访问到 Web App。<br>同时，也没有办法通过该 Space 的 URL 访问到 App。</p><p>若是想要其他人能通过 Space 的 URL 访问到 Web App，或者需要将 App 嵌入其他网站进行访问时，则需要将 Visibility 设置为 Public。<br>在设置成了 Public 之后，Space 的菜单会出现<code>Embed this Space</code>。<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/embed_space.png" alt="Embed this Space"><br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/embed_space_2.png" alt="Embed this Space"></p><p>根据上图的提示，将<code>&lt;script&gt;</code>和<code>&lt;gradio-app&gt;</code>标签复制到其他网站的 HTML 中，即可嵌入到其他网站中。<br>效果见后面。</p><h3 id="4-成果展示">4. 成果展示</h3><script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/3.29.0/gradio.js"></script><p><gradio-app src="https://ellendan-chat-lab.hf.space"></gradio-app></p><p>App 的 Password Input 需要输入作者个人微信号的号码，欢迎大家试用。<br>同时，由于 GPT API 的调用，有 Rate limits, API 每分钟的调用次数有限制，所以可能会出现无法响应的情况。</p><ul><li><code>RPM</code> - request per minute</li><li><code>TPM</code> - token per minute<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/rate_limits.png" alt="rate limits"></li></ul>]]></content>
      
      
      <categories>
          
          <category> ChatGPT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> ChatGPT </tag>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>反手回摸Oracle</title>
      <link href="/2022/08/22/fan-shou-hui-mo-oracle/"/>
      <url>/2022/08/22/fan-shou-hui-mo-oracle/</url>
      
        <content type="html"><![CDATA[<p>最后一次用 Oracle 应该还是在2012的时候，之后就一路用开源数据库。<br>没想到现在还有反手回摸的时候。<br>回摸也就算了，等准备好 Oracle 知识回顾，最后发现计划赶不上变化，暂时用不上了。<br>重新 review 了一把自己的kanban和计划清单，赶紧记录一下，回到目标的事务上去。</p><span id="more"></span><h3 id="1-MacOS-安装-Oracle">1. MacOS 安装 Oracle</h3><p>对于已经习惯了所有工具都要本地装一装、摸一摸的工程师而言，装个单例数据库这事儿自然不在话下。<br>然而search homebrew 和 dockerhub，突然发现 —— 居然没有oracle database。这不就尴尬了嘛？<br>去 Oracle 官网查看了一下，要想在 MacOS 上安装Oracle，两种方式：1. visualBox 2. 本地 dockerfile build。<br>那自然是选择2了。</p><h4 id="1-1-Oracle-官方dockerfile大合集">1.1. Oracle 官方dockerfile大合集</h4><p>访问 Oracle 官方在 github 上 repo <a href="https://github.com/oracle/docker-images">docker-images</a>。</p><pre class="line-numbers language-none"><code class="language-none">$ git clone git@github.com:oracle/docker-images.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>子目录是 Oracle 各种产品目录。比如database，就是 <code>OracleDatabase</code>, OGG 就是 <code>OracleGoldenGate</code>。</p><h4 id="1-2-查看-dockerfile">1.2. 查看 dockerfile</h4><p>进入到本地 repo 目录 <code>OracleDatabase/SingleInstance/dockerfiles</code>，可以看到目前支持的数据库版本：<br><img src="/2022/08/22/fan-shou-hui-mo-oracle/dockerfile_list.png" alt="dockerfile_list"><br>选择一个版本，比如 19.3.0，进入目录。</p><h4 id="1-3-下载-Linux-Oracle-Database-程序包">1.3. 下载 Linux Oracle Database 程序包</h4><p>可以查找官网，也可以通过 readme 文件上的链接跳入下载页面。<br>点击链接，手动下载。<br><img src="/2022/08/22/fan-shou-hui-mo-oracle/oracle_download_page.png" alt="download_page"><br>对，2.8G。</p><h4 id="1-4-将下载的database程序包移入OracleDatabase-SingleInstance-dockerfiles-19-3-0">1.4. 将下载的database程序包移入<code>OracleDatabase/SingleInstance/dockerfiles/19.3.0/</code></h4><p><img src="/2022/08/22/fan-shou-hui-mo-oracle/zip_into_directory.png" alt="zip into directory"></p><h4 id="1-5-运行buildContainerImage">1.5. 运行buildContainerImage</h4><p>回到<code>OracleDatabase/SingleInstance/dockerfiles</code>目录，运行命令<code>buildContainerImage.sh</code>。</p><pre class="line-numbers language-none"><code class="language-none">$ ./buildContainerImage.sh -h$ ./buildContainerImage.sh -v 19.3.0 -s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><em>注意</em> 运行命令build之前，确保本地没有开启任何网络代理，不然 build 时会失败。<br>build成功之后，通过<code>docker images</code>查看image，总大小6个多G，体量感人。。</p><p>另外，如果想要安装其他版本，比如18.4.0 和 xe 版本，相同的步骤和方式，但可能需要修改dockerfile的部分语句。<br>即使进行了dockerfile修改，xe 版本本人build并没有成功过，这个需要再次检验和查看。</p><h4 id="1-6-docker-run">1.6. docker run</h4><pre class="line-numbers language-none"><code class="language-none">docker run --name oracle19 -d -p 11521:1521 -p 15500:5500 -e ORACLE_PWD=123456 -v ~/tmp-oradata:/opt/oracle/oradata oracle/database/19.3.0-se2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这时候，通过docker host本地 11521 端口，就可以连接docker oracle了。</p><h3 id="2-Oracle-Database-基础概念和语句图谱">2. Oracle Database 基础概念和语句图谱</h3><div class="markmap-container" style="height:800px">  <svg data="{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[0,1]},&quot;v&quot;:&quot;Oracle Database&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[1,2]},&quot;v&quot;:&quot;数据库概念&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[2,3]},&quot;v&quot;:&quot;数据库&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[3,4]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[4,5]},&quot;v&quot;:&quot;查看当前数据库：select name from V$DATABASE;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[5,6]},&quot;v&quot;:&quot;数据库实例&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[6,7]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[7,8]},&quot;v&quot;:&quot;查看当前数据库实例：select name from V$INSTANCE;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[8,9]},&quot;v&quot;:&quot;SID&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[9,10]},&quot;v&quot;:&quot;CDB &amp;amp; PDB&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[10,11]},&quot;v&quot;:&quot;SQLPLUS&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[11,12]},&quot;v&quot;:&quot;tnsnames.ora&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[12,13]},&quot;v&quot;:&quot;sqlnet.ora&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[13,14]},&quot;v&quot;:&quot;连接&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[14,15]},&quot;v&quot;:&quot;sqlplus username/password@host:port/SID&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[15,16]},&quot;v&quot;:&quot;conn username/password&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[16,17]},&quot;v&quot;:&quot;用户/角色/权限&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[17,18]},&quot;v&quot;:&quot;用户&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[18,19]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[19,20]},&quot;v&quot;:&quot;创建用户：create user ogg identified by ogg default tablespace customer;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[20,21]},&quot;v&quot;:&quot;查询用户：select * from dba_users where lower(username)=‘ogg';&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[21,22]},&quot;v&quot;:&quot;删除用户：drop user ogg;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[22,23]},&quot;v&quot;:&quot;角色&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[23,24]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[24,25]},&quot;v&quot;:&quot;创建角色：create role etl;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[25,26]},&quot;v&quot;:&quot;查询角色：select * from DBA_ROLES;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[26,27]},&quot;v&quot;:&quot;角色授权（系统）：grant connect,resource,create session, alter session to etl;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[27,28]},&quot;v&quot;:&quot;角色授权（对象）：grant insert,update,delete on t_custmer to etl;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[28,29]},&quot;v&quot;:&quot;给用户添加角色：grant etl01 to ogg;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[29,30]},&quot;v&quot;:&quot;删除角色：drop role etl;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[30,31]},&quot;v&quot;:&quot;权限&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[31,32]},&quot;v&quot;:&quot;定义&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[32,33]},&quot;v&quot;:&quot;系统权限&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[33,34]},&quot;v&quot;:&quot;对象权限：指用户对已有对象的操作权限。&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[34,35]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[35,36]},&quot;v&quot;:&quot;系统权限&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[36,37]},&quot;v&quot;:&quot;查询系统权限：select distinct PRIVILEGE from DBA_SYS_PRIVS;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[37,38]},&quot;v&quot;:&quot;查询grantee拥有的权限：select * from DBA_SYS_PRIVS where lower(grantee)='ogg’;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[38,39]},&quot;v&quot;:&quot;给用户添加权限：grant create session,alter session to ogg;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[39,40]},&quot;v&quot;:&quot;收回权限：revoke alter session from ogg;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[40,41]},&quot;v&quot;:&quot;对象权限&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[41,42]},&quot;v&quot;:&quot;查询grantee用户的对象权限：select grantee, table_name, privilege from dba_tab_privs where lower(grantee) = ‘ogg’;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[42,43]},&quot;v&quot;:&quot;分配对象权限：grant all on t_employees to ogg;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[43,44]},&quot;v&quot;:&quot;收回权限：revoke delete on t_employees from ogg;&quot;}]}]}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[44,45]},&quot;v&quot;:&quot;逻辑结构&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[45,46]},&quot;v&quot;:&quot;数据库/表空间/表&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[46,47]},&quot;v&quot;:&quot;数据库&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[47,48]},&quot;v&quot;:&quot;SQL&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[48,49]},&quot;v&quot;:&quot;表空间&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[49,50]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[50,51]},&quot;v&quot;:&quot;创建表空间：CREATE TABLESPACE customer datafile '/opt/oracle/oradata/XE/customer.dbf' SIZE 100M autoextend on next 20M Maxsize 500M;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[51,52]},&quot;v&quot;:&quot;删除表空间：drop tablespace customer including contents and datafiles;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[52,53]},&quot;v&quot;:&quot;查看表空间数据文件：select file_name, tablespace_name from DBA_DATA_FILES order by FILE_NAME;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[53,54]},&quot;v&quot;:&quot;查看所有表空间：SELECT TABLESPACE_NAME, STATUS, ALLOCATION_TYPE, CONTENTS FROM DBA_TABLESPACES;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[54,55]},&quot;v&quot;:&quot;表&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[55,56]},&quot;v&quot;:&quot;用户/schema/对象&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[56,57]},&quot;v&quot;:&quot;用户&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[57,58]},&quot;v&quot;:&quot;SYS/SYSTEM&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[58,59]},&quot;v&quot;:&quot;SYS 是 SYSDBA。可创建数据库。&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[59,60]},&quot;v&quot;:&quot;SYSTEM 是 SYSOPER。权限次之。&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[60,61]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[61,62]},&quot;v&quot;:&quot;查看当前库下所有用户：select username,ACCOUNT_STATUS,DEFAULT_TABLESPACE, TEMPORARY_TABLESPACE from DBA_USERS;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[62,63]},&quot;v&quot;:&quot;schema&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[63,64]},&quot;v&quot;:&quot;定义&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[64,65]},&quot;v&quot;:&quot;Schema 是用户拥有的所有对象的集合。对象包括：表、索引、视图等等。&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[65,66]},&quot;v&quot;:&quot;每个用户都会有独立的schema，schema 必须依赖用户的存在而存在。&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[66,67]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[67,68]},&quot;v&quot;:&quot;查询当前用户和schema：select sys_context('userenv', 'current_user') current_user, sys_context('userenv', 'current_user') current_schema from dual;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[68,69]},&quot;v&quot;:&quot;对象&quot;}]}]}]}"></svg></div>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>聊聊研发效能治理方案的理论框架（下篇）</title>
      <link href="/2022/07/18/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-xia-pian/"/>
      <url>/2022/07/18/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-xia-pian/</url>
      
        <content type="html"><![CDATA[<p>已经过了一旬，下篇居然还没开始动笔。<br>反思了一下人生：P<br>书接上回。</p><span id="more"></span><h3 id="2-接上篇">2. 接上篇</h3><p>在上一节的健康度指标中，有非常重要的一项 —— Lead Time。<br>Lead Time 的定义来源于传统制造业，指从受订到出货之间间隔的时间。<br>同时，与Lead Time 一同被提起的，还有<code>"Cycle Time"</code>。 而 DevOps 的度量指标，习惯称其为<code>“Process time”</code>。<br>Cycle Time 和 Process Time, 在软件研发和 DevOps 领域基本相互等同，主要指去掉排队等待时长，处于生产任务（增值活动）执行的时长。</p><p>一定要谈下区别的话，对 DevOps 工具自动化来说，基本每个环节的执行动作都是可重复的、标准的，因此“单件”的 Process time 基本可以代表当前任务的生产性能。<br>位于 DevOps 之前的研发环节，每件制品包含知识类的创造、不是标准件、无法准确重复，因此在统计任务时长时（比如：In Dev processing, in QA processing）, 只能通过“多件”运算出均值，亦就是 Cycle time.<br><img src="/2022/07/18/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-xia-pian/lead&amp;cycle_time.png" alt="lead Time &amp; cycle time"></p><p>Lead Time 和 Cycle Time 是精益制造中重要的衡量指标。<br>自从精益生产在制造业获得成功之后，为了改善产品开发流程，软件研发行业也将精益思想引入到了产品研发之中。</p><h4 id="2-2-价值流分析和改进建议">2.2. 价值流分析和改进建议</h4><p>从研发效能来看，除了宏观的 lead time 的健康度之外，想要回答 lead time 为何会花费这么长时间、具体那些环节比较耗时、是否可以优化耗时时，就需要将研发工作流程打开来看一看。<br>想要理解和观察研发流程，有一个重要工具，就是 —— 价值流图（Value Stream Mapping， VSM）。</p><p>软件研发流程，是从需求构想到产品（或功能）发布上线的这个过程中，为了提供用户价值而采取的一系列研发活动。<br>价值流图，就是用来观察和分析价值在研发流程中流动的情况。<br>价值在整个流动的过程中，会经历增值活动、非增值但必要的活动（I型浪费）、以及非增值可以去掉的活动（II型浪费）。价值流图分析的目的，首先就是去掉 II 型浪费，然后再将 I 型浪费转化为 II 型浪费从而消除。<br><img src="/2022/07/18/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-xia-pian/vsm.png" alt="VSM"></p><p><em>也许有人会认为，上图中 QA 进行测试、Ops 进行发布，这些怎么能看做是增值行为呢？这主要是因为，不能只是从代码即是生产的角度去看待软件研发。<br>软件研发，其实是一种知识型的创造活动，虽然这些知识最终是通过代码的形式固化下来的。这种知识性的创造活动，包括PO、BA、Dev、QA、Ops所有角色的知识汇总。<br>这也是为何敏捷测试总是强调测试左移的重要性 —— 在需求分析或者 Feature kick off 阶段，QA 尽早参与到知识汇集的阶段，也可以降低 Dev 的返工率。即使是处于“开发”下游的“功能测试”，也可以从提供自动化测试代码的视角，察觉到测试的增值贡献 —— 让代码制品拥有了自动化测试代码。</em></p><p>正如图中显示，黄色标签为 I 型浪费，红色为 II 型浪费，比如“等待型浪费” —— 等待联调， “返工型浪费” —— 改 Bug。<br>那如何实施消除浪费呢？比如上面的等待联调、联调后的bug返工修复。<br>没有标准答案，但大体有如下思路：</p><ol><li>当前后端等待联调，团队的Dev是否可以发展成全栈工程师，这样前后端一个Dev就直接完成了，不存在联调。既消除了联调等待，也降低了返工率。</li><li>如果不发展全栈工程师，在story开始阶段，前后端是否可以一起设计和约定好契约（包括happy path、unhappy path、异常处理），由契约DSL上传到contract Mock server，这样可以降低联调成本和返工率。</li></ol><h4 id="2-3-敏捷-DevOps团队能力建设">2.3. 敏捷 &amp; DevOps团队能力建设</h4><p>有了前面两步治理成熟度的达成：度量评估和价值流分析，对研发效能有了不同维度整体的了解之后，接着就进入到治理动作的实施中。<br>建议使用带有整体优化能力的理论和实践框架 —— 敏捷 &amp; DevOps。这些理论和实践已经被反复验证，并且非常成熟。</p><p>敏捷，鼓励创建研发的全功能团队，提升交流和互动，以尽早和持续的交付高价值的软件为目标。一些团队甚至还鼓励成员打破角色边界，比如身兼 QA 能力的 Dev、具备 ops 能力的 Dev 等等。在这个阶段，基于Scrum、Kanban软件研发模式的普及，持续交付理念（Continuous Delivery, Jez Humble 提到的宏观角度的持续交付）也越来越被重视。</p><p>到2009年，终于有人在借鉴敏捷和精益的基础上，创造了 DevOps 这个词，旨在强调将 Ops 加入到产品研发全功能团队的充分必要性，并且兼顾开发思维、实行 infra as code的运维方式和方法，旨在提升产品交付效率和可靠性。</p><p>随着 DevOps 运动的兴起和推广， DevOps 逐渐发展，包括和涵盖了方法论、流程、自动化工具，以及特别强调的 DevOps 文化，并且逐渐影响到了整个研发价值流的参与者们遵循 DevOps 精神进行群策群力。<br>比如：Sec、QA 将安全和测试脚本加入Pipeline —— 不需要等到环境验证，在build运行的过程中就可以快速反馈到Dev，进行代码修复。</p><p>《凤凰项目》在DevOps原则，总结了三步工作法：</p><ul><li>流动原则。实现开发到运维的工作快速地从左往右流动。</li><li>反馈原则。从右往左的每个阶段中，应持续、快速地获得工作反馈。</li><li>持续学习和实验原则。团队建立持续学习和实践的文化。</li></ul><p><img src="/2022/07/18/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-xia-pian/three-steps-method.png" alt="三步法"></p><p>因此，团队针对敏捷 &amp; DevOps 进行能力建设，可以从整体优化的角度对效能进行治理和提升。<br>在具备了敏捷 &amp; DevOps 能力下，再去探索局部优化和治理。</p><h4 id="2-4-交付和运营方式转变">2.4. 交付和运营方式转变</h4><p>在敏捷 &amp; DevOps 团队具备稳定和高效地研发效率、高质量、降低了发布成本和发布风险后，让原本正确、但看起来不可实现地交付和运营方式变得可能：</p><ul><li>系统3~6个月一次大批量发布上线 <code>--&gt;</code> 每个月/甚至更短周期 小批量发布上线</li><li>由需求批量压入迭代的 Scrum 研发管理模式 <code>--&gt;</code> 需求拉动的 Kanban 研发管理模式</li><li>DevOps 2.0、持续交付2.0 逐渐实现。</li></ul><p>研发效能被提及，其目标是快速验证产品、获取用户反馈的能力，位于行业前台的系统的快速推出，还能带来抢占市场的机会。<br>因此，交付和运营方式的转变，在完成治理成熟度3之后，必要、且可顺势而行。</p><h4 id="2-5-共享的、自助的研发运营XXX一体化平台">2.5. 共享的、自助的研发运营XXX一体化平台</h4><p>也许有人会奇怪，在达成前 4 步效能成熟度之后，第 5 阶次的成熟度居然是推出 研发运营XXX一体化平台？（XXX可能是业务运营等等，反正随着 DevOps 2.0、持续交付2.0、bizDevOps这些相似概念的提出，大家旨在将产品的从概念到投入用户群体，这其中正向、反向的活动都组成一个闭环的整体）<br>将研发运营XXX一体化平台放在效能治理成熟度最后一步的逻辑是：</p><ul><li>即使不依托一体化平台，循序前四个成熟度治理，效能治理也可以在不同的企业和组织中开展。</li><li>当团队达成前四步治理成熟度，可以考虑将局部优化转化成全局优化。借助研发运营XXX一体化平台，对企业和组织内的全局优化事半功倍。</li><li>研发运营XXX一体化平台，说白了，只是一个工具，投入需要大成本。如果没有前四步成熟度的认知和达成，它也仅仅只是个工具。</li></ul><h3 id="3-总结">3. 总结</h3><p>研发效能治理方案的理论框架，基本到这里就阐述完了。<br>总结一下，就是：</p><ul><li>先度量和评估，再价值流分析</li><li>敏捷 &amp; DevOps 团队能力建设</li><li>交付和运营模式转变</li><li>推出 共享的、自助的研发运营XXX一体化平台</li></ul><h3 id="后话">后话</h3><p>在我写完（上篇）的时候，一些朋友表达了对国内越来越看重“研发效能”、“研发效能治理”这些命题和观点的不满，我其实也一样。<br>但是国内这方面的对软件定制和咨询的商机，又的确会经常出现。从我们这些公司的角度，就会去想 —— 是跪着把这钱给赚了，还是站着把这钱给赚了的问题。我自己也一直没有结论。<br>直到最近我在做一个售前方案的时候，跟公司内的一个咨询师交流，发现他对于“研发效能”这词的排斥。我内心颇有点恼，因为他讲的那些其实大家都心知肚明，反而我好像变成那个不道德和狭隘的一方。<br>因此，对于赚钱的问题，有了结论 —— 那就站着把钱给赚了吧，以后就只谈 价值交付、持续交付 2.0、DevOps。</p><p>不管怎样，立Flag后第二篇文章，总算是完成了，yeah~</p>]]></content>
      
      
      <categories>
          
          <category> 敏捷精益软件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 精益 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>聊聊研发效能治理方案的理论框架（上篇）</title>
      <link href="/2022/07/02/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-shang-pian/"/>
      <url>/2022/07/02/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-shang-pian/</url>
      
        <content type="html"><![CDATA[<p>最近几年，国内业界越来越常提及<code>“研发效能”</code>这个词，追其根源大部分是始于<code>“DevOps”</code>运动的活跃。<br>知道 DevOps 发展历史的，基本都了解 DevOps 是受敏捷的影响，是敏捷原则在软件研发到运维运营层面的延伸。<br>很多云厂商在推广自己 DevOps 平台服务的时候，也会提及对<code>“研发效能”</code>的大幅度影响，比如 AWS 对 DevOps 的描述：</p><blockquote><p>DevOps is the combination of cultural philosophies, practices, and tools that increases an organization’s ability to deliver applications and services at high velocity: evolving and improving products at a faster pace than organizations using traditional software development and infrastructure management processes. This speed enables organizations to better serve their customers and compete more effectively in the market.</p></blockquote><p>那么，研发效能 == DevOps 吗？<br>答案自然是否定 。</p><span id="more"></span><p>研发效能 明显是“问题域”。<br>DevOps 是一种解决方案，且是一种已经被验证、非常成熟的、可以提升软件研发效能的解决方案。<br>但就像人感冒发烧一样，吃 A 药可以痊愈，吃 B 药也可以痊愈，打针也可以痊愈，甚至有时候发现吃药效果不理想，最后还是去打了针。<br><code>研发效能低</code>，就像人感冒发烧一样，是个 “问题” 。<code>DevOps</code>, 是解决这个问题的一种 “药”。</p><p>因此，弄清楚了<code>问题域</code>和<code>解空间</code>的关系之后，我们来看看研发效能和它的解空间，并且主要聊一聊解空间（研发效能治理）。</p><h3 id="1-研发效能的定义">1. 研发效能的定义</h3><p>研发效能，即持续快速交付价值的能力。<br>将其拆解一下：<code>研发效能</code> = <code>效率</code> + <code>质量</code>+ <code>有效价值</code>，还有这三项可重复和稳定发生的<code>持续性</code>。</p><p>展开来讲，就是</p><ul><li>要在保证系统可靠性、不降低交付质量的情况下，尽量缩短从业务构想到功能上线的时间  （质量 + 效率）</li><li>从而使“最小化可行需求”能快速被验证，确保有效价值，减少浪费  （有效价值）</li><li>且整个过程效果可重复发生（持续性）</li></ul><h3 id="2-研发效能的治理">2. 研发效能的治理</h3><p>有了定义之后，就来看看如何对研发效能进行治理。<br>根据市面上大部分公司的软件工程能力状况，针对研发效能治理，这里提炼了一条“研发效能治理成熟度模型”。</p><p><img src="/2022/07/02/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-shang-pian/%E6%B2%BB%E7%90%86%E6%88%90%E7%86%9F%E5%BA%A6%E6%9B%B2%E7%BA%BF.png" alt="研发效能治理成熟度"><br>从左至右，研发效能治理分为5个阶段，每个阶段也必须包含它左边所有阶段的成果。<br>举个例子：某IT部门采购了一个 DevOps 平台服务，但日常仅仅当做 CI/CD流水线 甚至是“发布工具”来使用，对效能治理没什么概念，这时候该IT部门的治理成熟度自然是低的，可能只在“度量和评估”的位置。</p><p>接着，展开来看看效能治理成熟度每一个阶段。</p><h4 id="2-1-度量和评估">2.1. 度量和评估</h4><p>管理学之父彼得德鲁克曾经说过：“如果你无法度量它，就无法管理它”。<br>对管理如此，对效能治理亦是如此。因此，度量和评估，对于研发效能的治理必不可少。</p><p>那么，再来看看为何把“度量和评估”放在治理的第一步呢：</p><ul><li>首先，想要对研发效能进行治理，必须知道当前效能处于一个什么阶段，对现状有了度量评估和自我认知之后，才能明确之后治理的方向和力度。</li><li>同时，度量和评估模型在持续治理的过程中，可以阶段性地重复使用，用以呈现治理成果的效果和进行快速反馈。</li></ul><p>因此，度量和评估，作为研发效能治理的第一步不可或缺。</p><p><strong>接着，来看看如何做度量和评估？</strong><br><strong>从 “健康度指标” 和 “局部诊断性指标” 分两层来看。</strong></p><h5 id="健康度指标">健康度指标</h5><p>首先，借鉴于<code>DORA</code>(DevOps研究和评估组织) 的2021年报告中的Four Key Metrics，将其作为研发效能的4个关键 <strong><code>健康度指标</code></strong>:</p><p><img src="/2022/07/02/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-shang-pian/four_key_metrics.png" alt="four key metrics"></p><ul><li><strong>研发效率</strong>：<ul><li>部署频率</li><li>前置时间（Lead time）</li></ul></li><li><strong>研发质量</strong>：<ul><li>故障恢复时间 （MTTR）</li><li>部署失败率</li></ul></li></ul><p><code>特别注意</code>：区别于 DevOps 只关注于“从代码提交到功能发布”这个区间的前置时间，研发效能中的“前置时间”延伸了覆盖范围 —— 从业务构想到功能发布，涉及研发运营的整个研发周期。<br>其他三项，与 DevOps 报告相同。</p><p>至于，研发效能中的__<code>有效价值</code>__，其与业务关系紧密，度量数据模型需要根据具体业务来设计，因此目前仅给予该项 <code>健康度评估模型</code>：</p><blockquote><p>Measurement involves collecting factual information about the value of a deployed feature and evaluating it against the original hypothesis statement.<br>Rate your team’s ability to collect objective information about the actual value realized by deployed features so that it can inform strategic financial decisions.<br>Sit (1-2): We don’t define or measure the value of Features.<br>Crawl (3-4): We’ve defined what “value” is but don’t know how to measure it.<br>Walk (5-6): We capture qualitative feedback from the business about the value of our Features.<br>Run (7-8): We capture qualitative and quantitative feedback from the business and our monitoring systems about the value of our features.<br>Fly (9-10): We aggregate the quantitative and qualitative feedback to objectively validate the original hypothesis and inform pivot-or-persevere decisions.</p></blockquote><p>看到这里，是不是有点眼熟，如果原本预想的解决方案是 “DevOps一体化” 的话，加上有效价值的度量，是不是方案就要考虑<code>"BizDevOps"</code>?! 是不是仅仅一个DevOps的方案就不够匹配了？（重新再正视一下问题域和解空间的区别 :P）</p><h5 id="局部诊断性指标">局部诊断性指标</h5><p>也许有人会觉得，对比下其他类型的度量和评估报告上繁多的指标量，上面这几个指标未免有些简陋。<br>比如，连常见的评估应用架构维度的指标都没有。<br>其实，应用架构指标是有的，但并不属于效能“健康度指标”，而是“局部诊断性指标”。</p><ul><li>当发现健康度不理想，需要分析、定位和形成改进建议时，这时就要借助于局部诊断性指标。</li><li>当实施了改进建议，对局部指标进行了优化，最终效果又会传导到健康度指标上。<br>如果局部指标改进了，但健康度未提升，这时可能需要回过头来分析和反思一下：是诊断和改进建议的问题，还是本身局部指标需要调整。</li></ul><p><img src="/2022/07/02/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-shang-pian/%E5%B1%80%E9%83%A8%E8%AF%8A%E6%96%AD%E6%80%A7%E6%8C%87%E6%A0%87.png" alt="局部诊断性指标示例"></p><p>有了这两层指标，整个研发效能的度量和评估模型才大体完整。<br>而在整个研发的过程中，可以常常阶段性的使用模型进行度量和评估一下，比如每次发布周期完成 或者 每次sprint完成的时候等等。<br>使用指标值的时候，也需要注意：<strong>指标值本身并不重要，重要的是通过数据驱动出洞见。而在持续改进的过程中，数据趋势比数据值更重要。</strong></p><p><img src="/2022/07/02/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-shang-pian/key_metrics_report.png" alt="趋势图"></p><p>《下篇》讲接着聊剩下的4个成熟度阶段。</p>]]></content>
      
      
      <categories>
          
          <category> 敏捷精益软件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 精益 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库的ACID和分布式事务</title>
      <link href="/2022/05/10/shu-ju-ku-de-acid-he-fen-bu-shi-shi-wu/"/>
      <url>/2022/05/10/shu-ju-ku-de-acid-he-fen-bu-shi-shi-wu/</url>
      
        <content type="html"><![CDATA[<p>前面写了一篇关于<code>CAP原理</code>的博文，说到<code>一致性 Consistency</code>，有人往往会想到事务<code>ACID</code>特性中的<code>C: Consistency</code>，虽然都叫一致性，但完全是两个东西。</p><ul><li><code>CAP</code>的一致性指：数据库的同一复制集（replicaSet）之间数据相同。<br><em>这里的“数据库”，可以是主从、主备、集群架构，但没有单机架构。</em></li><li><code>ACID</code>的一致性指：在数据库单一实例中(暂不涉及多个数据源的分布式事务)，成功写入的数据不违反已定义的数据规则，如约束、级联规则等等。<br><em>一般在<code>业务流程</code>这个上下文下，聊<code>数据的一致性</code>，通常是在聊广义的数据一致性，即<code>ACID</code>这四项，并非是<code>C</code>一项。单机数据库就是通过事务来保障<code>数据的一致性</code>。</em><br>接着，来通过本地事务的详细说一下<code>ACID</code>，以及跨多数据源的分布式事务。</li></ul><span id="more"></span><p><em>注：</em> 文章的余下部分，提到的数据一致性，都是指广义数据一致性，即ACID四项。不再涉及<code>CAP</code>部分。</p><h3 id="1-本地事务ACID">1. 本地事务ACID</h3><p><code>本地事务</code>，这里指单个业务服务仅操作单一数据源，完全由 DBMS (Data Base Management System)提供的事务ACID能力。<br>除去上面对<code>Consistency</code>的解释外，剩下的三项：</p><ul><li><code>Atomic(原子性)</code>：在事务边界内的所有写操作，要么一起成功，要么一起失败(也叫 All-or-Nothing）。<br>阻止出现只有部分更新的数据异常。</li><li><code>Isolation(隔离性)</code>：存在并发的情况下，不同的连接的读、写操作相互之间独立，尽量不受影响。<br>从低到高分为四个隔离级别：<code>Read uncommitted</code>、<code>Read committed</code>、<code>Repeatable read</code>、<code>Serializable</code>。各数据库厂商实现方式不同，造成标准的表现性有些许差别。比如 MySQL InnoDB采用 MVCC 机制实现事务隔离，Repeatable read 级别可以防止幻读。</li><li><code>Durability(持久性)</code>：保证所有成功提交的数据都能正确被持久化，不会被丢失。</li></ul><h3 id="2-跨多数据源的分布式事务">2. 跨多数据源的分布式事务</h3><p>在分布式环境下，由于数据提交链路会涉及到多个数据源节点，要保证提交的数据如单机节点一样拥有事务的 ACID 特性，就变得非常复杂。<br>因此，分布式事务要解决的核心问题，就是如何在分布式环境中实现这些 ACID 特性。</p><p>传统的单机数据库 DBMS 提供事务的 ACID 特性，提供了强一致性模型，屏蔽了开发人员去额外实现底层数据 ACID 四个维度的问题，简化了开发工作。<br>最早出现的"分布式事务问题"的解决方案，基本是为了对齐数据库的事务能力 —— 实现强一致性，因此出现了比如X/Open XA等协议标准，其背后使用的是 2PC (两段式提交)解决方案。<br>因此，支持X/Open XA标准的这些强一致性解决方案，也被称为“分布式事务”。<br><em>注意区分一下“分布式事务问题”和“分布式事务解决方案”这两个词。</em><br><em>因为事务被分拆到多个数据源节点，带来的事务被分布式了的问题，称为“分布式事务问题”。但分布式事务问题的解决方案，除了最早出现的强一致性的“分布式事务”这一种方案外，还有考虑场景可用的“弱一致性模型”解决方案和“最终一致性模型”解决方案。</em><br><em>因此，当有人说：“不要使用分布式事务，尽量使用最终一致性”时，他的意思是不要使用强一致性，并非是让你不要使用多数据源。</em></p><h4 id="2-1-2PC-两段式提交">2.1 2PC 两段式提交</h4><p>两段式提交协议主要分为两个阶段：<br><img src="/2022/05/10/shu-ju-ku-de-acid-he-fen-bu-shi-shi-wu/2PC.png" alt="2PC"></p><h5 id="第一阶段（prepare-准备阶段）">第一阶段（prepare 准备阶段）</h5><ol><li><strong>协调者（Coordinator）</strong>：发起并管理整个事务的进程。它首先向所有参与事务的节点（也称为参与者）发送 prepare request。</li><li><strong>参与者（Participants）</strong>：接收到 prepare request 后，每个参与者会锁定资源，执行事务操作，并将操作结果（成功或失败）记录到日志中。然后，它们各自向协调者报告”准备就绪“（表示可以提交，资源已锁定，操作已记录，但尚未实际提交）或“准备失败“。</li></ol><h5 id="第二阶段（commit-提交阶段）">第二阶段（commit 提交阶段）</h5><ul><li>如果所有参与者都报告”准备就绪“，协调者向所有参与者发送 commit request。参与者在完成事务提交后释放所有锁定的资源，并向协调者报告完成。</li><li>如果任何参与者报告”准备失败“，或者任何参与者响应超时，协调者向所有参与者发送 rollback request。参与者将撤销所有事务操作，释放所有锁定的资源，并向协调者报告完成。</li></ul><h5 id="两段式提交的缺点">两段式提交的缺点</h5><p>尽管两段式提交能够确保分布式系统中事务的一致性，但它也有一些缺点：</p><ul><li><strong>性能问题</strong>：所有参与者在第一阶段结束时都必须等待，直到收到协调者的最终决定（提交或回滚）。这个等待过程可能会导致系统资源长时间锁定，影响性能。</li><li><strong>单点故障</strong>：如果协调者在第二阶段崩溃，参与者可能会陷入不确定状态，不知道是应该提交还是回滚，这会导致系统挂起。</li><li><strong>数据不一致</strong>：在某些极端情况下（如网络分区），可能会导致部分参与者提交事务，而其他参与者回滚事务，从而导致数据不一致。</li></ul><p>为了解决这些问题，研究者提出了许多改进的协议，如三段式提交（Three-Phase Commit，3PC）等，旨在提高容错性和减少在事务处理过程中资源锁定的时间。</p><h4 id="2-2-3PC-三段式提交">2.2 3PC 三段式提交</h4><p>3PC 是两段式提交（2PC）的改进版本，旨在解决 2PC 面临的一些主要问题，尤其是在面对单点故障和网络分区时，能更好地保持分布式系统的数据一致性。<br>3PC 通过将<code>prepare阶段</code>分拆成<code>Can Commit</code>和<code>Pre-Commit</code>两个阶段， 通过<code>询问，再锁资源，最后真正提交</code>的方式，来减少阻塞和减轻单点故障的影响，提高系统的容错性。</p><p><img src="/2022/05/10/shu-ju-ku-de-acid-he-fen-bu-shi-shi-wu/3PC.png" alt="3PC"></p><h5 id="第一阶段：准备阶段（Can-Commit）">第一阶段：准备阶段（Can Commit）</h5><ol><li><strong>协调者</strong>向所有参与者发送<code>Can Commit</code>请求，并等待参与者的响应。</li><li><strong>参与者</strong>：<ul><li>收到<code>Can Commit</code>请求后，参与者执行事务相关的准备工作（如检查数据的有效性、预留必需资源等）。</li><li>如果参与者判断自己能够提交事务，则向协调者发送<code>Yes</code>回复，表明准备就绪。</li><li>如果无法提交（如资源不足或数据验证失败），则发送<code>No</code>回复，并终止事务。</li></ul></li></ol><h5 id="第二阶段：预提交阶段（Pre-commit）">第二阶段：预提交阶段（Pre-commit）</h5><ul><li><strong>触发条件</strong>：只有当协调者从所有参与者处收到了<code>Yes</code>回复，才会进入此阶段。</li></ul><ol><li><p><strong>协调者</strong>：</p><ul><li>向所有参与者发送<code>Pre-commit</code>请求，通知它们进入预提交状态。</li><li>开始等待所有参与者的<code>ACK</code>（确认）消息。</li></ul></li><li><p><strong>参与者</strong>：</p><ul><li>收到<code>Pre-commit</code>请求后，参与者会执行所有必要操作以准备提交事务，但此时不会真正提交。这可能包括最终的<code>资源锁定</code>和<code>日志记录</code>，以确保可以安全地提交事务。</li><li>准备就绪后，参与者会向协调者发送<code>ACK</code>，表示准备提交。</li></ul></li></ol><h5 id="第三阶段：提交阶段（Do-Commit）">第三阶段：提交阶段（Do Commit）</h5><ul><li><strong>触发条件（提交）</strong>：如果协调者收到所有参与者的<code>ACK</code>，则会进入提交阶段。</li><li><strong>触发条件（中止）</strong>：如果在任何阶段协调者从任一参与者那里接收到<code>No</code>，或者超时没有收到预期的回复，它将决定中止事务。</li></ul><p>当触发提交分支：</p><ol><li><strong>协调者</strong>：<ul><li>向所有参与者发送<code>Do Commit</code>指令。</li></ul></li><li><strong>参与者</strong>：<ul><li>收到<code>Do Commit</code>后，参与者正式提交事务，并在事务日志中记录此次提交。</li><li>完成提交后，释放所有锁定的资源，并向协调者发送<code>完成</code>消息。</li></ul></li></ol><p>当触发中止分支：</p><ol><li><strong>协调者</strong>：<ul><li>如果决定中止事务，协调者会向所有参与者发送<code>Abort</code>指令。</li></ul></li><li><strong>参与者</strong>：<ul><li>收到<code>Abort</code>指令的参与者会撤销所有事务操作，并释放所有占用的资源。</li></ul></li></ol><h5 id="优势">优势</h5><ul><li><strong>减少阻塞</strong>：通过 pre-commit 阶段的机制设定：在此阶段才锁定资源 以及 参与者对于指令超时未接收进行默认事务处理的方式，来减少了阻塞时间。</li><li><strong>提高容错性</strong>：3PC通过引入额外的预提交阶段，增加了决策过程的灵活性，使系统更能容忍协调者的失败。</li></ul><h5 id="缺点">缺点</h5><ul><li><strong>性能开销</strong>：引入额外的预提交阶段意味着更多的通信开销，可能对系统性能产生负面影响。</li><li><strong>复杂性增加</strong>：与2PC相比，3PC的实现更加复杂，需要更多的控制逻辑来处理额外的阶段和可能的状态。</li><li><strong>仍然存在问题</strong>：尽管3PC在某些方面比2PC更健壮，但它仍然不能完全解决分布式系统中的所有问题，如网络分区情况下的脑裂问题(在第三阶段参与者没有接收到Abort指令，采用了默认的do commit，则会造成参与者群的数据不一致，虽然因为前两阶段的设计，这种情况的概率会比较低)。</li></ul><p>总的来说，3PC通过引入三段式算法，在一定程度上提高了分布式系统事务处理的可靠性和容错性，但这也以增加系统复杂性和通信成本为代价。在实际应用中，需要根据系统的具体需求和环境，权衡3PC与其他事务处理机制的利弊。</p><h4 id="2-3-总结">2.3 总结</h4><p>通过上面对2/3PC算法的了解，可以发现其并不能完全达到强一致性的目标，在网络分区等情况下仍会出现数据不一致，同时还会带来低性能低并发等问题。<br>因此，才会有后面解决分布式事务问题的其他解决方案。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式架构必须重视的CAP理论</title>
      <link href="/2022/05/03/fen-bu-shi-jia-gou-bi-xu-chong-shi-de-cap-li-lun/"/>
      <url>/2022/05/03/fen-bu-shi-jia-gou-bi-xu-chong-shi-de-cap-li-lun/</url>
      
        <content type="html"><![CDATA[<p>CAP定理，说起来程序员们应该耳熟能详：C(Consistency)、A(Availability)、P(Partition Tolerance)，构成在分布式数据存储中的“不可能三角”，三者只能保证其二。<br>来，再展开说说？这时候，多数人的回答就会是是而非，模棱两可。<br>也许不少应用级开发工程师觉得 —— 我又不自研集群数据库，也不开发云平台，没必要那么了解 CAP 理论。<br>那么，你开发的应用系统，是否使用了分布式架构呢？如果是，CAP 理论可以说是指导构建系统的技术理论基石之一，必须要重视起来。</p><span id="more"></span><h3 id="1-CAP-定理到底讲了什么">1. CAP 定理到底讲了什么?</h3><p>CAP 定理对分布式数据存储系统的特性进行高度抽象，提炼成了3个维度：</p><ul><li><p><code>Consistency 一致性</code>, 每一次读取操作，要么系统返回最新的数据写入值（无论读取到哪一个数据节点），要么返回系统错误。<br>这里的一致性，代表的强一致性、线性一致性（Linearizability）。</p></li><li><p><code>Availability 可用性</code>, 每一次读取操作都能获得系统的返回，但不保证返回的是最新的数据写入值。</p></li><li><p><code>Partition Tolerance 分区容错性</code>，当数据节点之间发生网络分区（包括网络丢包、连接中断阻塞等），系统仍然要继续工作。</p></li></ul><p>这其中的底层逻辑是：分布式数据存储各节点之间通过网络连接，在运行期间不可避免存在网络分区的风险。<br>当网络分区发生时，无论是节点之间的状态同步还是数据复制，都会发生异常，部分节点的数据滞留在过去时刻的某种状态。</p><p>而保证<code>分区容错性</code>，就是当发生网络分区异常时，整个系统仍然运行并继续工作，这时候提供的服务维度只可能在 Consistency 和 Availability 中保证一项：</p><ul><li><p>确保一致性，牺牲可用性。<br>系统会通过内部策略，自动修复集群，最终确保<code>Consistency</code>声明的强一致性。在自动修复完成之前，外部请求会返回系统出错或者超时。<br><img src="/2022/05/03/fen-bu-shi-jia-gou-bi-xu-chong-shi-de-cap-li-lun/CAP_CP.png" alt="CP"><br><em>上图简化了集群中的一些问题描述，比如共识算法至少需要三个节点。</em><br><em>当节点 2 与 节点 1 之间因为通讯异常，未能对 x 的值达成一致，此时外部请求读取 x 的值，系统将返回“系统出错”或者超时。</em></p></li><li><p>确保可用性，牺牲一致性。<br>系统在自动修复集群期间，没有达成数据一致性的各节点仍会对外及时响应，确保<code>Availability</code>声明的高可用性。<br><img src="/2022/05/03/fen-bu-shi-jia-gou-bi-xu-chong-shi-de-cap-li-lun/CAP_AP.png" alt="AP"></p></li></ul><p>以上，即是 CAP 理论中 CP 和 AP 的由来。<br>然而，在分布式数据存储架构中，虽然网络分区是不可回避的风险，但也不意味着系统任何时候都处于网络分区的状态之下。在没有发生网络分区的时候，CA 应该是主要状态。</p><p>有人也许会对此产生质疑：即使分布式集群一切运行正常，没有发生网络故障，但节点间的数据传输也需要时间、存在网络延时，不可能在未完成数据同步的中间状态下，既保证可用，又保证所有节点数据一致性。<br>是的，这种问法很对。<br>因此，针对 CAP 理论中的 C，一些专家解释：Consistency，是忽略数据复制延时的，是假设数据复制不存在延时的理论场景。</p><p>然而数据复制的延时，在现实分布式系统运行期间始终存在，因此这时无 <code>P</code> 的 <code>CA</code> 很难与现实进行相互映射，使用时可能会造成困扰，不如理解为:</p><ul><li><code>Consistency</code> 是包含正常水平的复制延时的，这部分延时会计算在响应时间中，而不算影响 <code>Availability</code>。而当达成一致性的处理时长超出这个正常水平，才算作影响 <code>Availability</code>。<br>当然，更好的解释，也许应该看下 <code>PACELC 理论</code>，可以对此场景进行补充。</li></ul><h3 id="2-CAP-的扩展：PACELC-理论">2. CAP 的扩展：PACELC 理论</h3><p>通过上面对<code>CAP 定理</code>的了解，可以总结为在分布式数据存储架构设计中，至少需要一条 baseline 策略，应对出现网络分区这种危险状况。<br><img src="/2022/05/03/fen-bu-shi-jia-gou-bi-xu-chong-shi-de-cap-li-lun/CAP.png" alt="CAP"></p><p>在没有出现网络分区、正常运行的系统状态下，CAP 理论中的 CA 可以达成，但<code>数据一致性</code>的状态、以及隐藏在达成该状态背后的<code>延时时长</code> —— 这两个现实系统中过于常见的维度，如一双在 CAP 定理中说不清、道不明、又无处安放的小手，又该如何衡量和取舍呢？</p><p>这时候，就可以看一下 <code>PACELE 理论</code>。<br><code>PACELE</code> 是 <code>CAP 理论</code> 的扩展， <code>PAC</code> 各字母同 <code>CAP 理论</code>， <code>E (Else)</code> 仅是连接词，<code>L (latency) </code>、<code>C (consistency)</code>。意思就是，当没有出现网络分区、系统正常运行时，<code>低延时</code>（低于数据达成一致所需的平均延时水平） 和 <code>数据一致性</code>，二者需要选择其一，不能同时保证。<br><img src="/2022/05/03/fen-bu-shi-jia-gou-bi-xu-chong-shi-de-cap-li-lun/PACELE.png" alt="PACELE"></p><p>当有了基于<code>CAP</code>扩展出的<code>PACELE</code>，个人觉得，分布式数据存储的特性架构描述才比较完整。<br>比如，MongoDB 集群的就是典型的 <code>PA/EC</code> 系统：在出现网络分区时，MongoDB 集群优先保证可用性，数据可能不是最新；在集群正常状态下，优先保证数据一致性。<br>这也就防止了用户一听到 AP 架构就造成的恐慌 —— 以为系统状态正常下，程序员仍需要大量编码、自己处理数据一致性的问题。</p><p>下图是<code>PACELE 理论</code>中的特性搭配图，（横轴是发生 P 时的A or C 选择，纵轴是没有发生 P 时对 C or L 的选择）：<br><img src="/2022/05/03/fen-bu-shi-jia-gou-bi-xu-chong-shi-de-cap-li-lun/PACELE_2.png" alt="PACELE"></p><h3 id="3-为什么做分布式架构要重视-CAP-理论？">3. 为什么做分布式架构要重视 CAP 理论？</h3><h4 id="3-1-对分布式应用架构有借鉴和指导作用">3.1. 对分布式应用架构有借鉴和指导作用</h4><p>当前主流的分布式应用架构如微服务架构，在领域微服务之间不可避免地存在数据复制，比如：服务边界内实体、同时也是其他微服务的值对象；采用 CQRS 模式构建微服务；使用事件驱动架构搭建微服务等等。<br>只要存在数据在不同服务之间的复制：</p><ul><li>当复制机制出现连通故障、阻塞、高延迟等（比如消息组件消息堆积等），都可以近似的理解为 <code>网络分区</code>， 当发生<code>网络分区</code>时，需要有对应策略，无论是优先保证<code>数据一致性</code>，还是优先<code>可用性</code>？</li><li>当复制机制正常，数据同步仍存在时间成本。这时候，是优先保证<code>数据一致性</code>，还是优先<code>低延时</code>？<br>虽然以上的 “数据一致性” 不一定是 CAP 中的 “线性一致性” 这种强一致性，但 CAP 理论的这种思考维度和框架，以及扩展出的分布式算法和实践，在分布式应用架构设计中，也有很强的借鉴和指导作用。</li></ul><h4 id="3-2-指导数据存储方案的选型">3.2. 指导数据存储方案的选型</h4><p>分布式应用架构，不可避免地会面临对各种数据存储产品的选型，除了根据应用业务特性以及存储/读/写维度性能的需求，提供容量扩展、高可用的集群特性，也是必不可少的一个考察维度。<br>比如，业务特性需要的是一个 PA/EC 特性的集群能力，PA/EL 特性的产品自然是不匹配需求的。</p><h4 id="3-3-帮助完善数据存储方案落地">3.3. 帮助完善数据存储方案落地</h4><p>前面提了集群数据库的选型，但离方案可落地仍有一段距离，需要完美适配应用的业务场景，可能除了正确执行客户端调用以外，还需要一些额外配置 或者 二次加工，才能达到某些特性目标。</p><p>比如 MongoDB 的 readConcern 和 writeConcern，没接触过 <code>Quorum NWR</code> 算法策略的人，可能无法快速意识到 —— MongoDB 即使在 <code>AP</code> 状态下，依然可以通过客户端配置 readConcern/writeConcern 有选择地达成数据强一致性。<br>而不了解 <code>Quorum NWR</code> 的，可能会舍近求远地设计出一些复杂度较高的自研策略。</p><h3 id="参考资料">参考资料</h3><p><a href="https://en.wikipedia.org/wiki/CAP_theorem">CAP理论维基百科及链接</a><br><a href="https://en.wikipedia.org/wiki/PACELC_theorem">PACELC理论维基百科及链接</a></p>]]></content>
      
      
      <categories>
          
          <category> 分布式架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重启</title>
      <link href="/2022/04/29/chong-qi/"/>
      <url>/2022/04/29/chong-qi/</url>
      
        <content type="html"><![CDATA[<p>最近回忆过往工作经历，发现以往知识经验、林林总总，所思所想胡乱堆积，没有整理成一套逻辑明了的结构纲要。<br>因此，予以记忆而言，效率不高，且没有关联的知识块容易遗忘；予以表达而言，易思维阻塞，前后逻辑不顺；予以认清知识本质而言，重复颇多，而且只见云雾不见青山。<br>所以，现觉得对自身的知识储备进行重构，迫在眉睫。<br>那么，有没有一种看起来比较靠谱的架构解决方案可以达到此目的呢？<br>重读《金字塔原理》之后，我觉得使用“金字塔结构”可以一试。</p><span id="more"></span><p><strong>为何使用“金字塔结构”有利于知识重构？</strong></p><ol><li>金字塔纵向的“疑问/回答式”结构，符合软件构建的思路——从意图推导方案，从问题域到解决方案域。</li><li>金字塔的纵向结构，将知识和思想进行了不同层次的抽象和汇总。</li><li>金字塔的横向结构，强调了同一个主题思想下的子思想项之间必须符合逻辑关系。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 写作 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker JVM通用工具诊断指南</title>
      <link href="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/"/>
      <url>/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/</url>
      
        <content type="html"><![CDATA[<p>Docker container 和 JVM的问题诊断，从来都不是静态的，所有来源数据都是一个动态的过程。<br>一个时间点的快照数据、或者一个单一数据项的字面值，并不能充分进行上下文分析，而是需要一段时间内持续的观测和数据获取，然后在时间维度上的纵向对比、不同实例间的横向对比等等手段，最终定位问题。</p><p>如下图中，资源利用率 —— 可能是docker CPU/Mem、JVM CPU/Mem、磁盘/网络IO、线程数等等。</p><ul><li><p>图1：在时间段上，根据使用量和压力峰值的分布，资源空闲量充足，无资源利用率瓶颈；所有实例表现一致。<br>一般，图1 这种正常态会作为基准值来参考。</p></li><li><p>图2：随着压力峰值时的量变，资源利用率超过阈值（80%），但峰值过后，资源得到逐渐释放，利用率得到回落；所有实例表现一致。<br>面对这种压力超过阈值的情况，一般就是开源 或者 节流的解决方式：1. 增加资源额度；2. 分析资源的top customers, 优化代码，节省资源的使用。</p></li><li><p>图3：相同应用的不同实例中，有一个实例的利用率明显区别于其他实例。<br>面对这种情况，在确认负载均衡、部署设施都一致的情况下，需要拿取问题实例的容器内、JVM内的各项细节数据进行横向对比和分析。</p></li><li><p>图4：资源利用率与使用量和压力峰值不呈现直接的正相关关系；所有实例表现一致。<br>这种情况，需要拿取容器、JVM内的细节数据与基准状态（比如升级前的线上版本）进行纵向对比和分析。</p></li></ul><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-graph-trend.png" alt="资源利用率趋势图"></p><p>docker JVM出现性能问题时，一般会表现为以下几个方面：</p><ul><li>内存利用率高出阈值</li><li>CPU利用率高出阈值</li><li>整体性服务请求响应变慢 或 超时</li></ul><p>注：由于此篇指南对应线上部署环境的Docker JVM，除了线上监控工具提供的监视数据以外，涉及到图形化分析工具的使用方式都是离线分析，<br>并且不涉及各云特色的诊断工具。</p><h2 id="1-Docker-container-CPU-内存高">1. Docker container CPU / 内存高</h2><p>当发生docker container CPU / 内存高的情况，首先需要确认，是哪些进程在占用容器资源。除了JVM外，是否还有其他大量占用容器资源的进程？<br>如果系统没有接入性能监控平台，或者监控平台数据不直观时，可以在docker container内使用一些 Linux 命令。<br>推荐Linux工具和命令：</p><ul><li>top</li><li>iostat</li><li>vmstat</li></ul><h3 id="1-1-top工具">1.1 top工具</h3><p>top是Linux下常用的性能分析工具，能够实时显示系统中各进程的资源占用状况。</p><pre class="line-numbers language-none"><code class="language-none">$ top -c$ top -Hp &lt;pid&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>含义：</strong></p><ul><li>top 罗列出当前系统中的资源状况，以及进程数量、列表，并且实时刷新，<code>-c</code> 选项，显示完整的进程启动命令行。<br>top 监控支持交互的形式，具体操作查询linux top使用方法。</li><li>当获取到 <code>pid</code> 后，想要查看具体 pid 进程的资源消耗，以及进程内的线程列表，可使用<code>-Hp &lt;pid&gt;</code>。<br>H代表 lightweight，切换到此模式，所有Task显示的进程内的Thread数量，清单列表显示的线程清单。</li></ul><p><strong>注意：</strong><br>在docker中运行top命令时，<code>CPU%</code> 和 <code>MEM%</code> 是基于docker host物理机的“总CPU”和“总物理内存”的百分比。</p><h3 id="1-2-iostat工具">1.2 iostat工具</h3><p>iostat是I/O statistics的缩写，用来动态监控磁盘的活动。</p><pre class="line-numbers language-none"><code class="language-none">$ iostat -d -x -k 1 10<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>含义:</strong></p><ul><li><code>-d -x -k 1 10</code> 显示磁盘，显示详情，以KB为单位。1秒刷新一次，刷新10次后退出。</li></ul><p>确定了主要占用资源的进程后，针对不同的进程服务类型，使用不同的分析工具。<br>下面主要列举了Java JVM性能诊断。</p><h2 id="2-JVM-内存利用率高">2. JVM 内存利用率高</h2><h3 id="2-1-JVM-Memory分配现状">2.1 JVM Memory分配现状</h3><p>JDK自带的两个工具的用法：</p><ul><li><p><code>$ jmap -heap &lt;pid&gt;</code></p></li><li><p><code>$ jstat -gccapacity &lt;pid&gt;</code><br><code>$ jstat -gc &lt;pid&gt;</code></p></li></ul><h3 id="2-2-内存泄露">2.2 内存泄露</h3><p>在不存在内存分配问题的前提下，内存持续偏高时，首先需要排除是否是内存泄露。</p><p>如何确认是否存在内存泄露：</p><ul><li>查看HeapDumpOnOutOfMemoryError</li><li>查看GC状态</li><li>多次主动生成dump</li><li>分析工具 MAT / VisuaVM / JProfiler</li></ul><h4 id="2-2-1-HeapDumpOnOutOfMemoryError（内存溢出）">2.2.1 HeapDumpOnOutOfMemoryError（内存溢出）</h4><p>当程序运行过程中，申请对象内存超出剩余可用内存时，则会发生内存溢出异常。<br>存在内存溢出时，原因上有一定可能 —— 程序中存在内存泄露，对象被错误引用而造成始终无法释放、占据内存。</p><p>一般在生产环境的 <code>JVM Options</code> 的配置中，都会带有几个如下配置。（如果没有，务必添加）</p>  <pre class="line-numbers language-none"><code class="language-none">-XX:+HeapDumpOnOutOfMemoryError-XX:HeapDumpPath=/heapdump/out_of_memory_error/logs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>含义</strong>：</p><ul><li>在运行时发生 <code>OutOfMemoryError</code> 时，会输出heapdump文件，文件地址位于 <code>/heapdump/out_of_memory_error/logs</code> 此路径下。</li></ul><p>存在内存溢出时，根因不一定是存在内存泄露，也有可能是资源压力遭遇瓶颈。<br>程序在抛出 OutOfMemryError 时，message中会注明原因，比如<code>Java heap space</code> 等。<br>通俗来讲，JVM会抛出 OutOfMemryError 的内存区，不只是堆，一共包含堆、非堆（Metaspace）、堆外（直接内存）、栈四个部分。</p><p><strong>关键概念</strong>:<br>JVM内存结构划分：<br><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-mem.png" alt="JVM 内存划分"></p><p>实际上，除去上面6块以外，还有一个程序计数器。但程序计数器占用内存较少，并且不会抛出OutOfMemoryError，这里忽略。<br>当抛出OutOfMemoryError时，从程序日志中获取errorMessage，从而可以快速定位是哪块内存区域出现了问题。<br>在不存在内存溢出的情况下，内存长期居高不下，这时可以根据不同内存区域的内存使用率和回收率进行预判。<br>如：</p><ul><li>图一，堆内存的利用量高，造成CPU频繁GC。</li><li>图二，Metaspace 和 堆对内存利用量正常，同时CPU并无频繁GC。JVM 总内存利用量依然很高，这时需分析栈内存的占用情况。</li><li>图三，JVM 总内存利用量正常，CPU无频繁GC。在排除了非JVM之外的程序占用外，需分析直接内存的占用情况。</li></ul><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-mem-gc.png" alt="JVM GC趋势图"></p><h4 id="2-2-2-查看GC状态">2.2.2 查看GC状态</h4><p>查看GC状态，可以在没有OutOfMemoryError来源的情况下，快速定位<code>堆</code>和 <code>MetaSpace</code> 的内存使用量、回收效果、平均常驻容量等等，以此来推断内存对象在新生代、老生代和 MetaSpace 的用量和瓶颈。<br>一般在生产环境的<code>JVM Options</code> 的配置中，会带有如下几个GC配置。</p>  <pre class="line-numbers language-none"><code class="language-none">-XX:+UseGCLogFileRotation-XX:NumberOfGCLogFiles=10-XX:GCLogFileSize=100M-Xloggc:/heapdump/gc/logs/gc.log-XX:+PrintGCDetails-XX:+PrintGCDateStamps<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>前三行：GC日志每个文件大小：100M，最多保留10个文件，超出则使用替换覆盖的策略。</li><li><code>-Xloggc:/heapdump/gc/logs/gc.log</code> ，GC日志路径在<code>/heapdump/gc/logs/</code>文件夹下，文件名以<code>gc.log</code>为前缀。</li><li>后两行：打印GC时的详情，打印GC日志的时间戳。</li></ul><p>有了这些配置之后，JVM在启动之后，会输出GC日志。</p><blockquote><p>2020-12-04T17:13:17.280-0800: 22845.509: [GC (Allocation Failure) [PSYoungGen: 581178K-&gt;16640K(611840K)] 925472K-&gt;909807K(1511936K), 0.5084573 secs] [Times: user=0.36 sys=0.57, real=0.50 secs]</p><p>2020-12-04T17:13:17.789-0800: 22846.017: [Full GC (Ergonomics) [PSYoungGen: 16640K-&gt;16388K(611840K)] [ParOldGen: 893167K-&gt;892384K(1358336K)] 909807K-&gt;908773K(1970176K), [Metaspace: 44412K-&gt;44412K(1091584K)], 0.5756780 secs] [Times: user=2.70 sys=0.19, real=0.58 secs]</p></blockquote><p>其中最需注意的是，GC类型-原因、一次GC后内存回收的效果、GC时长。</p><ul><li><p><code>GC (Allocation Failure)</code>：GC类型 - Young GC，原因 - 内存分配失败。</p></li><li><p><code>PSYoungGen: 581178K-&gt;16640K(611840K)</code>：新生代从 581178K 降到 16640K，当前新生代总大小 611840K。</p></li><li><p><code>925472K-&gt;909807K(1511936K)</code>: 堆从 925472K 降到 909807K，当前堆总大小 1511936K。</p></li><li><p>此次GC执行时长0.5084573秒。此时间是物理感知的绝对时间，与后面的real相同。</p></li><li><p><code>Full GC (Ergonomics)</code> GC类型 - Full GC，原因 - 内存调整，具体由垃圾回收器类型决定。</p></li><li><p><code>ParOldGen: 893167K-&gt;892384K(1358336K)</code>: 老生代从 893167K 降到 892384K， 当前老生代总大小 1358336K。</p></li><li><p><code>909807K-&gt;908773K(1970176K)</code>: 堆从 909807K 降到 908773K，当前堆总大小 1970176K。</p></li><li><p><code>Metaspace: 44412K-&gt;44412K(1091584K)</code>: metaspace 从 44412K 无下降，当前 metaspace 总大小 1091584K。</p></li></ul><p>关键概念：</p><ul><li><p>垃圾回收器类型。<br>-XX:UseParallelGC 是JDK9之前server模式下的默认回收器，使用的是Parallel Scavenge +  ParOld 的收集器组合进行内存回收。<br>即新生代是GC多线程、标记-整理的GC算法，老生代是GC多线程、标记-整理的GC算法。<br>此款垃圾回收器，是以吞吐量为目的，即在执行垃圾回收工作的同时，尽量让应用系统被阻塞更短的时间。<br><code>吞吐量 = （运行用户代码的时间）/ (运行用户代码的时间 + 运行垃圾回收的时间)</code><br>同时，在CMS/G1之前的通用垃圾回收器，都有JVM申请内存之后不会归还给系统的问题。在CMS得到缓解，G1已经可以做到及时归还。</p></li><li><p>MinorGC（YoungGC）\ MajorGC(Full GC)。<br>Full GC 实际上可以对堆（新生代+老生代）、metaspace、直接内存都产生垃圾回收效果。特别是直接内存，虽然直接内存使用的是JVM外部的内存空间，但对象句柄引用最终是放在JVM堆中，因此在full GC释放掉堆内的对象引用时，也可以造成直接内存释放的效果。</p></li></ul><p>查看GC状态也不是仅看某个时间点的快照值就可得出问题结论，也需要沿着时间轴观察一段时间下的GC效果。<br>比如，上面的例子中，可以看到第二次Full GC几乎没有什么回收效果，背后可能是大量耗费内存的请求压力造成的，这时候就需要在压力峰值降下来再次观察。</p><p>这时候，如果有线上GC的状态监视工具，可以直接查看此段事件的GC数据。如果没有监视工具 或者 GC分析数据不全，可以将GC logs导入到本地的离线分析工具，比如<a href="https://github.com/chewiebug/GCViewer">GCViewer</a>。</p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-gc-viewer.png" alt="gc viewer"></p><p>还有一些工具提供实时监控heap状态：</p><pre class="line-numbers language-none"><code class="language-none">$ jstat -gcutil &lt;pid&gt; 1000 100<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>含义：</strong><br>实时监控JVM 堆使用大小、GC的次数和时间。每1000毫秒刷新一次，一共刷新100次。</p><p>通过查看GC状态获知内存被大量分配的是哪几个区域，各区域的增长速率、gc触发的频率和耗时。</p><h4 id="2-2-3-手动生成-heapdump-文件">2.2.3 手动生成 heapdump 文件</h4><p>当无 <code>OutOfMemoryError</code> 产生，但内存利用率异常时，可以使用 <code>jcmd</code> 手动生成 / 获取heap dump文件。</p><p><code>heapdump</code> 文件是当前JVM容器的内存分析快照，一般尝试分析内存问题时，需要在不同维度多次生成 heapdump 文件，用以横向对比（不同JVM之间）或者 纵向对比（同一JVM不同时间阶段之间）。</p>  <pre class="line-numbers language-none"><code class="language-none">$ jcmd -l$ jcmd &lt;pid&gt; GC.heap_dump /tmp/java_pid&lt;pid&gt;.hprof <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>含义</strong>：</p><ul><li><code>jcmd -l</code> 展示所有 JVM 进程，通过该命令获取application的进程id。</li><li>根据pid，使用命令 <code>jcmd GC.heap_dump</code> 生成heap dump到目标文件路径。<br>该命令默认生成 <code>live objects</code> 的数据，因此在生成dump文件前，会执行一次full GC。如果不想强制执行full GC，则可以带上options <code>-all</code>, 这时会生成所有 <code>objects</code> 的数据。</li></ul><h4 id="2-2-4-分析Heap-dump文件">2.2.4 分析Heap dump文件</h4><p>分析heapdump文件的目的，是为了获取最有嫌疑的占用内存的大对象 或 多数对象以及上下文。</p><p>常用的开源免费工具有 MAT、VisualVM、JProfiler。</p><ul><li><p>MAT（Memory Analyzer Tool），出自eclipse，可以单独安装使用；</p></li><li><p>VisualVM，部分JDK自带。不带的版本，需要另行下载安装；</p></li><li><p>JProfiler，已经与Intellij IDEA集成，可以直接在Intellij IDEA上使用；</p></li></ul><p>对于离线分析，MAT优势比较大，优先推荐。MAT提供更详细和直观的 Leak Suspect report 和 Top Components report，在工具台中还可以交互进行更细节的定位。</p><p><strong>Lead Suspect report</strong> 中主要关注几个部分：</p><p><strong>1. Leak Suspect report的全局图</strong></p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-MAT-leaksuspect-1.png" alt="MAT leaksuspect report"></p><p><strong>图中含义</strong>:</p><p>在tomcat线程运行时，有一个对象实例 <code>Object[]</code> 拿住了456M内存，占用堆内存的97.41%。该实例不一定是内存泄露，但作为消耗内存的大对象，依然值得排查。</p><p>点击最下面的链接 <code>Details &gt;&gt;</code> 可以查看分析详情：</p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-MAT-leak-suspect-2.png" alt="MAT leaksuspect report details"></p><p><code>Details &gt;&gt;</code> 一般分为几项：</p><ul><li><p>Shortest Paths To the Accumulation Point：从GC roots 到达 <code>累积点</code> 的最短路径；</p></li><li><p>Accumulated Objects in Dominator Tree：显示累积对象的 <code>Dominator Tree</code> (统治者树)；</p></li><li><p>Accumulated Objects by Class in Dominator Tree：显示累积类的 <code>Dominator Tree</code>（统治者树）；</p></li><li><p>All Accumulated Objects by Class：显示累积类对应的实例数量和一共占用的Shallow Heap。</p></li></ul><p><strong>关键概念：</strong></p><ul><li><p>Shortest paths<br>在Java回收机制中，使用的是可达性分析算法。对象是否要被GC，需要运算从GC roots对象开始，搜索引用链，以此证明该对象不可达。不可达的对象，会被垃圾回收，如果该对象无法被回收，则存在内存泄露。</p></li><li><p>Dominator Tree<br>当对象<code>Object B</code> 被 <code>Object A</code> 引用而造成无法释放的情况，这时候<code>Object A</code> 就是 <code>Object B</code> 的统治者。</p></li><li><p>Shallow Heap &amp; Retained Heap<br>对象自身占用的内存大小，即是Shallow Heap。<br>如果：对象<code>Object B</code> 被 <code>Object A</code> 引用而造成无法释放的情况（Object B 不再引用其他对象），这时候<br><code>Object A Retained Heap = Object A Shallow Heap + Object B Shallow Heap</code></p></li></ul><p>当获取了Leak Suspect对象以及类型, 以及上面的 <code>Details</code> 项，在对这些类型背后的代码获得了解的情况下，很容易找到是哪部分代码执行过程中出现了偏差 —— 注意，仅是执行过程中出现偏差，不一定是问题的根因。<br>在JVM中所有线程和任务对于CPU、内存、磁盘的资源占用都是共享的，因此问题的根因需要再次推导。</p><p>当然，也有比较简单的场景，可以只指根因的。</p><p><strong>2. Top Customers</strong></p><p>在MAT  <code>Leak Suspect report</code> 中除了可以查看Lead suspect objects，还可以通过 <code>Top Customers</code> 目录查看更多的内存消费者排行。</p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-MAT-top-customers.png" alt="Top Customers 1"></p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-MAT-top-consumers-2.png" alt="Top Customers 2"></p><p><strong>3. 辅助查看部分Class Histogram和Thread Overview</strong></p><p><code>class Histogram</code> 类直方图，按Retained Heap排序，体现JVM class生成了多少实例，并且占据了多少内存。</p><p>由于展示图的顶层大部分是Java内部类型，缺少必要的诊断上下文，因此按内存占用大小挨个查看。<br>在有具体的聚焦对象时，可以作为辅助工具查看。</p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-MAT-class-histo.png" alt="类直方图"></p><p>比如，上图中shallow Heap占用特别大的<code>int[]</code>，在MAT工具中，可以通过点击<code>list objects-&gt; with incoming reference</code>，显示其实际被哪里引用，从而查找到 hold 住这块些内存的程序位置。<br>下图是最简单的API controller hold住内存，因此容易查找和定位。而如果是跨API的框架和基础设施代码，则需要进一步的分析和定位。</p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-list-incoming-objects.png" alt="list-incoming-objects"></p><p><code>Thread overview</code> 线程总览，可以看到所有线程的状态。<br>由于内存对象的GC roots并不一定是线程，所以此图仅对发现<code>Dominator</code>是线程的对象内存有效，一般作为辅助查看。<br><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-MAT-thread-overview.png" alt="list-thread"></p><h2 id="3-JVM-CPU-利用率高">3. JVM CPU 利用率高</h2><h3 id="3-1-首先查看JVM中是哪些线程对CPU的占用率高">3.1 首先查看JVM中是哪些线程对CPU的占用率高</h3><p>使用Top命令行：</p><pre class="line-numbers language-none"><code class="language-none">$ top -Hp &lt;pid&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查看CPU占用高的线程ID，记录下这些线程ID。</p><h3 id="3-2-使用jcmd-dump-thread">3.2 使用jcmd dump thread</h3><p>使用jcmd命令行：</p><pre class="line-numbers language-none"><code class="language-none">$ jcmd $pid Thread.print &gt; ./manual.tdump<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-3-将之前记录的线程ID，进行十六进制转换">3.3 将之前记录的线程ID，进行十六进制转换</h3><p>Linux原生命令行：</p><pre class="line-numbers language-none"><code class="language-none">printf "%x\n" &lt;tid&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-4-将Threaddump文件导入TMDA工具">3.4 将Threaddump文件导入<code>TMDA</code>工具</h3><p><a href="https://www.ibm.com/support/pages/ibm-thread-and-monitor-dump-analyzer-java-tmda">TMDA</a>工具，IBM线程离线分析工具。</p><p>打开 <code>Thread Details</code>, 使用16进制的 threadID 在<code>NativeID</code>（dump源文件中是<code>nid</code>）对应查找到线程状态、调用栈。</p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-tmda-stack.png" alt="tmda-stack"></p><p>通过分析调用栈，获取相关线程执行的程序位置。<br>当可疑线程是GC线程时，结合内存分析工具一起诊断。</p><p>如果单次 threaddump 分析结果无可疑，可以通过多次生成 threaddump 文件进行时间上纵向对比。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微服务线上治理之监控</title>
      <link href="/2021/01/18/wei-fu-wu-xian-shang-zhi-li-zhi-jian-kong/"/>
      <url>/2021/01/18/wei-fu-wu-xian-shang-zhi-li-zhi-jian-kong/</url>
      
        <content type="html"><![CDATA[<p>微服务架构已经是时下后端应用开发的主流架构之一。微服务的整个生命周期包括<code>微服务拆分和定义（产品规划）</code>、<code>微服务研发</code>、<code>微服务构建与部署</code>、<code>监控与运维</code>几个阶段。</p><p>对于一般企业的微服务改造而言，极少部分企业认为用上微服务概念 + Spring cloud套件就是整活微服务架构了；一部分企业还能认识到针对微服务构建和部署所必需的DevOps流水线或平台；接着，越来越多的企业开始接受支持微服务拆分和设计思想的<code>Domain Driven Design</code>；在完成前三步的基础上，最终还有少部分企业意识到线上分布式系统带来的复杂性，需要进行微服务线上治理——分层次的监控、诊断及最终的治理方案。</p><p>这里就主要从可观测性、层次性、时效性上，聊聊微服务线上治理中的监控。</p><span id="more"></span><h3 id="1-系统运行时的可观测性">1. 系统运行时的可观测性</h3><p>微服务线上治理的前提——采集线上运行时数据，让系统状态与流程可被实时度量和监控。</p><p>管理学之⽗德鲁克曾经说过:“如果你无法度量它，就无法改进它。”</p><p>然而对于今天——在各系统存在各种五花八门、各式各样、大量指标数据的当下，如何整合这些指标，在度量的同时，提升整个系统运行时的可观测性，以达到及时地发现问题、定位问题的目的，才是微服务线上治理的基础。</p><p>理论上，问题越早发现、越早修复，可以越节省研发成本。一些微服务的问题，在规划、研发、构建等阶段，可以通过线下微服务治理的方式提前解决掉。</p><p>然而，对于微服务能力不同、或者理解不同的各企业和团队来说，部分团队需要等到系统被部署到线上运行时才能真正发现和正视问题。</p><p>当你面临的团队，不追求clean architecture、不写测试、不坚持重构、没有性能测试和联调测试、甚至没有太多有经验的开发，这时候，线上系统监控将成为最后的反馈堡垒。</p><p>因此，带有观测性的线上监控能力是各个微服务团队必不可少的“看家”工具之一。</p><p>业内能做到线上监控的开源产品和商业产品不一而足。大家可能见过下面这样的（监控微服务状态、微服务之间调用等）：<br><img src="/2021/01/18/wei-fu-wu-xian-shang-zhi-li-zhi-jian-kong/image-spring_boot_dashboard.png" alt="图1"><br><em>（图 1）</em></p><p>或者是，监控 服务对资源CPU、内存、磁盘等利用率趋势：</p><p><img src="/2021/01/18/wei-fu-wu-xian-shang-zhi-li-zhi-jian-kong/image-grafana_jvm_dashboard.png" alt="图2"><br><em>（图 2）</em></p><p>也有API调用量、失败率、延时时长的TopN统计：</p><p><img src="/2021/01/18/wei-fu-wu-xian-shang-zhi-li-zhi-jian-kong/image-app_api.png" alt="图3"><br><em>（图 3）</em></p><p>或者，是基于动态链路技术实现的链路图：</p><p><img src="/2021/01/18/wei-fu-wu-xian-shang-zhi-li-zhi-jian-kong/image-dynamic_invoking_graph.png" alt="图4"><br><em>（图 4）</em></p><h3 id="2-监控需要分层次">2. 监控需要分层次</h3><p>看过上面四种监控示例图，相信有不少做过线上问题诊断的同事会认为：不少指标过于细，或者过于底层，对于发现实际问题和定位问题毫无帮助。</p><p>当经过详细调研分析和使用之后，本人发现这些监控模型是应该分层次来理解和使用的。</p><p><img src="/2021/01/18/wei-fu-wu-xian-shang-zhi-li-zhi-jian-kong/image-layers.png" alt="图5"></p><p>一共分为<code>基础状态层</code>、<code>资源占用层</code>、<code>API层</code>、<code>链路层</code>。</p><ul><li>基础状态层：各微服务和基础设施服务（比如数据库）的生效配置及实时状态，如健康度、熔断器状态、限流阀状态、灰度状态等等。（示例图1）</li><li>资源占用层：各微服务和基础设施服务对资源的占用，比如微服务对系统CPU、内存、磁盘等的占用率，微服务内部堆栈对内存的利用率等等。（示例图2）</li><li>API层：各微服务的API性能，API方式包括且不限于http restful API、messageQueue consumer等等；同时，基础设施服务，比如数据库，SQL本身可以理解为一种特殊的API，因此慢SQL统计和监控，也可以算入API层。（示例图3）</li><li>链路层：统计和追踪由服务请求发起的整个系统内部链路的流转，包括微服务之间、微服务与基础设施服务之间的链路。微服务之间的调用方式包括且不限于http restful、messageQueue等等。（示例图4）</li></ul><p>越靠近<code>技术底层</code>，指标越孤立，对服务的影响面越广，越难直接定位问题；</p><p>越靠近<code>应用层</code>，指标越具象，影响面越小，越容易定位问题。</p><p>当然也有人会认为，在这种分层结构中，应该将基础设施服务单独拎出来作为一个单独分类  —— 的确也是无不可，除了链路层以外，基础设施服务可以独立完成另外三层的纵向切片。</p><h3 id="3-监控需要时效性">3. 监控需要时效性</h3><p>在搭建监控工具 或者 接入监控平台时，面对于采集日志、指标的实时运算方式，大多数情况团队都默认监控是实时的 —— 这样能及时发现和响应问题。</p><p>并且大部分监控工具，做到了监控自动化，进行实时预警，及时通知到相关人员处理问题；或者，有部分DevOps监控平台甚至可以做到自动化AI管控，针对<code>基础状态层</code>、<code>资源占用层</code>出现的问题，使用资源临时扩容、资源切换/重启等策略进行线上自动恢复。</p><p>然而，随着Q/TPS、数据量的增长，监控服务资源升级的滞后 或 架构的不合理，监控延时的误差会越来越大。</p><p>当监控的时效性越来越偏离实时，团队对于系统运行时快速发现和响应问题的效率将大打折扣。</p>]]></content>
      
      
      <categories>
          
          <category> 微服务治理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微服务治理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL InnoDB 聚集索引数据结构</title>
      <link href="/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/"/>
      <url>/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/</url>
      
        <content type="html"><![CDATA[<blockquote><p>关系型数据库系统的世界是非常复杂的 —— 如果我们思考一下我们需要做哪些事情才能满足SQL语句的查询需求，就能意识到这种复杂是必然的。但具有讽刺意味的是，书写SQL是如此简单，表、行与列的概念也非常容易理解。</p><p>​—— 《数据库索引设计和优化》</p></blockquote><span id="more"></span><h3 id="1-页-Page">1. 页 (Page)</h3><p>页，是数据库数据存储方式的逻辑结构。</p><p>Innodb 采用将存储数据按表空间（tablespace）的方式进行存放。如果没有开启 <code>innodb_file_per_table</code> 设置，新的表的创建会保存进默认的系统共享表空间。</p><pre class="line-numbers language-none"><code class="language-none">mysql&gt; show variables like 'innodb_file_per_table';+-----------------------+-------+| Variable_name         | Value |+-----------------------+-------+| innodb_file_per_table | ON    |+-----------------------+-------+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当 <code>innodb_file_per_table</code> 等于 <code>ON</code> 时，会给每个表创建独立的数据文件。</p><p>比如，在数据库 <code>test</code> 中创建一个表 <code>show_index</code> ，在mysql 的 dataDirectory 目录下就回出现一个名为 <code>show_index.ibd</code> 的数据文件。</p><p>在单个表的数据文件中，数据就是以多个页的形式进行排列。MySQL默认配置下，每16K，即为一个页。</p><p>借用了《MySQL技术内幕Innodb存储引擎》作者的工具<code>py_innodb_page_type.py</code>，可以查看到单表数据文件的页组成：</p><p><img src="/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/image-py-innodb-page-info.png" alt="图1 file_per_table tablespace结构图"></p><p>MySQL中数据页和索引页，都被归类为B Tree Node类型，严格来说应该是B+ Tree Node。</p><h3 id="2-B-Tree-Node">2. B+ Tree Node</h3><p>B+ Tree概念，需要区分二叉树（Binary Tree）、二叉查找树（BST）、B-Tree（B: Balance）。</p><p>在MySQL innodb中，叶子节点页的page level为0，非叶子节点页的page level &gt; 0。</p><p><img src="/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/image-B+tree.png" alt="图2 聚集索引的B+ Tree图"></p><p>上图是一个聚集索引的B+ Tree图。</p><p>1个B+ Tree Node，占据一个页。</p><ul><li>在索引页，页的主要记录部分(<code>User Records</code>)存放的<code>Record</code> = <code>record header</code> + <code>index key</code> + <code>page pointer</code>。</li><li>在数据页，则是按表创建时的<code>row_format</code>类型存放完整数据行记录。<br>row_format类型分别有：<code>Compact</code>、<code>Redundant</code>、<code>Compressed</code>和<code>Dynamic</code>。</li></ul><p>因此，在聚集索引中，非叶子节点都为索引页，叶子节点为数据页；</p><p>在辅助索引中，非叶子节点和叶子节点都为索引页。不同的是，叶子节点里记录的是聚集索引中的主键ID值。</p><p>注意，在索引页的Record中的<code>page pointer</code>，指向的是页，而非具体的记录行。并且Record的<code>index key</code>，为指向的page records的起始键值。</p><h4 id="2-1-聚集索引-Cluster-index">2.1. 聚集索引 (Cluster index)</h4><p>MySQL将数据存放在聚集索引的叶子节点中，由索引进行组织。因此也可称为，数据即索引，索引即数据，在整个页分类中，都被列为<code>B+ Tree Node</code>。</p><p>图2 即是一个完整的聚集索引的B+ Tree结构展现。</p><p>在叶子节点是如何实现双向链接的结构，可以详细看下页内的组织分布。</p><p>在表空间文件的一个页的结构上，内容布局为：</p><p><img src="/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/image-page-structure.png" alt="图3 页的结构组成图"></p><p>在聚集索引中，数据页内除了按照主键大小进行记录存放以外，在<code>File header</code>中，有两个字段：<code>fil_page_prev</code> 和<code>fil_page_next</code>, 分别记录了上一页/下一页的偏移量（offset），用以实现数据页在B+ Tree叶子位置的双向链表结构。</p><h3 id="3-数据检索">3. 数据检索</h3><p>通过B+ Tree结构，可以明显看到，通过B+ Tree查找，可以定位到索引最后指向的数据页，并不能找到具体的记录本身。</p><p>这时，数据库会将该页加载到内存中，然后通过<code>Page Directory</code>进行二分查找。</p><h4 id="3-1-Page-Directory">3.1. Page Directory</h4><p><code>Page Directory</code>是该页存放的<code>User Records</code>的一个稀疏目录，存放的内容是Record在页内的相对位置。每两个字节，记录一个相对位置，从邻近<code>File Trailer</code>的位置开始倒排存放。</p><p><img src="/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/image-page-directory.png" alt="image-20210107214107410"></p><p><code>Page Directory</code>中每两个字节，代表一个目录槽。在上图中，一共有6个槽。</p><p>在页首的<code>Page Header</code>部分有一个<code>Page_N_Dir_Slots</code>的字段 —— 同样记录了目录槽的数量。</p><p>一个目录槽，对应按序的多条记录。记录的相对位置，指向这批记录的第一条记录。</p><p>每条记录都有<code>Record header</code>, 但目录槽 指向的第一条记录的<code>Record Header</code>中第4~8位（bits），是<code>n_owned</code>值，代表该目录槽中拥有的记录数量。</p><p><code>Record header</code>的组织结构：</p><p><img src="/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/image-record-header.png" alt="image-20210107214322598"></p><p>比如下图，一共有6个目录槽，大部分目录槽中有4条记录。</p><p><img src="/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/image-page-slots.png" alt="image-20210107204730744"></p><h3 id="4-总结">4. 总结</h3><p>MySQL Innodb通过页组织成的B+ Tree Nodes结构 和 Page Directory，完成了具体记录的检索。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>研发效能之层级测试</title>
      <link href="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/"/>
      <url>/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/</url>
      
        <content type="html"><![CDATA[<p>研发效能不等于研发效率。</p><p>在我司的<code>研发平台解决方案</code>的定义中，研发效能 = 可持续快速交付价值的能力 = 效率 + 质量 + 用户价值。</p><p>如果不能达到相应的质量标准和用户价值，再高的研发效率也是枉然。</p><p>这里我专门聊一下效率和质量之间的结合一个点。</p><h3 id="1-在对质量的追求中，如何优化研发效率？">1. 在对质量的追求中，如何优化研发效率？</h3><span id="more"></span><p>在敏捷团队里，开发人员往往被要求编写单元测试、集成测试、契约测试等等自动化测试，并且在 CI 流水线上创建对应的<code>test stage</code>，通过每次提交代码后重复运行 —— 来获取测试情况，以此来增添交付质量的保证。</p><p><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/CI%E6%B5%81%E6%B0%B4%E7%BA%BF.png" alt="CI流水线"></p><p>CI 流水线上运行的自动化测试，大家一定不陌生 —— 一次编写、重复运行、变更时及时维护。</p><p>对团队而言，<strong>可视化</strong>、最直观的就是，测试的运行效率、运行时长。</p><p>因此，团队会尽量缩短测试集的运行时长，以达到快速反馈和提高流水线的及时使用率。</p><p>同时，快速的测试运行效率，也可以缩短开发人员进行代码预提交的检查时间。</p><p>在一般__不可视化__的角落，其实还有日常的测试编写和维护的效率。</p><p>当团队要求较高的代码覆盖率时，往往一个 story 的开发时间中，可能有一半左右用以编写上述自动化测试。</p><p>所以，在研发效能度量中，自动化测试的效率包括两个部分：</p><p><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E7%9A%84%E6%95%88%E7%8E%87.png" alt="自动化测试的效率"></p><p>不仅要优化测试集的运行效率，同时还要优化测试编写的效率。</p><h3 id="2-测试金字塔是个合适的策略">2. 测试金字塔是个合适的策略</h3><p><a href="https://martinfowler.com/bliki/TestPyramid.html">测试金字塔</a>主导思想就是，通过不同的测试类型组合，来达到质量与投入产出比的一个平衡取舍 —— 以合适的投入产出比，来获取一个较高的质量。</p><p>除开硬件资源的投入（如 CI 资源），投入产出比与研发效率是线性的关系。</p><p>测试金字塔中，底层的单元测试拥有反馈快、代价低、单一职责的特点，因此作为基数最大的基层测试 —— 用以覆盖绝大部分代码逻辑。</p><p>基于单元测试上的其他上层测试，主要以其他角度弥补单元测试的不足，如组件完整性等等，同时它们面临的问题越来越复杂、范围越来越广，启动和运行的过程也会越来越重，编写和维护成本也越高。</p><p>因此，运用测试金字塔，利用大量的底层单元测试来尽量覆盖代码逻辑，是同时优化<code>测试编写效率</code>和<code>测试集运行效率</code>的一把有利钥匙。</p><h3 id="3-单元测试覆盖所有代码逻辑-——-不可能做到？">3. 单元测试覆盖所有代码逻辑 —— 不可能做到？</h3><p>以服务架构举例，从传统的分层架构说起。（代码术语以Java/Spring为背景。）<br><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/%E4%BC%A0%E7%BB%9F%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84.png" alt="传统分层架构"></p><p>从技术实现角度来讲，只有其中的 application 层和 domain 层可以实现真正意义的单元测试 —— 只测试单元本身，仅使用 Junit + mokito，测试反馈总时长在秒级以内。</p><p>从代码实现来看，user interfaces 和 persistence 其实也可以仅使用 Junit + mokito 来编写单元测试。<br>但问题是：这两层只使用单元测试来测方法体本身，没有意义。</p><h4 id="3-1-是否要单独测试-user-interfaces-和-persist-层？">3.1. 是否要单独测试 user interfaces 和 persist 层？</h4><p>这里有块示例代码，见下。<br>user interfaces 里面定义的基于 Spring MVC 的 controller，看起来方法体内只有一两行代码，同时下层 applicationService 和 mapper 逻辑已经由自身单元测试覆盖了。</p><pre class="line-numbers language-none"><code class="language-none">@GetMapping("/customers/{customerId}/projects/{projectId}")@PreAuthorize("hasRole('USER')")@ResponseStatus(HttpStatus.OK)Set&lt;LatestPipelineInfoResponse&gt; fetchLatestUploadInfo(@PathVariable @Min(0) Long customerId, @PathVariable Long projectId){    Set&lt;LatestPipelineInfoDTO&gt; dtos = this.service.fetchLatestUploadInfo(customerId, projectId);    return LatestPipelineInfoResponseMapper.MAPPER.fromDto(dtos);}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果使用单元测试，仅仅测的是 controller 对 service 和 mapper 的成功调用，意义很小。</p><p>我们这看一下上面这个controller method背后覆盖了多少逻辑：</p><ul><li><p>监听http request</p></li><li><p>将http request中的数据反序列化转换成Java objects, 注入到方法调用的入参中</p></li><li><p>验证入参</p></li><li><p>验证 security 权限</p></li><li><p>调用业务逻辑</p></li><li><p>将业务逻辑返回的Java objects序列化返回到response中</p></li><li><p>处理以上环节中发生的异常</p><p>一共7项，虽然代码实现起来很简单，这是因为 Spring 框架帮开发人员简化了很多代码量。<br>单独测试user interfaces层，并不是说要测 Spring 提供的框架能力，而是要测这块定制代码最终实现的是 —— “正如你所愿”。</p></li></ul><p>相同道理，在persist层，如果代码里有复杂的逻辑，比如动态查询，或者直接HSQL、SQL。如：</p><pre class="line-numbers language-none"><code class="language-none">public interface PipelineHistoryJpaRepository extends        JpaRepository&lt;PipelineHistory, String&gt; {    @Query(nativeQuery = true, value = "SELECT * FROM pipeline_histories p, " +            "(SELECT max(id) AS id FROM pipeline_histories " +            "GROUP BY customer_id, project_id, pipeline_name) tmp " +            "WHERE p.id = tmp.id " +            "ORDER BY customer_id, project_id, pipeline_name")    public List&lt;PipelineHistory&gt; fetchAllExistsPipeline();}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>persist层逻辑，也需要使用测试覆盖。<br>当然，如果是JPA自动生成的findBy、save等等系列，不在这块范围之内。</p><h4 id="3-2-如何单独测-user-interfaces-和-persist-层？">3.2. 如何单独测 user interfaces 和 persist 层？</h4><p>user interfaces 和 persist 层因为框架和工具的原因，只能带上Spring application context一起启动测试。<br>正常来说，它们已经算是集成测试了，集成了 Spring 容器。</p><p>用过 @SpringBootTest 的人，一定对其造成的测试编写效率和运行效率印象深刻 —— 可能只是添加了几个 Bean，就会让 context 的启动时间延长几秒，不恰当地使用某些test annotation也会造成context的重新加载和刷新。</p><p>本人也用过很长一段时间 —— 通过 API 调用整个组件（<code>controller </code>-&gt; <code>servcie</code>-&gt;<code>repository</code>-&gt;<code>memory db</code>）, 以实现对user interfaces 和 persist 层的覆盖。即使在成功优化Spring加载机制 —— 每次批量运行测试用例仅加载一次 application context，但每次编写新的API测试、修复API测试仍然痛苦不已 —— 每次运行单条测试进行反馈时，依然要等待一次完整的 context 启动。</p><p>因此，这里推荐使用Spring提供的切片测试工具（Tests Slices）: @WebMvcTest、@DataJpaTest。其原理是仅创建简化的application context，少量的bean，使用轻量级、有针对性范围的方式，降低反馈时间、提升测试性能。<br>在编写测试、运行测试的性能上，切片测试的反馈效率的确赶不上单元测试，但对比 @SpringBootTest 加载几乎完整 context 的情况已经优化不少。</p><h4 id="3-3-最终的目的：利用基层的测试来整体覆盖代码逻辑">3.3. 最终的目的：利用基层的测试来整体覆盖代码逻辑</h4><p>回到之前的问题：技术意义上的单元测试的确不能覆盖所有代码逻辑。</p><p>但，<code>单元测试</code> + <code>轻量级的、快速反馈的 slice tests</code> 可以尽量覆盖到所有代码逻辑。</p><p>因为<code>单元测试 + slice tests</code>的目标是为了完成分层架构内的逻辑测试，为了避免语义上的冲突，因此这里将两者一起称为<code>层级测试</code>。<br>除了传统的分层架构，也来看看六边形架构、或者叫接口适配器架构是不是适合进行<code>分层测试</code>呢？<br>其实不然，六边形架构在宏观意义上，其实可以看成是“两层” —— domain 和 infrastructure。<br><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/%E5%85%AD%E8%BE%B9%E5%BD%A2%E6%9E%B6%E6%9E%84.png" alt="六边形架构"><br>正好对照了 unit tests 和 slice tests 的分界。<br>而这两层的区别，在于 unit tests 测试的是系统中稳定的业务层，可以尽量多的追求代码覆盖率；而slice tests 测试的是对基础设施的依赖适配和定制逻辑，追求定制逻辑的功能覆盖。<br>最终同样得以完成对 ”代码逻辑“ 的整体测试覆盖。</p><h3 id="题外：">题外：</h3><h4 id="1-API集成测试（API-Integration-Tests）">1. API集成测试（API Integration Tests）</h4><p><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/API%E9%9B%86%E6%88%90%E6%B5%8B%E8%AF%95.png" alt="API集成测试"><br>在完成前面的层级测试、覆盖了所有逻辑细节之后，就轮到跨层级的连通性测试了。<br>这里虽然命名为“API集成测试”，其实也叫“组件测试”。由于系统架构由来已久，到微服务架构的时候，一个组件的边界已经是一个微服务的边界，针对微服务的API特性, 这篇文章里称其为“API集成测试”。</p><p>基于测试运行的可重复性，API集成测试中需要降低对外界的依赖，比如微服务在真实环境中对数据库、外部服务的依赖。</p><p>数据库可以替换成能力相同的内存式、或嵌入式数据库，比如生产mysql\mariaDB 可替换成 mariadb4j 实现嵌入式数据库；外部服务依赖，使用服务边界mock进行统一管理。</p><p>借用**<a href="http://github.com/tobyclemson">Toby Clemson</a>** 的一张微服务组件测试的图，橙色的虚线正是组件测试的边界。<a href="https://martinfowler.com/articles/microservice-testing/">原图来源</a></p><p><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/%E7%BB%84%E4%BB%B6%E6%B5%8B%E8%AF%95.png" alt="组件测试"></p><p>使用 API 集成测试实现组件内部的连通性测试，一般测试路径选择覆盖层级完整的 happy path，不要企图去测试各逻辑分支。</p><p>举个例子：</p><p>一般写API集成测试的时候，常会遇到层级间“传递参数缺少校验“的问题，如 controller 调用 applicationService 时，入参传递了一个未预料的<code>null</code> 值，这个<code>null</code>值的校验，应该由具体代码 controller 与 applicationService 之间进行约定：可以是接收方编写防御性校验，也可以由调用方前瞻性校验。</p><p>因此，此处<code>null</code>值校验的逻辑完全是可以在 Layer tests中由测试覆盖。不要试图在API集成测试中覆盖这个<code>null</code>和<code>非null</code>分支。</p><h4 id="2-契约测试-Contract-Tests">2. 契约测试(Contract Tests)</h4><p>之前测完各层级逻辑、组件内的调用连通性，接着来看一下微服务边界的契约测试。</p><p><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/%E5%A5%91%E7%BA%A6%E6%B5%8B%E8%AF%95.png" alt="契约测试"></p><h5 id="契约-vs-API">契约 vs API</h5><p>对于契约测试，首先要避免进入 —— 一条API就应该是一个契约的误区。</p><p>记住，契约测试有个“首要精神“：<code>消费者驱动契约（Consumer Driven Contracts）</code>。</p><p>举个例子：</p><p><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/%E5%A5%91%E7%BA%A6.png" alt="契约"></p><p>服务producer，本身实现了一条API，返回资源 —— 每个会员的详细信息，包括：<code>id</code>、<code>age</code>、<code>name</code>。</p><p>服务consumer I、II、III知道 producer 服务可以提供会员信息资源，于是分别来与producer谈需求、谈集成，最终形成两份需求约定，见上图。</p><p>差别是：一份约定必须返回<code>id</code>和<code>age</code>字段，另一份约定必须返回<code>id</code>和<code>name</code>字段。</p><p>这也就形成了两份契约 —— 是根据消费者的需求直接驱动的。</p><p>从 consumer 角度来看，根本不关心 producer 的API是否是复用，这里只是恰好多个契约可以共用一条API而已，因此每个consumer的基本诉求就是 —— 无论之后API的实现如何变动，都不能影响自己契约内的数据。</p><p>接着在需求发布以后，consumer III的需求需要变动 —— 将返回的<code>name</code>字段，分切成<code>firstName</code>和<code>lastName</code>，这时候就形成了第三份<code>契约C</code>。无论具体API如何变更，都有两个基本的安全校验阀在那里：<code>契约A</code>和<code>契约B</code>。</p><p>也许有人会说不需要<code>契约C</code>，为了省事儿consumer III拿上<code>name</code>字段自己拆嘛。这种思路在现实谈需求、谈集成中其实经常会碰到。 这里一个小的玩笑：请告诉我，你觉得”金城武“是姓”金城“，还是姓”金“？</p><h5 id="契约测试需要双方维护">契约测试需要双方维护</h5><p><code>契约（contract）</code>以满足consumer需求为目的，以consumer定义为主导，但 producer / customer 双方都有校验契约交付物的权利和义务 。</p><p><code>契约测试</code>，首先运行在producer的<code>auto test</code>中，以保证任何时候 producer 代码变更之后都满足契约。</p><p>同时该契约需要生成stub，提供给 consumer 以作为test double，consumer 依赖此契约的场景使用测试覆盖，以保证契约被变更时 consumer 能够及时获知。</p><h5 id="不要滥用契约测试">不要滥用契约测试</h5><p>契约中主要约定是三部分：<code>调用方式</code>、<code>数据类型</code>、<code>数据格式</code>。因此契约测试主要校验的是这三部分，不包括数据值。</p><p>并且每一份契约的形成和变更，都会涉及到两方团队的沟通、协议和实现，比单元测试、API 集成测试 —— 代价高，效率低。</p><p>因此，契约测试在测试金字塔中位于 API 集成测试上方。</p><p>除了<code>调用方式</code>、<code>数据类型</code>、<code>数据格式</code>外，需要使用单元测试、API 集成测试的方式覆盖。</p><h4 id="3-E2E测试">3. E2E测试</h4><p>在软件研发阶段的 E2E 测试，一直有<code>无法稳定重复运行</code>、<code>代价高</code>、<code>效率低</code>等等问题，因此一直被放在测试金字塔的顶端。</p><p>在微服务架构、多微服务环境部署中，在 E2E 是基于环境、运行时的情况下，这些问题就更加突出。</p><p>因此，E2E 测试的目标和范围在团队中需要仔细的被定义。</p><p>在本文的上下文——研发阶段的质量内建，推荐仅将 E2E 测试作为基于几个关键业务场景的服务连通性测试。</p><p>当然，如果团队有一票专门来写E2E测试的人手，愿意承担高代价的成本、觉得这种ROI可以接受，也是可以多写写E2E测试的。</p>]]></content>
      
      
      <categories>
          
          <category> 敏捷精益软件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 敏捷测试 </tag>
            
            <tag> 研发效能 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在gradle管理可共享的依赖版本管理</title>
      <link href="/2020/06/05/zai-gradle-guan-li-ke-gong-xiang-de-yi-lai-ban-ben/"/>
      <url>/2020/06/05/zai-gradle-guan-li-ke-gong-xiang-de-yi-lai-ban-ben/</url>
      
        <content type="html"><![CDATA[<p>“可共享的依赖版本管理” —— 用过 Maven 的小伙伴们可能说，这不就是BOM么。<br>对，这里聊的就是如何使用 gradle 实现 BOM 生成和导入。<br>没用过 Maven 的小伙伴们也不用被劝退，想想在使用Spring plugin <code>io.spring.dependency-management</code>时，<br><code>imports.mavenBom</code>到底在做什么，有没有想要了解一下？</p><span id="more"></span><h3 id="1-BOM是什么？">1. BOM是什么？</h3><p>在说 BOM 之前，先了解一下 Maven 的一些基本概念。<br>Maven <strong>POM</strong>，全名 <code>Project Object Model</code>, 是 Maven 使用中的重要配置文件，xml格式，主要用来导入依赖和进行项目构建。<br>Maven <strong>BOM</strong>，全名 <code>Bill Of Materials</code>, 是一种特殊的 POM，主要用来集中管理项目依赖的版本，更加灵活地维护所有依赖的版本信息。<br>配置好的 BOM，可以放在单个项目中自用，也可以传阅和分享给其他项目进行公用。</p><p>讲的直观一点，效果就是（见下图）：<br><img src="/2020/06/05/zai-gradle-guan-li-ke-gong-xiang-de-yi-lai-ban-ben/Spring-dependencies-management.png" alt="Spring-dependencies-management"><br>dependencies中依赖的那些库为何可以不用标明版本？<br>正是因为使用了<em>dependency-management</em> 插件，当 gradle plugin <em>org.springframework.boot</em> 检测到此插件启用时，会自动导入Spring boot dependencies BOM，这样依赖库们会主动使用 BOM 中推荐的版本。<a href="https://docs.spring.io/spring-boot/docs/current/gradle-plugin/reference/html/#managing-dependencies">链接</a></p><p>下面是Spring Cloud BOM的一部分展示(完整见<a href="https://github.com/spring-cloud/spring-cloud-release/blob/vHoxton.SR5/spring-cloud-dependencies/pom.xml">链接</a>)：</p><p><img src="/2020/06/05/zai-gradle-guan-li-ke-gong-xiang-de-yi-lai-ban-ben/Spring-cloud-dependencies.png" alt="Spring-cloud-dependencies"></p><p>看到这里，是不是觉得有 BOM 的情况下便捷不少，再也不用一条条dependency分别查阅、选择和维护版本了？<br>日常开发中，我们已经见识过了Spring boot / Spring Cloud /junit 这些常用 BOMs。</p><p>当有了已经被验证过的依赖版本管理，setup projects时候直接拿来复用，是不是感觉省事不少？<br>同时 BOM 不可避免地还支持版本升级。<br>下面我们就来看看如何在 gradle 中定义我们自己的 BOM。</p><h3 id="2-gradle-Java-platform-plugin">2. gradle Java platform plugin</h3><p><code>gradle Java platform plugin</code>是 gradle 对定义、发布 BOM 提供的一款实用插件。<br>引入它，我们就可以开始动手工作了。<a href="https://docs.gradle.org/5.6.3/userguide/java_platform_plugin.html#header">官方链接</a></p><p><em><code>build.gradle</code></em></p><pre class="line-numbers language-none"><code class="language-none">plugins {    id 'maven-publish'    id 'java-platform'}version '0.1.1-SNAPSHOT'javaPlatform {    allowDependencies()}dependencies {    api platform('org.springframework.boot:spring-boot-dependencies:2.2.6.RELEASE')    api platform('org.springframework.cloud:spring-cloud-dependencies:Greenwich.SR3')    api platform('org.springframework.cloud:spring-cloud-contract-dependencies:2.2.3.RELEASE')    api platform('org.junit:junit-bom:5.3.2')    constraints {        api 'com.google.guava:guava:27.0.1-jre'        api 'ch.vorburger.mariaDB4j:mariaDB4j-springboot:2.4.0'        api 'org.mariadb.jdbc:mariadb-java-client:2.2.5'        api 'org.mockito:mockito-core:2.22.0'        api 'org.mockito:mockito-junit-jupiter:2.22.0'        api 'org.assertj:assertj-core:3.11.1'    }}publishing {    repositories {        maven {            credentials {                username = 'jfrog'                password = 'jfrog123456'            }            def releasesRepoUrl = 'http://localhost:8082/artifactory/libs-release/'            def snapshotsRepoUrl = 'http://localhost:8082/artifactory/libs-snapshot/'            url = version.endsWith('SNAPSHOT') ? snapshotsRepoUrl : releasesRepoUrl        }    }    publications {        myPlatform(MavenPublication) {            from components.javaPlatform        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当然, 作为一个服务级的 BOM，自然无需从零开始逐条定义，可以直接先 import 框架级的 BOMs，如上例中的Spring boot / Spring cloud / Spring cloud contract / Junit。<br>但由于需要使用第三方platform bom, 则不得不打开配置约束 ——<code>javaPlatform.allowDependencies</code>。具体使用请见<a href="https://docs.gradle.org/5.6.3/userguide/java_platform_plugin.html#sec:java_platform_bom_import">官方链接</a></p><p>这里，通过gradle生成的 BOM 会发布到一个我本地自己搭建的JFrog artifactory OSS中。<br>(为什么不在云上搭一个？啊哈哈，因为JFrog artifactory OSS最低预配是4核4G内存，自己掏钱就手短了。。)<br>当然,也可以生成本地的 POM 文件，手动复制传阅，但这样就不容易进行后续的版本管理和保持更新了。</p><p>maven publish 成功后，我们就可以来使用 BOM 导入依赖版本了。</p><h3 id="3-gradle-platform">3. gradle platform</h3><p>导入方式也非常简单，直接使用platform组件即可。<a href="https://docs.gradle.org/current/userguide/platforms.html">官方链接</a></p><p>创建一个example项目试一下, 编写<code>build.gradle</code>文件。</p><pre class="line-numbers language-none"><code class="language-none">repositories {    maven {        credentials {            username = "jfrog"            password = "jfrog123456"        }        url "http://localhost:8082/artifactory/libs-snapshot/"    }}dependencies {    implementation platform('com.ellendan.service.template:dependencies-bom:0.1.1-SNAPSHOT')    implementation 'org.springframework.boot:spring-boot-starter-web'    implementation 'org.springframework.boot:spring-boot-starter-security'}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对，就是使用platform()引入即可。</p><p>也许有人会问：大家用 spring-dependency-management 习惯了，这个 BOM 是否支持 spring-dependency-management 的 <code>imports.mavenBom</code>。<br>理论上是支持的。<br>但本人在写代码的时候，发现自定义 BOM 中spring boot dependencies BOM 无法被成功引入，而其他 BOMs 都没有此问题、可以成功导入。<br>因此，我这里并不推荐通过spring-dependency-management的<code>imports.mavenBom</code>来导入。</p><h3 id="4-为什么要做“可共享的依赖版本管理”">4. 为什么要做“可共享的依赖版本管理”</h3><p>这还要从本人最近的一个任务说起。<br>任务本身是做 —— “启动模板”。<br>但“启动模板”，这四个字，怎么看都觉得非常的静态。<br>结合Rebecca《演进式架构》中“服务模板”的概念（虽然“模板”这命名还是怎么看怎么静态）。在构建服务的过程中，为了防止有害的重复，如果技术上的适当耦合避免不了，那就尽量让其黑盒复用。</p><blockquote><p>通过在服务模板中定义适当的技术架构耦合点，并让基础设施团队管理这些耦合，就能使各个服务团队免于这些苦恼。</p></blockquote><p>所以，这里决定尝试做一个“服务模板”。<br>依赖版本管理只是其中的一个小的部分, 并且使用 gradle 来实现也非常简单。<br>具体代码地址：<a href="https://github.com/ellendan000/service_template">https://github.com/ellendan000/service_template</a></p><h3 id="PS-废话篇">PS. 废话篇</h3><p>眼看2020就要过半，由于2020开局乱来，受种种因素影响，计划一团混乱变更。<br>一鼓作气，再而衰，三而竭，各种计划目标债。期望2020后半段能走好吧~</p><h3 id="参考资料">参考资料</h3><ol><li><a href="https://docs.spring.io/spring-boot/docs/current/gradle-plugin/reference/html/#managing-dependencies">https://docs.spring.io/spring-boot/docs/current/gradle-plugin/reference/html/#managing-dependencies</a></li><li><a href="https://docs.gradle.org/5.6.3/userguide/java_platform_plugin.html#header">https://docs.gradle.org/5.6.3/userguide/java_platform_plugin.html#header</a></li><li><a href="https://docs.gradle.org/current/userguide/platforms.html">https://docs.gradle.org/current/userguide/platforms.html</a></li><li><a href="https://docs.spring.io/dependency-management-plugin/docs/current/reference/html/#introduction">https://docs.spring.io/dependency-management-plugin/docs/current/reference/html/#introduction</a></li><li><a href="https://www.baeldung.com/spring-maven-bom">https://www.baeldung.com/spring-maven-bom</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Gradle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DDD概念概览</title>
      <link href="/2020/02/09/ddd-gai-nian-gai-lan/"/>
      <url>/2020/02/09/ddd-gai-nian-gai-lan/</url>
      
        <content type="html"><![CDATA[<p>软件的核心，是为其用户解决领域相关问题的能力。</p><h3 id="1-何为DDD">1. 何为DDD</h3><p>DDD是Domain Driven Design的简称。<strong>领域驱动设计</strong>，“<strong>领域</strong>”指业务领域，“<strong>设计</strong>”指软件设计。<br>DDD可以看成一种开发思想体系，促成了一种新的以领域为中心的思维方式，使得团队可以高效管理——用于复杂问题域的软件的构造和维护。</p><span id="more"></span><h3 id="2-为什么DDD">2. 为什么DDD</h3><p>对于一个复杂业务系统，无视业务复杂度而割裂式地进行软件设计，往往会造成软件的<strong>大泥球模式（BBoM）</strong>，后果就是：</p><ol><li>对统一语言和问题域知识缺乏重视，导致代码库可用但无法揭示业务意图。</li><li>缺乏基于问题域模型的应用程序设计的重视，让代码库缺乏与业务行为的协同效应，当有后续功能的扩展就会变得棘手。领域复杂性和技术复杂性混合在了一起。</li><li>会扼杀开发。对开发人员来说，软件杂乱、变更易出错。对企业来说，降低了软件快速实现商业价值的能力。</li><li>缺乏对问题域的关注和正确认识，构建出来的软件系统往往会失败。<br>注：<strong>问题域</strong> ，涉及你当前正在构建软件的主题领域。是确定软件价值的关键点。</li></ol><h3 id="3-DDD模式">3. DDD模式</h3><p>DDD具有两种模式类型：战略模式和战术模式。<br>战略模式影响的是解决方案，战术模式用于实现富领域模型。<br><img src="/2020/02/09/ddd-gai-nian-gai-lan/ddd-summary.png" alt="Domain Drive Design Summary.png"></p><h4 id="3-1-DDD战略模式">3.1. DDD战略模式</h4><p>领域驱动设计的战略模式会提炼问题域并塑造应用程序的架构。</p><ol><li>提炼问题域以揭示重要之处是什么 —— 核心子域。核心域是编写软件的原因，保留最大价值的关键区域，决定软件成功与否的关键。并非一个系统的所有部分都需要被精心设计，团队可以更专注于核心领域。</li><li>在解空间构建一个软件模型，以处理领域问题并让软件与业务保持一致。</li><li>运用统一语言（Ubiquitous Language），开启建模协作。首先，确保的是领域专家和开发团队协作工作，其次，是将分析模型绑定到代码模型，以便开发团队和领域专家能够在模型设计方面进行协作。</li><li>限界上下文（Bounded Context），定义了模型的适用性并确保保留其完整性和独立发展的能力。统一语言和模型的适用边界应该是要在具体的限界上下文内。</li><li>上下文映射（Context Map）。上下文映射提供了整个系统各上下文边界之间的宏观状况，揭示了上下文之间的关系和交互方式，同时表现出各上下文内模型的有多少差异，以及它们的交换哪些数据来实现业务处理过程。</li></ol><p><strong>问题空间 &amp; 解空间</strong><br>战略模式中强调问题空间和解空间的区别。只有明确确定了问题空间，才能分析出对应的解空间，最终才能构建出满足解决业务问题的成功软件。<br>上1，是解决问题空间复杂度的管理模式。问题空间将问题提炼成更多可管理的子域。<br>上2、3、4、5， 是解空间的管理模式。</p><p>战略模式强调了DDD的侧重点是：知识消化、知识提炼、协作沟通、统一语言、上下文、模型持续发展。<br>后面战术模式，其实只是支持其实现而推荐的手段。</p><h4 id="3-2-DDD战术模式">3.2. DDD战术模式</h4><p>DDD的战术模式（也称模型构造块）是一个帮助创建用于复杂有界上下文的有效模型的模式集合。<br>许多模式都早于DDD概念的出现，但依然有一些被推荐为DDD战术的标准模式。<br>在战略模式提供的架构和原则的基础上，共用这些标准模式可以让设计有序进行，也使项目组成员能够更方便地了解彼此的工作内容。</p><ol><li>实体（Entity）</li><li>值对象（Value Object）</li><li>领域服务（Domain Service）</li><li>工厂(Factory)和验证器(Validator)</li><li>聚合(Aggregation)</li><li>资源库(Repository)</li><li>领域事件(Domain Event)</li><li>模块(Module)</li><li>集成限界上下文</li><li>六边形架构</li></ol><h3 id="参考文献">参考文献</h3><ol><li>《领域驱动设计：软件核心复杂性应对之道》，Eric Evans 著</li><li>《实现领域驱动设计》，Vaughn Vemon 著</li><li>《领域驱动设计模式、原理与实践》，Scott Millett / Nick Tune 著</li></ol>]]></content>
      
      
      <categories>
          
          <category> DDD </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DDD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从精益来看价值交付是什么</title>
      <link href="/2020/02/08/cong-jing-yi-lai-kan-jie-zhi-jiao-fu-shi-shi-me/"/>
      <url>/2020/02/08/cong-jing-yi-lai-kan-jie-zhi-jiao-fu-shi-shi-me/</url>
      
        <content type="html"><![CDATA[<p>前一段时间在做U内的价值交付。<br>个人也从最开始的可意会不可言传的状态，到后来可以聊些概念和措施的阶段。</p><p>老实说，曾经在我司经常听到Dev challenge BA：“你这个需求的价值是什么？”现在反而听到越来越少。<br>曾经我们坚持要去做有价值的事情，直到我们现在不得不 highlight 出 <code>价值交付</code> 这个标题。<br>并且常常会被问到 —— 价值交付，它到底指什么？</p><span id="more"></span><h2 id="1-“价值交付是什么？”">1. “价值交付是什么？”</h2><p>首先，我不会尝试直接回答这个问题。<br>作为一个交付型U，我们先从一些耳熟能详的理论和方法实践中，尝试找到“价值”这个词。</p><ol><li>敏捷软件开发宣言</li></ol><blockquote><p>我们一直在实践中探寻更好的软件开发方法，身体力行的同时也帮助他人。<br>由此我们建立了如下价值观：</p><p>个体和互动 高于 流程和工具<br>工作的软件 高于 详尽的文档<br>客户合作 高于 合同谈判<br>响应变化 高于 遵循计划</p><p>也就是说，尽管右项有其价值，<br>我们更重视左项的价值。</p></blockquote><ol start="2"><li>相互依赖声明（敏捷项目管理宣言）</li></ol><blockquote><p>敏捷和自适应的方法把人、项目和价值联系起来<br>我们是一群能够非常成功地交付成果的项目领导者所组成的团体。为了能成功交付：</p><p>我们通过关注持续的价值流，以此来提高投资回报率。<br>我们通过与客户的频繁交互和分享所有权，以此来交付可靠的结果。<br>我们预先考虑不确定性的因素，并通过迭代、预防和适应的方式管理它。<br>我们承认个人是价值的最终源泉，努力建立一个人尽其才的环境，以此释放创造力和创新力。<br>我们通过团队结果问责制以及团队责任分享制，以此来提升绩效。<br>我们按照具体情况制定策略、过程和实践，以此来提高效率和可靠性。</p></blockquote><ol start="3"><li>精益<br>好吧。无论是精益软件开发7原则，还是丰田精益方法的14原则都没有提到“价值”这两个字。<br>但是，在《精益思想》进行了这样的总结 —— 5个原则：</li></ol><blockquote><p>精确地定义特性产品的价值；<br>识别出每种产品的价值流；<br>使价值不间断地流动；<br>让客户从生产者方面拉动价值；<br>永远追求尽善尽美。</p></blockquote><p>从前两组概念 —— 敏捷和敏捷项目管理，来直接追溯价值交付，看起来总是有些刻意。<br>而精益思想的第一原则“精确地定义特性产品的价值”，直接从用户受众的角度入手，就看起来直观的多，因此我这里就直接从精益来看价值交付是什么。</p><h3 id="1-1-价值交付的具象产出部分-——-产品">1.1. 价值交付的具象产出部分 —— 产品</h3><p>说到精益，如果用一句话来描述它是用来干什么的话，那应该是：<code>杜绝浪费，降本增效。</code><br>当然，如果提到它诞生的背景的话，它解决了工业化大生产中的提前批量性生产、生产时间周期过长、生产可预测性不准等问题，但解决问题的终极思路就是：<code>在保证价值的同时，持续不断、稳定地消除浪费，从而降低成本提升效能。</code></p><p>说到“浪费”：丰田模式中，将生产活动中的各环节分为3类步骤：</p><ul><li>明确能创造价值的步骤</li><li>虽然不能创造价值，但是在现有技术和生产条件下不可避免的步骤（<strong>1型浪费</strong>）</li><li>不创造价值，并且可以去掉的步骤（<strong>2型浪费</strong>）<br>针对产品制造的第一要务就是首先定义价值，从而识别整个生产活动中能够创造价值的步骤、1型浪费和2型浪费。然后消除2型浪费，并将1型浪费逐渐转化成2型浪费从来最终消除。</li></ul><h4 id="1-1-1-首先定义价值">1.1.1 首先定义价值</h4><p><img src="/2020/02/08/cong-jing-yi-lai-kan-jie-zhi-jiao-fu-shi-shi-me/value.png" alt="价值"></p><p>同样的道理，在软件交付中，首先的出发点就是价值，并不是一堆一堆的功能集、features 或者 看起来非常 fashion 但不解决自身问题的前沿方案。</p><p>然而无论是制造业还是软件业，价值只能由产品的使用者 —— 最终用户来确定。<br>一般在交付团队中，会有两种情况：</p><ul><li>客户就是用户</li><li>客户只是尝试设计产品，用户是另外的群体。<br>在客户不是用户的情况下，如果客户并没有收集和分析用户的真实需求，整个交付过程就会变成 —— 提前生产、没有以需求来拉动生产，最终价值交付物是否能产生价值只能凭玄学的地步。一旦不能产生价值，就变成了最大的浪费。<br><img src="/2020/02/08/cong-jing-yi-lai-kan-jie-zhi-jiao-fu-shi-shi-me/pull-push.png" alt="用户拉动 vs 提前生产后推动"></li></ul><p>交付价值，只有在用 —— <code>具有特定价格、能在特定时间内满足用户需求的特定产品</code>（无论商品或者服务）来表达时才有意义。<br>所以，在交付之前，先确定产品的价值 —— 开发的人力成本、时间成本、机会成本，和最重要的一点 —— 这是否解决了用户的真实问题吗？以及是否“更好地”解决了用户的真实问题？<br>为什么这里有“更好地”一说？<br>就比如同样是员工打卡系统，在开发各成本投入产出比相似的情况下，上AI人脸识别 —— 自然是比手工签到的价值要大的。</p><p>也许有人会说，“我们使用敏捷，就是因为当下无法定义出明确产生价值的需求，才使用敏捷软件交付 —— 实现增量性发布、快速实验和反馈。”<br>这里要分两种情况来看这个问题：</p><ul><li>第一种情况：只是短视的一种借口。懒于、或者能力不足直接放弃努力，造成无法通过问题收集、需求分析和商业洞见对各种业务方案进行过滤，从源头上就开始产生软件开发的大量浪费。</li><li>第二种情况：已经有了需求收集和分析渠道，但行业方案较新，无法完全避免产品实验开发的浪费。这种，在更下游、更靠近用户的地方，是否建立了有效的用户反馈、价值追踪和核定机制 —— 实验的效果是什么样的，生成了哪些价值，是否帮助我们更好地逐渐形成价值定义？</li></ul><p>实现完价值定义之后，我们针对当前价值定义来看看“交付”这个动作。</p><h4 id="1-1-2-从需求到产品的快速研发能力">1.1.2. 从需求到产品的快速研发能力</h4><h5 id="“识别出每种产品的价值流”">“识别出每种产品的价值流”</h5><p>用过 Scrum 或者 Kanban board 的人应该都理解，一张卡（无论 EPIC 卡还是 story 卡），其承载的就是一个价值点（这里不涉及到估算）。</p><p>而将 board 上的各个 columns 对应的步骤连接起来，其实就组成了完成此类卡的一条粗粒度的“价值流”。其中，有产生价值的In Dev、In QA等，也有1型浪费Dev Done / Ready for QA 等等，当然个别团队可能还存在2型浪费的 columns。<br>价值流的目标就是让团队识别出流程步骤，为之后消除这些浪费做准备，最终降低开发成本、缩短lead time。<br>那从这种粗粒度的”价值流“中如何逐渐暴露浪费和执行改进呢？</p><h5 id="“使价值不间断地流动”">“使价值不间断地流动”</h5><p>也许有人会觉得这句话理解起来很难，其实在部分团队内非常常见。<br>比如：见过一些客户团队，所有 story 的开发只要开发人员开发完毕，就推进Dev Done column 中，等到整体功能开发的差不多了，才引入 QA 来开始测试，在此之前 QA 资源可能在忙于另一个团队的测试工作。一种类似制造业批量化生产的模式，生产步骤之间存在大量库存，批量满额之后，才会推进到下一个生产环节。<br>也有一些敏捷团队，由于 QA 资源不足，出现相同的Dev Done之后在Ready for QA中形成批量等待，始终无人解决，甚至大家对此已经习以为常 —— QA会在下一个sprint整体测试这批卡。<br>“使价值不间断地流动”，其实不仅是行动、更是从思想和意识上认识到 —— 价值要流动起来。就像最后那些敏捷团队的例子，即使使用了敏捷流程和工具，思想和意识不到位，依然用出了批量的样子。</p><p>有人会说：“这种批量有什么不好？团队上所有的人都在工作，并没有空转，人力没有被浪费。“<br>如果一定要从项目人力运营的知识域中来看价值交付，我只想说：是的，大家看起来都忙忙碌碌，行色匆匆，努力“做事”，但是人力花完就代表创造了价值么？<br>另一方面，我也可以从”测试前置“、”一次性把事情做好“、”缺陷越晚修复，修复的成本越高“、”开发周期越长，越容易返工“等等方面来聊一聊不关注价值流会造成的种种人力成本、时间成本、机会成本上的浪费。</p><p>只有让价值尽量不间断地流动起来，从需求到生产，才会暴露问题 —— 让团队观察和思考这种端到端的整条价值生产活动中，哪些是产生价值的，哪些是浪费？持续地逐渐优化和消除浪费后，降低开发成本、提升研发效能。</p><h5 id="“让客户从生产者方面拉动价值”">“让客户从生产者方面拉动价值”</h5><p>当研发效能提升、单个价值点能被快速完成端到端交付时，提前预测性质的功能设计（是否能最终产生价值靠玄学的那种）就可以完全被避免，由最下游的终端用户直接提出需求，从来拉动交付。</p><h4 id="1-1-3-方案、技术先进性的加持">1.1.3 方案、技术先进性的加持</h4><p>在前面我讲board上面的价值流的时候，始终特指其是”粗粒度“的价值流。<br>为何？<br>因为无法从这些columns中看到：用A框架开发会比B节省多少开发成本、使用某个自动化测试方案可以节省多少测试成本，诸如此类的“细粒度”的价值流才会发现的浪费对比。<br>这种时候，各团队面临的问题各不相同，需要团队一线人员自身的方案和技术能力去扩展优势、消除浪费，不再局限于敏捷软件开发流程、scrum / kanban board来宏观指导和描述开发流程。</p><p>这里就涉及到精益思想的最后一个原则：<em>“永远追求尽善尽美”</em>。</p><h3 id="1-2-价值交付的土壤-——-团队能力-学习型组织">1.2. 价值交付的土壤 —— 团队能力 / 学习型组织</h3><p>精益思想前四大原则都只是在讲 —— 如何消除产品生产过程的浪费，最终形成高效有价值的生产流程。一般完成前四原则，基本可以收获 <code>突破性改善</code>（指初次改革，调整生产活动后，一次性获取到的改善效果）。<br>精益思想用最后一个原则<code>“永远追求尽善尽美”</code>，才提到了如何 <code>持续性改善</code> 。</p><p>而《丰田模式》用了一整本书，来讲如何实现“追求尽善尽美”、实现“持续性改善” —— 即使完成了前面四个原则，或用了大量的精益工具和实践，只要没达到一点，就不是精益。精益 —— <code>打造一个真正的学习型组织。</code></p><p>这个“学习型组织”，不是说 —— 只是在组织内培养学习氛围，今天去学几种对价值流毫无帮助的语言或架构，明天去做一些对当前主业务毫无扩展的社区活动。也不是说，当某个团队需要一个大数据工程师时，需要从零开始培养，当第二个团队又需要一个大数据工程师时，再次另外培养。<br>而是说 —— 培养学习氛围、过程中不断创建“标准化”以达到“稳定”，然后让成员发挥创造性思维和创新能力以持续改进价值流的组织。</p><p>为什么说“团队能力/学习型组织”是价值交付的土壤呢？<br>假设某团队前四原则背后的工作并不是团队自发形成完成的，是由一个外部人员引入并督促实践完成，本团队并没有掌握其能力。当用户需求拉动生产越来越快时，必然会暴露进一步需要解决的瓶颈和浪费，这时候团队离开了外部人员根本无力继续持续改进从而稳定交付价值。</p><p>为了真正实现精益的持久性改善和价值交付，这需要一个自下而上的过程。<br>仅靠上级制定几个衡量指标，没有培养团队的学习和自组织能力，你永远也想像不到真正实践时会长成什么样子。<br>将团队的指标呈现想像成地上的树，如下图。<br>上级也许期望是扎根价值交付、持续性改进指标背后的问题。但团队也许只是做了一些流于表面的工作让指标变得好看。<br><img src="/2020/02/08/cong-jing-yi-lai-kan-jie-zhi-jiao-fu-shi-shi-me/how-tree-grow.png" alt="你以为和实际的区别"></p><h2 id="2-最后">2. 最后</h2><p>何为价值交付？<br>以打造学习型组织或团队为基石 —— 精确定义产品用户价值，尽可能以追求价值卓越为目标，从需求提出开始到产品上线被终端使用，持续消除或者减少阻碍产品研发的浪费，最终实现产品价值。</p><p>看起来，精益贯穿始终。<br>再回来看看《敏捷宣言》和《相互依赖声明》，发现和精益很多方面都很相似。只不过在我看来，精益可以更好的端到端描述整个价值流思路。</p>]]></content>
      
      
      <categories>
          
          <category> 敏捷精益软件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 价值交付 </tag>
            
            <tag> 精益 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么越身处团队越难改进</title>
      <link href="/2020/01/16/wei-shi-me-yue-shen-chu-tuan-dui-yue-nan-gai-jin/"/>
      <url>/2020/01/16/wei-shi-me-yue-shen-chu-tuan-dui-yue-nan-gai-jin/</url>
      
        <content type="html"><![CDATA[<p>“为什么越身处团队越难改进？”</p><p>最开始我意识到这个问题的时候，那时候我读了一本叫《咨询的奥秘》的书，里面有一个“普雷斯科特腌黄瓜原则”。<br>好吧，不要较真，不要记住这个别扭的原则名字。名字根本无关紧要，这本书的风格是在讲故事，里面的名词大部分对应的故事叙事主题。<br>这个原则的名字，并没有分享性，更没有Brook’s Law这样带有明确的理论体系。<br>因此，每次我提到它的时候，只说成“腌黄瓜原则”。</p><span id="more"></span><h5 id="腌黄瓜原则">腌黄瓜原则</h5><p><em>故事大体是这样的：</em></p><blockquote><p><em>从前有一根倔强的黄瓜，被普雷斯科特爷爷放在了卤水桶里。它看了看其他的黄瓜，对它们身上发生的事情十分厌恶。</em><br><em>“真是要了命了”，它骂道，“你们这帮黄瓜都怎么啦？一点骨气都没了吗？有自尊的黄瓜不会随随便便不经过抗争就被腌了。”</em><br><em>“那我们能做啥呢？”黄瓜们问到。</em><br><em>“你可以抵抗啊，这就是你能做的。这也是我要做的，我不会让卤水进入我的皮肤的。”</em></p><p><em>而若干时间之后，普雷斯科特爷爷的腌黄瓜就做成了。</em><br><em>“孩子，别傻了。如果你在卤水里呆得够久，就变成腌黄瓜了。”</em></p></blockquote><p><em>这个故事的最后，书中给了一个总结：</em></p><blockquote><p><em>黄瓜被卤水腌的多，卤水被黄瓜染的少。</em><br><em>如果小系统试图通过长期和持续接触来改变大系统，那么最后更可能是自己发生变化。</em></p></blockquote><p><em>所以，作为咨询顾问，要时不时地跳出客户的环境，不要让自己被“腌”。</em></p><p>看到这一段的时候，我本人正身处于绝对的交付一线中，并不能像咨询顾问一样，时不时跳出项目环境。<br>因此，那时候我总是渴望有几个新的“新鲜黄瓜“进来，搅动这桶卤水，我们这些”身残心不残的黄瓜们“也顺势可以做一些项目和团队改进的事情。</p><p>也许有人要问：“为什么不渴望的是一个外部的咨询顾问过来，搅动你们从而完成改进？”<br>作为一个专业服务以及咨询公司中的一员，我深知在所有的改进和持续完善中，真正能依赖、最后落地的 —— 其实是冲在一线的这个团队成员们自身。<br>于是，这个“卤水效应”，仿佛让自我救赎变成了一个不可能完成的事实。</p><p>再后来的一段时间，我真的获取到了跳出“卤水”的机会，接触到了有意思的环境和机会。当再次回头来做改进的事情的时候，我又读到了《丰田模式》。<br>在其“拨云见日”中，提到了人类的适应能力。</p><h5 id="人类的适应能力">人类的适应能力</h5><p><em>书中有这样一段（源自章节“拨云见日”）：</em></p><blockquote><p><em>乍一看到某个作业流程，我们很容易将所看到的景象与有益的或必需（创造价值）的工作混为一谈。人们都在忙碌，他们行色匆匆，他们努力“做事”，因此看清他们的真实状态绝非易事。</em></p><p><em>如果作业流程混乱不堪，我们很容易对真实的状况、什么可以做到及什么不可以做到得出错误的结论。适应周围环境的能力是人类生存必需的特征之一，所幸我们都具备这一能力，然而，正是这种适应能力，使创建精益流程的工作异常艰难。</em></p><p><em>从本质上而言，我们会适应周围的环境，并在很短的时间里接受环境，并视之为“正常”而不再予以考虑。在很多情况下，我们会把这种情况当做我们“应该做的事情”。幸运的是，我们可以摆脱这种模式，当从另外一个角度来看待这种情况时，我们的理解便会更深一步。运用精益理念和工具将迫使我们从不同的视角重新审视环境。如果我们的头脑能够接受新的信息，那么真正的转变就可能发生。</em></p></blockquote><p><em>还有相似的这样一段（源自章节“站在圆圈内的练习”）</em></p><blockquote><p><em>具有讽刺意味的是，如果你对练习中的流程已十分熟悉，那么这项练习的难度就更大。因为，你已了解浪费存在的“原因”，所以你更倾向于使其合理化，并得出无法改进的结论。在练习中，最好的方法是承认存在浪费，而无须对其做出解释或思考解决之法。</em></p></blockquote><p>书中这两处描述的场景，看起来跟前面“腌黄瓜的卤水效应”有异曲同工之处。然而，《丰田模式》这本书讲述的跟《咨询的奥义》不同的正是 —— 不只是自己跳出卤水之外，而是身处环境中如何完成自我救赎的事。</p><p>所以，当深处团队中改进，我们需要的是什么？“不同的视角重新审视环境”，找到正确的理念和工具，当然还有一系列整体优化等后续。虽然我最近的背景主要是在价值交付，这篇文章我就不延伸讲了。稍微大白话来说的话，就是“不仅要低头做事，还要抬头看路”；精益一点，就是“要定义价值，消除浪费”。</p><p>也许，有人说到 —— 这篇文章前面讲到的我都懂，但当冲在一线的时候，往往那巨大的压力就是没办法、也没有时间去做好价值定位、改善的事情，那些总是排不上优先级。<br>好吧，我这里再次借用曾经看过的另一本书中的一个理论：首先支付自己。（由于不是跟软件开发的书籍，这里就不引用了。有兴趣的小伙伴可以使用关键词查询）<br>这里借鉴一下，改为“首先投资自己”。</p><h5 id="首先投资自己">首先投资自己</h5><p><em>原本“首先支付自己”的故事是这样的：（是一条财富的增长思路）</em></p><p><em>每个月的薪资发下来的时候，人们习惯于先还信用卡、缴房租、缴各种费用、支付，最后剩下来的才考虑投资、理财。而往往最后却剩下的可能只是空气，这样月复一月、年复一年，选择这样做的人们仍然是靠着每月薪资度日，永远与资本性盈利增长绝缘，一旦失去工作，基本几个月断粮，或者吃存款的份儿。<br>因此，为了避免人们是为了生存而工作，日复一日别无选择，就提出了“首先支付自己”的思路。<br>也就是，在每个月薪资发下来的时候，先划出优先投资、理财的那部分，剩下的才考虑还款、缴费、支付。不仅可以保障长期的财务投资的同时，在剩下的钱不够用的时候，也可以激励人去创造更多的价值盈利。</em></p><p>这里借鉴一下。<br>在一线的时候，团队总是被盲目地BU、stories、bugs追着跑，耗掉了大部分的时间，总说用剩下的时间来做价值审视和改进。往往最后剩下的时间可能都是负数，引以为傲的敏捷、精益、价值交付都被抛之脑后。团队在养活自己的边缘挣扎，每日忙忙碌碌、行色匆匆、“努力”做事，最后我们把自己从专业服务做成了外包，日复一日别无选择。团队里的客户也把自己从企业数字化方案推动者做成了外包人员manager。<br>所以，当有压力来的时候，请先抗住压力，确保有效的时间来投资团队和价值体系。</p><h4 id="总结">总结</h4><p>克服”腌黄瓜原则“，克服”人类的适应能力“，保证”首先投资自己“。<br>至于怎么做？这不是本篇文章的范围，也许下一篇涉及价值交付的文章中提及。</p><p>最后放一张本人最近画的团队改进图 —— 借鉴自”精益持续改进的螺旋循环图“。<br>随便看看，这里不会有说明。就是为了凑图来的 😁<br><img src="/2020/01/16/wei-shi-me-yue-shen-chu-tuan-dui-yue-nan-gai-jin/continuous_improvement_spiral_graph.png" alt="精益持续改进的螺旋循环图"></p>]]></content>
      
      
      <categories>
          
          <category> 咨询 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 持续改进 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>敏捷测试四象限之三四</title>
      <link href="/2019/12/01/min-jie-ce-shi-si-xiang-xian-zhi-san-si/"/>
      <url>/2019/12/01/min-jie-ce-shi-si-xiang-xian-zhi-san-si/</url>
      
        <content type="html"><![CDATA[<p>接着上篇《敏捷测试四象限之一二》，这里主要讲下剩下的三四象限。<br>这篇就没有上篇那些吐槽生活中的小例子了。</p><p><img src="/2019/12/01/min-jie-ce-shi-si-xiang-xian-zhi-san-si/agile_testing_quadrant.png" alt="敏捷测试四象限"></p><p>在四象限图的右边部分，区别于“支持团队”，主要目的是来“评价产品”。<br>所谓评价产品，就是以用户体验的角度去测试系统 —— 在测试中尽量重现最终用户的实际体验，或者如beta测试，直接邀请终端用户参与测试。</p><span id="more"></span><h4 id="1-第三象限，“面向业务”、“评价产品”的测试">1. 第三象限，“面向业务”、“评价产品”的测试</h4><p>面向业务的测试实例帮助团队设计期望的产品，但可能业务某些测试实例本身是错误的 —— 业务专家可能遗漏了某些功能；或者是因为该功能不是他们的实际领域、并没有正确的了解这个功能；团队误解了某些实例；开发编写的代码可以通过之前一二象限的测试，但并没有产生客户想要的东西，等等。<br>这就是使用第三象限测试的地方。</p><p>第三象限中测试的主体，是手动完成。<br>当然，如果没有将象限一和象限二中的测试实现自动化，那么测试人员根本没有时间进行第三象限的测试。<br>而对于第三象限的测试，实现自动化是很困难的，因为这类测试依赖于人们的智力、经验和直觉。</p><p>比如，探索性测试，就是敏捷测试中，对于用户故事测试和自动化回归测试集的重要补充。<br>使用探索性测试时，首先，测试人员对现存系统有整体了解，然后，不按照原有的验收测试项剧本，将“测试设计”、“测试执行”和“学习”同时进行。最终能设计新的测试，并能引出不少对新特性的想法，而这些新特性往往会演变成新的故事。</p><p>可用性测试。注意这里是Usability，不是availability。后端开发人员估计第一反应是后者。<br>这里的第三象限的可用性测试，是指对于用户来说的可用性，包括 —— 是否易于学习、记忆、操作，是否提升用户效率等等。</p><p>UAT、alpha、beta 测试，都算是用户验收测试，基于系统的全量评测，发现并反馈问题，修复或者获取新的用户故事想法来以此改进。<br>由于本人作为一个开发人员，参与的不多，就不仔细描述了。</p><h4 id="2-第四象限，跨功能性需求测试">2. 第四象限，跨功能性需求测试</h4><p>第四象限的目的是评价产品的跨功能性需求，比如性能、安全、可靠性、可扩展性等等。</p><p>这是一个敏捷开发比较容易忽视的测试维度。<br>为什么会忽视呢？<br>其中一部分原因是 —— 敏捷流程中一个很重要的步骤是，让业务（PO）编写用户故事并对其优先级排序。一般非技术的业务团队成员通常会“假定”开发人员会考虑性能、安全等因素，但开发们只是专注于客户给出的优先级高的功能。<br>而有时候跨功能需求可能比实际的功能更重要。比如，如果一个在线商城的响应时间是一分钟，那么客户将不会等待欣赏它的任何功能。<br>因此，应该在开发周期的每一步都要考虑评价产品的面向技术的测试，而不是留到最后。不然，可能会太迟而不能修正这些问题。在很多情况下，这些测试甚至应该在功能测试之前进行，比如性能指标的不同，会驱动出不同的技术解决方案。</p><p>跨功能性需求，最好准备一个核对的表单，让团队对其有所了解，同时也能让 PO 给出每项的重要级别。开发团队有义务解释清楚不重视这些跨功能需求所导致的后果，PO 应该仔细思考所有这些重要质量因素并进行权衡，必要时候，在涉及的功能、用户故事上对其进行特别强调。</p><p>最后，具体第四象限的执行，团队可能需要借助固定专家的帮助，比如DBA、安全小组等，同时也会使用一些开源或者需购买的工具来完成。</p><h4 id="3-最后">3. 最后</h4><p>终于将敏捷测试四个象限写完了。<br>至于作为一个开发人员，为啥会跑去写一篇测试的博文、还跑去把《敏捷软件测试》这本书翻了一遍。<br>其中最主要的一个原因是，想要让开发人员充分了解“质量”的重要性，专注于质量。<br>而“质量”，对于开发团队来说，是用来获取客户信任的一个重要政治资本。<br>另外，敏捷测试每个象限其实承担了保持“技术债”在一个可管理的水品的角色。</p>]]></content>
      
      
      <categories>
          
          <category> 敏捷 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 敏捷测试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>敏捷测试四象限之一二</title>
      <link href="/2019/11/28/min-jie-ce-shi-si-xiang-xian-zhi-yi-er/"/>
      <url>/2019/11/28/min-jie-ce-shi-si-xiang-xian-zhi-yi-er/</url>
      
        <content type="html"><![CDATA[<p>本来这篇博文我是想这样开头的：</p><p>也许有人看见这篇文章的标题会觉得 —— 这跟开发人员无关。<br>不，你错了，这跟开发人员有关，并且有部分工作是需要开发人员去做的。</p><p>但，最近遇到了一些事情，我想换一个开头方式：</p><p>人在工作和生活中，风平浪静时，就像在实现 stories。而那些突如其来的、打断风平浪静的局面的事情，就像一个个 bugs。作为一个 Tech，我已经习惯了去解决这些 ”bugs“，但又不免内心会吐槽，这些突如其来的问题，作为产品和服务提供商，就不能重视一下质量建设？</p><p>说到质量建设，就不得不来看一下敏捷测试四象限。（这个转接是不是还蛮丝滑顺畅的）</p><p><img src="/2019/11/28/min-jie-ce-shi-si-xiang-xian-zhi-yi-er/agile_testing_quadrant.png" alt="敏捷测试四象限"></p><p>四象限左边部分，用以”支持团队“ —— 帮助团队开发产品。<br>与左边相异的右边部分，用以”评价产品“ —— 对交付的产品增量进行评测。</p><p>四象限下边部分，用以”面向技术“ —— 面向技术领域。<br>与下边相异的上边边部分，用以”面向业务“ —— 面向业务领域。</p><p>先声明，敏捷测试四象限可以认为是一个模型，或者工具，大家参照它来划分和搭建项目中的测试“架构”。因此，对于具体的项目而言，并不是每一个部分都必须采用和执行，但至少不要漏掉真正需要的维度和实践。</p><span id="more"></span><h4 id="1-第一象限，开发们最熟悉的部分">1. 第一象限，开发们最熟悉的部分</h4><p>四象限中左下方的象限代表了测试驱动开发。<br>估计有人会说，明明象限图上面写的只是”单元测试“、”组件测试“，怎么扯到测试驱动开发上去了？<br>测试驱动开发，可以分狭义（TDD）和广义，狭义是指开发时小步开发、先写测试、再写实现的开发方式；广义是指，加上业务、测试参与，以终为始，团队明确最终交付验收测试项，使用测试前置策略，以此出发进行功能设计、开发和构建的整个过程。当然，如果认可了狭义和广义两种方式之后，会觉得并无区别，就是”测试驱动开发“。当然较真一点的，会觉得广义中其实还包含了ATDD、BDD等。</p><p>老实说，早期的时候，我也认为先写测试，还是后写测试（我不是指开发完了之后补测试），没有明显的区别。<br>但经历了更多项目之后，深刻地感受到 —— 要使一个团队（对，我说的并不是特指的某个人，我指的是团队），能写出有效、高质量的测试，那还是一起来用TDD吧。<br>首先，以测试先行的方式开发的代码，自然会被要求设计为可测试的。<br>并且，伴随着开发过程中编写的测试，在帮助设计开发、保证质量的同时，在开发完成以后这些测试也承担着频繁回归和重构安全网的作用。<br>最后，当然附加作用就是这些测试是一份产品代码的使用指南。</p><p>至于开发完了之后补测试这种 —— 首先它顶多是只能算是一种回归测试，补上的测试一般会分支覆盖不全；就算最好的情况，分支都覆盖全了，它顶多也只能算另一种白盒测试，对“支持团队进行产品开发”中的设计和开发并无反馈和指导作用。更别说，大部分开发会”产品代码都写完了，赶紧补完测试后，赶去下一个story”的敷衍感。或者，只要没有强制要求，“以后加测试” —— 只是一句自己骗自己的谎言。</p><p>因此种种，敏捷测试第一象限中，测试驱动开发构建出的单元测试、组件测试，用以确保产品代码的内部质量。<br>内部质量，不是通过客户判断的，是由开发们定义的。当内部质量下降时，直观的可见损失比如：开发速率越来越慢，越来越多的bugs需要修复，不断被推迟的紧急重构等等。当然，如果除了第一象限外的其他象限测试也都同时翻车，这些产品质量缺陷将会被用户感知。</p><blockquote><p>举个现实生活中有趣的例子：本人最近使用了支某宝办理ETC，ETC设备被邮寄过来收到之后，需要车主安装、激活。<br>我打开产品说明书，使用支某宝激活引导小程序进行安装和激活。<br>当到达激活这个步骤的时候，提示“OBU设备故障，请联系客服处理”。<br>找到客服，客服直接告知：寄回更换设备。<br>依样寄回，过了两三天后，手机突然收到一条提示 —— ETC已成功激活？这是在做线上debug？<br>联系客服，客服说是技术人员在检修设备。“检修”设备。<br>过了两天，快递收到之前那台设备，已被激活。<br>总结一句：设备出厂有缺陷，新品寄回仅检修，线上debug激活，用户收到设备仍然一脸蒙圈 —— “账号”不仅被线上debug进行了写操作，到底修好没有还需用户自己开去一个ETC入口检验。<br>看，作为一个用户，我虽然看不到内部质量，但同时我也没有看到任何质量构建发挥作用。</p></blockquote><p>支持团队开发过程的面向技术测试，是所有将要进行的测试的重要基础。如果团队没有对这个象限中的测试做足够多的工作，其他类型的测试将会更加困难。因为团队的代码缺少内部质量，每项任务将需要更长的时间。</p><p>ps：第一象限的内容并非只有单元测试、组件测试，只要是“支持团队开发过程的面向技术测试”都可以放在其内，比如：契约测试。<br>第一象限的测试是自动化的，支持快速反馈的。</p><h4 id="2-第二象限，更高层次的支持团队开发">2. 第二象限，更高层次的支持团队开发</h4><p>第二象限也可以叫面向用户的测试，它们确定外部质量和用户需要的功能，包括验证用户故事、功能、界面、交互等等。<br>但既然是敏捷测试，这里强调的就又是 —— 测试驱动开发，只不过是从一个更高的层次上，包含了ATDD、BDD。</p><p>第二象限需要测试人员参与，开发人员提供技术支持，产品人员提供业务和用户故事。<br>测试人员需要对产品系统有全面的了解、关注全局、故事的业务和技术方面，而且始终考虑最终用户体验，以激发和揭示需求中的边界和隐藏假定，最终同业务和开发们明确验收测试项，以此来帮助团队开发正确的需求。<br>在必要情况下，测试人员使用业务领域语言DSL将验收测试转化为能够执行的测试代码，实现BDD，以驱动开发。一些较常见的工具比如cucumber。</p><p>当然，如果有人说，团队测试人员忙的没时间，只能在开发整体完成了之后才能以“测评”、“查bugs”的形式进行用户故事测试、功能测试。<br>那我只能送两老话：<br>“你无法把质量测试进产品中”、“一次性把事情做好，可以杜绝浪费”。<br>简单点说，就是测试人员发现了bugs，还是需要返工给开发人员修复，开发修复后，测试人员再重测，更何况bugs发现的越晚，修复的成本越高。这些种种，其实造成一些时间和效能的浪费，无法实现及时的支持团队开发。</p><blockquote><p>再举一个最近生活中碰到的有趣的例子：本人最近申请了某讯王卡升级5G的业务。<br>10月31日出的某讯王卡5G宣传，本人满足上面所有前置条件，看着广告上11月30日之前办理可以半年月租享受7折的优惠，同时想支持一把5G事业，<br>于是果断买了5G手机，接着点击了王卡助手的申请升级5G。<br>结果，第一次短信反馈，申请失败 —— 因为有一个王卡福利0元1G流量包。<br>手动上联通app注销了该业务，显示流量包将在11月30日失效。<br>再次点击申请升级，第二次短信反馈，申请失败 —— 因为这个流量包失效时间在11月30日，因此只能在12月才能办理。<br>一看，哪有这样的说法，这要是开通不了，不等于广告虚假宣传么，于是马上联系了王卡客服和联通客服。<br>历经3天的沟通和协作，最后王卡客服 + 我 + 联通电话客服，才成功完成这次5G套餐的升级。<br>主要原因 —— 王卡客服的账号权限根本完成不了这些流量包的立即取消失效，也就无法在广告优惠期内完成办理5G套餐。<br>最后是依靠联系联通电话客服这条workaround才完成办理5G套餐。<br>看看，整个功能测都没有测试，就上线了。虽然对于5G刚商用，必然有些手忙脚乱表示理解，但另一角度也说明“面向业务”的测试有多重要。<br>当然能做到测试驱动开发，就更敏捷了。</p></blockquote><p>第二象限的测试一般是自动 + 手动，BDD的测试可以实现自动，另外基于界面的End to End、或者是只基于API的重复性回归测试都尽量自动化，将手动测试放在分析 或者 其他自动测试弥补不了的工作上。并且手动测试时的前置条件、测试数据准备等等，其实也可以借助自动化完成以提高效率。</p><h4 id="3-最后">3. 最后</h4><p>这篇文章里面的两个生活中有趣的例子，放在第一象限、第二象限有人也许会觉得有些硬靠的感觉。<br>我想说 —— 没错🤣。这两个例子硬写进来，就是想吐下槽他们为啥不好好做测试？</p><blockquote><p>我这还有第三个例子：<br>在安和某康做体检预约，小程序填入工号后，接收手机验证码进行登录。<br>第一次登录成功，完成预约，之后几天token失效了。再进行登录，手机就再也接收不到验证码了。<br>反馈给安和某康客服，客服联系了技术部，最后就扔给我一个系统内部日志，告知我已经发送成功。。<br>由于想解决问题，本人愿意协助他们线上debug，并联系联通客服排除了手机和联通设置的一切问题，第二次安和某康技术部还是扔给我一个系统内部日志。。<br>我是一个用户，与其之间隔了电信供应商、短信渠道商、之后可能才到安和后台，给我看后台内部日志。。<br>最后还是客服人员上场，询问我是否完成了预约，没有完成可以人工帮我的哟~ 收不到短信验证码，也可以后台人工查的哟~<br>基于安和某康貌似只是个体检资源协调服务公司，可能科技不是他们的核心领域，直到最后我依然无法再登录，那也只能这样了。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 敏捷 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 敏捷测试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JIRA 报表使用浅析</title>
      <link href="/2019/11/22/jira-bao-biao-shi-yong-qian-xi/"/>
      <url>/2019/11/22/jira-bao-biao-shi-yong-qian-xi/</url>
      
        <content type="html"><![CDATA[<p>首先，贴一下官方报表的说明文档的链接：<a href="https://confluence.atlassian.com/jirasoftwareserver084/reporting-979406465.html">跳转</a><br>最近读了一本书，书中有一句话，大致意思是：文章太长时，大部分人其实都不会读完它。<br>觉得很有道理，但是这篇JIRA还是没办法的写了很长。<br>希望这是本人最后一篇JIRA的博文。耶。</p><p><img src="/2019/11/22/jira-bao-biao-shi-yong-qian-xi/JIRA-1.png" alt="JIRA"></p><h3 id="与Scrum-sprint相关的报表">与Scrum sprint相关的报表</h3><h4 id="1-Velocity-Chart">1. Velocity Chart</h4><p><img src="/2019/11/22/jira-bao-biao-shi-yong-qian-xi/JIRA-2.png" alt="Velocity Chart"><br>该报表会在对应 sprint complete 之后生成出对应的 sprint velocity 总值。<br>主要的作用是统计历史 sprint velocity，用以对将来的 sprint plan 提供 velocity 上的指导和参考。<br>以及在 velocity 趋势波动的时候，结合数据和实际情况进行分析 —— 波动产生的原因，用以调整团队在将来 sprint 中的工作。<br>注意：velocity 本身基于的估算，本身并不能作为一个 sprint 工作量的承诺。</p><p><strong>Commitment（柱）:</strong> 代表 sprint start 的时候，sprint plan 的所有 issues 估算值的总值。<br><strong>Completed（柱）:</strong> 代表 sprint complete 的时候，实际完成的 issues 估算值的总值。<br>**当单次Commitment比Completed高时，**代表未完成计划的 issues scope。<br>**当单次Completed比Commitment高时，**代表 sprint 中 issues scope 发生了变化。<br>ps：当然如果你的团队总是无法在 sprint 开启的时候，确定好 issues scope，那 Commitment 柱基本上是帮不了你了。</p><p>velocity chart 是 board-specific– 的，意思是说 —— 如果有两个 board 使用同一个 sprint，当前 board 的 velocity chart只会计算当前 board scope（根据board configure Filter）。</p><h4 id="2-Burndown-Chart">2. Burndown Chart</h4><p><img src="/2019/11/22/jira-bao-biao-shi-yong-qian-xi/JIRA-3.png" alt="Burndown Chart"></p><p>该报表不需要等到 sprint complete 之后才能看。<br>其根据时间轴，每当sprint内有 issue 估算值变化的时候，就会显示对应变化。<br>Burndown Chart 主要的作用是在sprint过程中实时跟踪sprint的进度，当 issues scope change 造成 burnup，当 issue completed 后 burndown,<br>以及观察团队的当前 sprint 剩余工作量、离最终的整体 burndown 的目标还有多远，是否要采取一些其他的行动改进以达到最终 burndown目标等等。</p><p>Burndown Chart也是 board-specific– 的，基于当前 board filter：</p><ul><li>Scope change - Issue added to sprint（具体原因）: 一个 issue 加入了此 active sprint。具体原因有多种，比如“Estimate of 1 has been added"添加估算，“Estimate changed from 3 to 2”修改估算，等等其他。</li><li>Burndown - Issue completed: 一个issue被完成。“完成”的定义是基于board column的，当issue被挪到active board最右的column，即认为complete。</li></ul><h4 id="3-Release-Burndown-EPIC-Burndown">3. Release Burndown / EPIC Burndown</h4><p><img src="/2019/11/22/jira-bao-biao-shi-yong-qian-xi/JIRA-4.png" alt="Release Burndown"></p><p>Release Burndown / EPIC Burndown 是从 Release version 和 EPIC 的维度，来看涉及到的 sprint issues 的burndown总量。<br>比如上图：<br>首先在左上角下拉框选择要查看的 release version，报表进行显示。<br>图中，该 release 计划交付的 issues 估算值总数102。绿色代表 sprint 完成的量，深蓝色代表 scope change, 浅蓝代表剩余的工作。<br>假设原计划是5个 sprint 后完成所有 issues，那么该图表明进度已经 delay，剩余 issues 估算值28，已经在占用后续 release的sprint 6 的时间，并且在 sprint 6 中减少了5个估算值的 scope。</p><h3 id="与Scrum-sprint无关的报表">与Scrum sprint无关的报表</h3><h4 id="1-Control-Chart">1. Control Chart</h4><p><img src="/2019/11/22/jira-bao-biao-shi-yong-qian-xi/JIRA-5.png" alt="Control Chart"><br>主要作用是来查看项目的cycle time（or lead time）。<br>cycle time代表issues在具体的column对应的状态上耗费的时间。<br>lead time代表整个团队对issues —— 从对应的需求提出到实现完成耗费的时间。</p><p>先从图上按顺序来看一下：<br>① 指向的绿色空心点，代表一个 issue。如果是一个大的绿实心点，代表一堆很接近的 issues。<br>② 指向的是，可自定义的报表 x横轴 时间区间。<br>③ 表示，在报表上使用鼠标悬浮滑动，可以查看固定时间点的值信息。<br>④ 指向的是，Refine report，此报表最重要的一块 —— 针对 issues scope 的选择。<br>报表最上面是统计信息<code>cycle time</code>、<code>issues count</code>。</p><p><strong>Refine report</strong><br><code>Columns</code> / <code>Swimlanes</code> / <code>Quick Filter</code> 三个过滤条件是 “与&amp;” 的关系。</p><ul><li><code>Columns</code>：基于board columns，提供多选。勾选上的 columns，报表会计算出 issues 处于被勾选的 columns 的总 cycle time，并进行显示。<br>而报表图上的issue绿点的横向坐标，代表该 issue “终止”该组 columns 的时间点。纵坐标代表该 issue 的cycle time。</li><li><code>Swimlanes</code>: 基于board configure Swimlanes设置的JQL filter进行issues scope过滤。</li><li><code>Quick filter</code>: 基于 board configure Quick Filters 设置的 JQL filter 进行 issues scope 过滤。</li></ul><p>Swimlanes 一般是基于board计算的，变动不会太大和频繁。因此，可以通过随时定制 Quick filter，来进行 Control chart 报表分析时的过滤。<br>比如添加一个 Quick filter —— 为了过滤出某一个 sprint 或者 release 的 issues；还比如官方推荐了一个去除<code>没有参考价值的异常issue</code> 的方法，就是通过在具体的异常 issue label 上进行标记，然后定制 Quick filter 进行过滤的方式，在 Control Chart 统计时排除异常 issues。</p><p><strong>Include non-working days in calculations</strong><br>报表右下角有一个viewing option，<code>Include non-working days in calculations</code>不勾选时，cycle time 的计算不会包含非工作日。<br>至于 Control Chart 上统计数据<code>cycle time</code>，包括average\median\min\max的时间显示，单位w/d/h中，<code>1w = 7 working days</code>，仅是一种简单的单位换算，不要产生误区。</p><p><strong>查看lead time</strong><br>如果项目设定 issue 从 <code>ready for dev</code> 到 <code>In dev</code> 到 <code>Dev Done</code> 到 <code>In QA</code> 到 <code>QA Done</code>，是一个需求从提出到完成实现的整个流程的话，将 columns 勾选上 <code>ready for dev</code> \ <code>In dev</code> \ <code>Dev Done</code> \ <code>In QA</code> 4个状态，则可以统计和绘制出 lead time 和相关 issues。<br>如果想分析 —— 到开发们完成卡的这段 cycle time，可以仅勾选<code>ready for dev</code> \ <code>In dev</code> 2个状态，即可查看。注意，不要将最后的缓冲队列 <code>Dev Done</code> 误勾选进去。</p><p><strong>rolling cycle time</strong><br>rolling cycle time是根据<code>当前issue + 前面x个issue + 后面x个issue</code>的平均cycle time。x 是基于时间轴上的issue总数的一个取值。<br>目的是为了展示cycle time的一个具体范围趋势 —— average cycle time就是一条水平线。<br>报表上的蓝色阴影区，代表issue cycle time和rolling cycle time的标准偏差值，蓝色区域越窄，代表issue cycle time更接近周边的issues cycle time，这段rolling cycle time置信值越高；越宽的区域，issue异常情况越多，rolling cycle time置信值越低。rolling cycle time置信值越低，代表该时间段附近issue异常越多。</p><p>另类使用小tips：columns单选之后，比如In Dev，计算出来的Average cycle * issues count，可以看到在此column内对应issues的时间投入程度（前提，团队有按真实情况及时挪卡）。</p><h4 id="2-Cumulative-Flow-Diagram">2. Cumulative Flow Diagram</h4><p><img src="/2019/11/22/jira-bao-biao-shi-yong-qian-xi/JIRA-6.png" alt="Cumulative Flow Diagram"></p><p>Cumulative Flow Diagram 其实非常简单，横轴是时间轴，纵轴是 issue 数量。<br>不同的色带，代表不同的 column，色带上边界值代表该时间点进入过（处于该column + 已经transfer到后续column）的 issue 总数值，色带的纵向宽度即是 “处于该column” 的 issue 总数。<br>Cumulative Flow Diagram 主要用来分析 issues 流量趋势是否正常、团队是否存在瓶颈。<br>比如：<br>在某一个时间段内，Dev done 色带在纵向上逐渐变宽，代表等待 QA 测试的 issues 堆积越来越多，QA 存在瓶颈；<br>在某一个时间点，In Dev 色带上边界值有下降趋势，代表有部分 issues 从 In dev 状态被重置回上游 column，代表 issue 内容可能被返工；<br>在某一个时间点，In Dev 色带在纵向上的宽度比正常时窄，说明在制品在减少，如果开发人员并没有减少时，代表部分开发人员在空转；<br>在一个 sprint 时间段内，Preparing 高度仍然在上升，说明 sprint scope 在增加；<br>所有 in progress 的 columns 色带，在横向宽度上变宽，说明 lead time 在逐渐变长。</p><p><strong>Refine report</strong><br>与 Control Chart 相同，对 issues scope 进行过滤。参照Control Chart Refine report。</p>]]></content>
      
      
      <categories>
          
          <category> 敏捷开发管理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 敏捷开发管理 </tag>
            
            <tag> JIRA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Scrum形外之神</title>
      <link href="/2019/10/23/scrum-xing-wai-zhi-shen/"/>
      <url>/2019/10/23/scrum-xing-wai-zhi-shen/</url>
      
        <content type="html"><![CDATA[<p>什么是Scrum?<br>Scrum是敏捷软件开发过程的一种框架，用以实现迭代式增量开发。<br>好吧，很抽象。</p><p>那是不是 —— 只要有了sprint、IPM、Showcase、Retrospective、可视化卡墙、每日站会，这些流程和工具，就已经实现Scrum了呢？<br>也许有人会说是。这看起来基本就是一个Scrum的MVP(Minimum viable product)。</p><p>好，那假设我们的团队已经实现了Scrum流程的MVP。<br>现在，我们来进行一下每日站会。请每个人依次对三个问题进行描述。<br>三个问题，哪三个问题？</p><ol><li>你昨天做了什么？</li><li>今天计划做什么？</li><li>遇到什么阻碍或问题？<br>一般大家都认为是这三个问题是不是？</li></ol><p>很多人都容易把每日站会视为一个简单的个人报告会。<br>但其实，Scrum的原版三个问题是：</p><ol><li>你昨天做了什么去帮助团队完成冲刺？</li><li>今天你打算做什么来帮助团队完成冲刺？</li><li>什么因素阻碍了团队的前进之路？<br>请注意，有两个字在这三个问题中一再出现 —— “团队/团队/团队”。<br>也许有人会认为区别不大 —— 每个人做好自己的工作，就是在推进团队整体的进度。</li></ol><span id="more"></span><h3 id="1-团队之力">1. 团队之力</h3><p>实行scrum的目标之一，提升团队能效，项目进展速度应该是越来越快的。</p><h4 id="1-1-团队学习和知识共享">1.1. 团队学习和知识共享</h4><p>假设有一堆3个月以上工作量story卡，有两种选择：</p><ol><li>分给5个工程师，他们各自都有充足的业务上下文来开发，但这5个工程师相互之间都不在同一个team，需要每人独立完成工作。</li><li>分给一个有5个工程师的team，团队性完成工作。<br>从做卡速率来考虑，你会倾向于哪一种选择？</li></ol><p>估计在有的PM看来，如果这些工程师的技能Level都相同的话，这两种选择根本没有太大区别。<br>但是其实不然。</p><p>如果可以选择，将这里的工程师都替换成10倍效率工程师，选择一的整体做卡速度会提升10倍；而选择二中即使替换成5倍效率工程师，整个团队整体做卡速度也会远远大于10倍。<br>为什么？</p><p>一个简单的场景：假设story卡中涉及到新的技术知识，选择一，整体花费的从零开始独立的学习时间是5人份；而选择二，只需要团队中一个人从零开始学习，然后通过有效的知识分享和传递，快速的让整个团队所有人掌握此项技术。</p><h4 id="1-2-消除单人进度的瓶颈">1.2. 消除单人进度的瓶颈</h4><p>当然也不只是学习新技术的场景，联想一下平时有没有这样的场景：<br>A工程师在站会上表示当前进度被一个技术性问题困扰，正好B有相关经验，于是B主动表示今天会跟A pair来为其加速和传递相关知识。</p><p>每个个体都有长短板和瓶颈，团队正是相互之间以己之长、补彼之短。<br>即使很不巧，一个团队中长短板都相同，这里可以想象一下鸣人利用影分身学习的场景————多线程不同角度的试错，再通过交流和知识共享，最终还是能让团队快速克服瓶颈、获得更全面的成长。</p><h4 id="1-3-小规模的加持">1.3. 小规模的加持</h4><p>从上面两点可以观察到团队之中相互之间信息透明、沟通交流非常重要。<br>Scrum团队中，每个成员都必须知道其他人在做什么。同时每个人自己正在做什么工作，正面临着哪些挑战，取得了哪些进步等等，都必须透明，让别人知道。<br>这里其实会花费一些沟通成本，如果团队过大，固然是会让沟通成本增加，同时会给每个成员关注的沟通渠道数带来很大的压力。<br>团队成员增加之后，相互之间沟通渠道就会大幅增加。</p><pre class="line-numbers language-none"><code class="language-none">团队总沟通渠道数 = n * (n - 1) / 2# n为成员数量<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果是7人，团队总沟通渠道数是21，9人是36，10人则是45。<br>人类的大脑可能根本无法应付这么多的沟通渠道。<br>相信大家都在站会和code review的时候有这样的感觉，当人数上升之后，越来越不能充足的了解其他成员正在干什么，更别说主动发现并给予帮助了。</p><h3 id="2-快速反馈和改进之力">2. 快速反馈和改进之力</h3><p>Scrum的目标是为了实现迭代增量开发，从而产生反馈，从中学习，之后调整我们正在构建的东西和我们的构建方式。<br>sprint为团队提供了相应的机制。</p><p>我们先过一下sprint整体流程。<br><code>sprint之初 —— IPM</code>：在每次冲刺之初，都会举行一次会议，产品负责人讲解需求，并由开发团队规划冲刺内容，即在未来两周内能完成多少工作，明确sprint结束时可交付的产品增量目标。<br><code>sprint运行中</code>：在sprint中，团队有两项工作：完成在当前sprint计划的工作以及准备下一个sprint。<br><code>sprint结束之前 —— review（showcase）</code>: 不展示成果，就没有效果。每次sprint的交付物应该是潜在可交付的产品增量，在showcase上展示已明确完成的增量成果，与sprint开始之前的完成目标进行对比，接受评审反馈。<br><code>sprint最后 —— team Retrospective</code>: 团队回顾会议，在会议中回顾整个sprint过程，反思过去以改善将来的sprint。</p><h4 id="2-1-快速反馈">2.1. 快速反馈</h4><p>每个sprint可看做是一种实验。<br>通过迭代sprint这种短期的time-box，每一次sprint结束之后，潜在可交付的产品增量可以让客户和团队快速评估该实验，获得反馈。<br>他们可以根据在上一个sprint中的发现来判断自己的前进方向是否正确，以及判断他们下一步打算做的事情是不是恰当的。<br>失败得快，才能迅速改正。</p><h4 id="2-2-检查和调整">2.2. 检查和调整</h4><p>Scrum的一个重要意义就是改变团队对时间的看法。实行sprint和每日站会一段时间之后，团队就不会再把时间看成一支径直飞向未来的箭，而是从周期性的视角去看待时间。</p><p>利用这一个个周期，形成戴明PDCA循环（Plan-Do-Check-Action）。<br>Review和Retrospective，就是scrum中形成检查和调整的一环。<br>不只是”检查和调整“团队构建的东西，还要”检查和调整“团队构建的过程。</p><p>每经过一次sprint，检验一下团队做的事情，看看是否朝着正确的方向前进？结果是不是真正希望看到的？是否有什么办法能改善目前正在做的事情？如何才能做得更快更好？存在哪些潜在的障碍？这一点看似容易，做起来并非易事，需要有思想，善于自省，有实事求是基于事实的数据和依据、自我约束的意识。</p><p>有人曾经发问：如果团队成员都不想开Retrospective，作为PM你打算怎么办？<br>当时的一个答案是：其实敏捷实践施于团队，都是可以根据团队实际情况进行剪裁的。如果团队觉得没有必要开，那就可以不开。<br>但我想说的是，对于Scrum，如果没有其他手段形成周期性最后的”检查和调整“闭环，那Retrospective就一定要开。即使是团队成员对于当前的Sprint状态、速度、步调非常满意，因为 —— 即使是这种情况，在Retrospective meeting上，团队也要回答一个重要问题：”你们如何才能做得更好？“</p><h3 id="3-短期详细计划，消除浪费之力">3. 短期详细计划，消除浪费之力</h3><p>在最早的软件开发方法 —— 瀑布式软件开发中，前期会做大量的分析、设计和计划，编写大量详细的文档文档、绘制大量的甘特图报告企图体现和控制软件的开发进度。而当现实进度与计划报告有矛盾时，认为往往认为问题出在现实上，认为图表是正确的。<br>本身这种长期计划和进度控制办法，建立的这种制度 —— 无异于强迫自己一味地空想。<br>首先，这种付出大量努力去规划细节，限制潜在变化，并预知未知因素的长期计划，最后往往会徒劳无功。每一个项目在开发过程中都需要人们去发现新问题，去激发自己的灵感。<br>其次，企图回避现实的不确定性。<br>另外，无法响应外在环境和商业的不断变化。<br>最后，是非常现实的一个问题 —— 人类其实非常不擅长于预测一件事情需要耗费的时间。</p><p>而在scrum中团队只需要对下一个sprint做详细计划，使用短周期来增加确定性、应对变化、快速反馈。节省长期计划中起不到作用的分析、设计、沟通协调的时间。</p><h3 id="4-专注目标、可持续的步调之力">4. 专注目标、可持续的步调之力</h3><p>sprint之所以叫冲刺，是可以让人产生一种紧张激烈的感觉。<br>但它强调的并不是 —— 长跑马拉松始终以最后200米冲刺的不可持续的节奏进行开发，反而十分强调可持续性开发节奏。</p><p>首先，不要改变当前sprint的目标。<br>一旦一个团队决定要完成某些任务，那么这些任务就锁定了，团队之外的任何人都不能再给他们增加任务，干预和扰乱团队只会大幅放缓团队的工作进度。<br>即使一些人质问敏捷不就是要拥抱变化吗？Scrum的拥抱变化不意味着可以在同一个sprint内进行改变。<br>其实，很少有企业身处“变化迅猛以至于企业不能在2周sprint的开始就设定优先级然后保持这些优先级不变”这样的行业中。许多企业也许认为他们就处于那样的环境，但事实上不然。<br>要达到不要轻易改变当前sprint的目标，这通常要求我们慢慢习惯于“提前思考”，不要“缺乏远见”。</p><p>其次，不要台球短跑。<br>台球短跑指，团队刚完成一个sprint，还没准备开始下一个，下一个sprint又开始启动。第二个sprint经常只是所谓的开始，实际上团队还根本没有准备好做这个sprint的工作，以致于他们不得不花费几天时间学会要干什么。<br>要记住，在当前sprint中，团队有两个目标：完成在当前sprint计划的工作以及准备下一个sprint。<br>特别PO、UED这些团队对其有前置依赖的角色，需要及时提前准备下一个sprint。这样可以让整个团队的交付步伐一直处于顺畅、可持续的状态。</p><h3 id="5-可预测之力">5. 可预测之力</h3><p>团队内，需要知道自己的速度。<br>每个团队都应该准确知道自己在每个sprint阶段中完成了多少工作，并且应该知道如何以更加聪明的方法去消除障碍，加快工作速度。<br>知道自己的工作速度之后，就能计算出交付日期，<code>速度 × sprint次数＝交付工作量</code>。</p><p>团队外，稳定、短期的交付频次，可以带给客户明确的”可预测性“ —— 基本上提出的需求和问题只要等待一个固定周期就可以上线。<br>当然如果客户在明知”可预测性“的基础上，仍然总是要求”快速响应“，没有耐心等待一个固定周期时间过去，那就可以考虑缩短这个固定周期的时间长度。比如，如果是2次sprint才release一次，则可以考虑是否能1次sprint就release。</p><h3 id="6-总结">6. 总结</h3><p>学习Scrum框架，使用其进行软件开发过程管理，往往很容易。<br>但，是不是总有那么一些团队，明明用了Scrum仍然每日疲于奔命？<br>是否是只见Scrum其形，不见其神呢？<br>如果是，可以检查一下是否有 其神中未发挥出来的力量？<br>如果是，可能团队需要考虑有一位专职的Scrum守护者 —— Scrum master。</p><h3 id="7-参考文献">7. 参考文献</h3><ol><li>《敏捷革命》，Jeff Sutherland 著</li><li>《Scrum 敏捷软件开发》，Mike Cohn 著</li><li>《硝烟中的 Scrum和 XP》，Henrik Kniberg 著</li></ol><p><img src="/2019/10/23/scrum-xing-wai-zhi-shen/cover.png" alt="封面"></p>]]></content>
      
      
      <categories>
          
          <category> 敏捷 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 敏捷 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么不鼓励加班</title>
      <link href="/2019/10/15/wei-shi-me-bu-gu-li-jia-ban/"/>
      <url>/2019/10/15/wei-shi-me-bu-gu-li-jia-ban/</url>
      
        <content type="html"><![CDATA[<p>首先，此篇文章有个大前提，主要针对知识性工作。<br>“知识性工作”与“可重复性的生产活动”对立。</p><p>看到这个标题的时候，大概很多人都会想——这是一篇996员工 ICU 的软文：不鼓励加班，是为了让员工过平衡的生活。<br>欧美不少公司不鼓励加班，是因为——他们重视员工的工作和生活。<br>我只想说：图样图森破。当然，也有可能仅仅是公司不想付加班费。</p><p>Scrum 之父杰夫·萨瑟兰 ，直接指出：“<strong>工时越长，效率越低。</strong>”<br>在一些管理者眼中：加班加点地工作不是敬业的标志，而是失败的标志。让员工早点下班，不是想让他们过一种平衡的生活，而是为了他们可以完成更多的工作。</p><span id="more"></span><h3 id="1-工时越长，效率越低">1. 工时越长，效率越低</h3><p>这个观点看起来貌似没有根据，是不是？<br>当然，有人会有预见性地说：完成知识性工作的主体是人，一天中人的集中力是有限的。即使当天工时延长，总的集中力的时长并不会相应延长。<br>说的不错。</p><p>同时，知识性工作中，其实伴随着大量的决策。有令人不安的证据显示，人们做决策的能力很有限，精力消耗得越多，休息时间越短，做出的决策就会越糟糕。<br>在 Scrum 之父的《敏捷革命》中有这样一个有趣的举证：</p><blockquote><p>2011年4月，以色列一组科研人员在《美国科学院院报》上发表了一篇关于决策科学的论文，非常值得关注。他们的论文题目是《司法裁决中的外部因素》。</p><p>这篇论文分析了8名以色列法官做出的1000多项司法判决。这8名法官主持着两个不同的假释裁决委员会。他们裁决的犯人有男性也有女性，有犹太裔以色列人也有阿拉伯裔以色列人。所犯罪行包括贪污公款罪、故意伤害罪、谋杀罪和强奸罪。法官们所审理的绝大多数案子都是假释申请。</p><p>这类工作似乎很简单，对吗？这些受人尊敬的法官运用自己多年来的经验和智慧做出至关重要的决定，不仅影响犯人与受害者的生活，还会影响整个社会的福祉。他们每天都会审理14~35个案件。</p><p>以色列的研究人员分析了法官做出裁决的时间、是否批准假释以及上一次吃点心的时间。如果法官刚吃完点心休息好，或者刚吃完午餐后开始上班，那么，有利于犯人的裁决就会占到60%；但是快到下一轮休息时间时，有利于犯人的裁决比例就会下降到零。</p><p>基本上，在短暂休息后，法官的态度都会比较积极，也比较容易做出宽大的裁决。对于这个世界发生犯罪行为的可能性以及犯人改过自新的可能性，他们会表现出较多想象力与包容心。但随着精力逐渐耗尽，维持现状的裁决便越来越多。</p><p>我敢肯定，如果你问这些法官是否相信自己每次都能做出同样良好的裁决，他们就会觉得受到了侮辱，但数据不会撒谎。当我们精力耗尽的时候，我们很容易做出荒谬的决定。</p><p>这种现象被称为“自我损耗”，意思就是，做出任何选择都需要耗费一定的精力。这是一种奇怪的损耗，因为你感觉不到身体的疲惫，但做出良好决定的能力会下降。你的自我控制能力、自我约束能力、思考能力以及预见能力等都会趋于减弱。</p></blockquote><p>是不是联想一下平时日常生活中的例子，会有一些感同身受？<br>很多时候，延长工时并不能继续增加产出——<code>正常不加班时的效率</code> x <code>延长的工时</code>。</p><p>记得这次在十一之前，与我方项目集成的一个乙方 team，由于进度落后的原因，许诺甲方会十一加班 7 天。<br>老实说，刚听到这个消息的时候我惊呆了——这种伤其团队根本的决策，都有勇气去做。<br>后来十一假期之后，我方项目与其集成联调，得到消息 —— 彼方这 7 天对于进度来说，并没有显著效果改善。</p><h3 id="2-工时越长，自我改进的标准越低">2. 工时越长，自我改进的标准越低</h3><p>这里主要是，想聊一下知识性工作中的软件开发这个行业。<br>持续改进，是软件开发中敏捷项目的一大特色。</p><p>当每日交付工时由于feature延长时，对于陈旧或者不合理地流程设计、架构设计、质量提升、可重构的代码等改进决策、创新决策，项目往往会采取保守的态度、更倾向于先维持现状。<br>直至于——自我改进的标准降低到不见——能完成feature功能交付就不错了。</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 敏捷 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python bumpvesion 使用</title>
      <link href="/2019/10/04/python-bumpvesion-shi-yong/"/>
      <url>/2019/10/04/python-bumpvesion-shi-yong/</url>
      
        <content type="html"><![CDATA[<p>python library project升级版本的工具。<br><a href="https://pypi.org/project/bumpversion/">开发者上手说明</a></p><p>这里按 source version control的项目配置进行说明。</p><ol><li>安装 bumpverson</li></ol><pre class="line-numbers language-none"><code class="language-none">pipenv install bumpversion --dev<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>添加配置文件<code>.bumpversion.cfg</code>，并加入版本管理。<br>配置文件内容：</li></ol><pre class="line-numbers language-none"><code class="language-none">[bumpversion]current_version = 0.1.1commit = Truetag = True[bumpversion:file:setup.py][bumpversion:file:package_name/__init__.py]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面一个[]下面是针对一个 section 的详细配置。<br>如，有两个需要控制 verion num 的地方，则要配置两个[bumpversion:file:…] section。<br><code>current_version = 0.1.1</code> 记录当前的版本是 0.0.1。<br><code>commit = True</code> bump 的时候会自动生成一条 commit。可以配置 commit msg 格式。<br><code>tag = True</code> bump 的时候自动打 tag。<br>具体每一项详细配置可见官方说明。</p><ol start="3"><li>运行 bumpversion 命令。</li></ol><pre class="line-numbers language-none"><code class="language-none">pipenv shellbumpversion &lt;part&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>part 默认主要是 <strong>major</strong>、<strong>minor</strong>、<strong>patch</strong>。<br>输入对应的 part，bumpversion 会对应的进行 version 升级。<br>比如：<code>bumpversion major</code>, 按上面的配置，version 会由<code>0.1.1</code>升级为<code>1.0.0</code>。</p><ol start="4"><li>push commits/tags。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>简单 JIRA Scrum Board 姿势</title>
      <link href="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/"/>
      <url>/2019/09/12/jian-dan-jira-scrum-board-zi-shi/</url>
      
        <content type="html"><![CDATA[<p>老实说，刚开始要写这篇博文的时候，我在想：我是谁？我在哪里？我在干什么？</p><p>目标：</p><ol><li>为了让JIRA board owner和admin创建出来的Scrum board更规范；为了使JIRA user在挪卡的时候，有效信息能被能好的track；为了用以统计分析、跟踪的reports能更好的为项目服务。</li><li>为了在team Retrospective meeting中，能更好地对Sprint进行回顾，从数据上提供更好的事实支撑和具体分析；为了在以后的Sprint进行逐步良性改善。</li></ol><p>最后自己心里还是默念：我是个Tech，我是个Tech，我是个Tech。</p><h3 id="JIRA概念性模型">JIRA概念性模型</h3><p><strong><code>Project</code></strong>: 可以理解为Issues所属的集合、命名空间。一般而言，可以一个software project来创建其对应的JIRA project。<br><strong><code>Issue</code></strong>: 可以具象理解为卡片，一个issue就是一张卡片。<br><strong><code>Issue type</code></strong>: 卡片类型，可以是Epic、story、bug、task等。<br><strong><code>Status</code></strong>: 卡片可以选择的状态。一堆status和transition构成一个具体的工作流（workflow），卡跟随工作流中设定的状态进行流转，完成卡的整个生命周期。</p><p><strong><code>Board</code></strong>: 具体的项目实践管理的操作空间。一个board可以关联一个project，也可以关联多个project，取决与创建board时的设置。简单一点话，我们这里还是让一个board仅关联一个project即可。<br><strong><code>Backlog</code></strong>: board中，未加入具体sprint的issues，则会显示在backlog区域内。<br><strong><code>Sprint</code></strong>: Scrum中的一个概念，代表一个固定的时间盒子（time box），可以是2周~4周。项目团队以每个sprint实现短期交付目标和增量式迭代。在JIRA中，一个Sprint中会加入一批Issues，用以详细定义此次Sprint的目标和工作内容。<br><strong><code>Active Sprint</code></strong>: 已经组织好issues list的sprint可以通过Sprint plan meeting(或者叫Iteration plan meeting)之后，将此Sprint激活。这时，此Sprint内的所有issues会自动显示在Active Sprint页面上 ———— 大多数JIRA User所关注的可视化电子墙则成功出现。<br><strong><code>Release / version</code></strong>: JIRA中没有Release这个实体概念。Release对应的实体，其实是version。在Issue的属性中关联上Fix version，则issue可以从Release / version的维度进行数据统计和进度track。</p><h3 id="简单上手">简单上手</h3><p>如果JIRA新手，可以先参照官方的<a href="https://confluence.atlassian.com/jirasoftwareserver/getting-started-as-a-jira-software-manager-938845036.html">Getting started as a Jira Software manager</a></p><p>这里，假设我们已经有了Project和已经完成了User Management ———— 一个已经运行了一段时间的开发项目，我们尝试来创建一个新的JIRA Scrum board。</p><h4 id="1-创建一个新的Scrum-board。">1. 创建一个新的Scrum board。</h4><p>在旧的board上，点击右上角的按钮[Board]，在下拉框中选择[Create board]。<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-1.png" alt="board dropdown list"></p><p>然后在下一步中选择[Create a Scrum board] &gt; [Board from an existing project]。可看到下图:<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-2.png" alt="create board dialog"></p><p>输入相应信息后，点击[Create board]，这时新的board就会创建出来。<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-3.png" alt="new board"></p><p>由于创建时选择了已存在的一个project，该project中有未分配给sprint的issues则会自动显示在新的board的backlog中。<br>当然如果board中只需要显示project中一部分的内容，可以通过修改board configuration页面中的filter进行过滤。</p><h4 id="2-配置board的Estimation。">2. 配置board的Estimation。</h4><p>点击board页面右上角的[board]按钮，选择[Configure]。<br>进入board configuration页面，选择[Estimation] tag。<br>在该页面上选择estimation和tracking基于的单位。<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-4.png" alt="board configration estimation page"></p><h4 id="3-使用backlog来为sprint做准备。">3. 使用backlog来为sprint做准备。</h4><p>从board页面，点击页面最上方的[create]按钮，来创建issue。<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-5.png" alt="create issue popover"></p><p>录入issue的必要信息，这时候estimation值一般是没有的，留待IPM中填充。<br>等准备好所有issues之后，backlog显示如下：<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-6.png" alt="Backlog page"></p><h4 id="4-开启IPM（Iteration-plan-meeting）">4. 开启IPM（Iteration plan meeting）</h4><p>在会议上，通过开发人员一起确认各个issue的估点，并且“创建”Sprint，根据估点和优先级，将issues拖入Sprint中。</p><ul><li><p><strong>录入估点</strong><br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-7.png" alt="Backlog page"></p></li><li><p><strong>创建Sprint</strong><br>点击Backlog右上角的[Create Sprint]，创建一个空的Sprint。然后拖入此次Sprint的issues。<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-8.png" alt="Backlog page"></p></li></ul><h4 id="5-准备开启Sprint。">5. 准备开启Sprint。</h4><p>最后检查一遍issues上的必要信息，特别注意估点（Estimation）已经成功录入。<br>检查完后，点击sprint右上角的[Strart Sprint]。接着在弹出框中选择好time box时间周期，最后点击[Start]。<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-9.png" alt="Start Sprint dialog"></p><p>这时，该Sprint会进入Active状态，所属issues会显示在board的Active board page中。<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-10.png" alt="Active Sprints page"></p><ul><li><strong>为什么提醒一定要再检查一遍issues，特别是在确认估点录入之后再start Sprint？</strong><br>因为按这个正常的流程，可以得到一个正常的燃尽图。见下：<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-11.png" alt="正常的燃尽图和track表格"></li></ul><p>如果在start sprint后才开始加入估点记录，则会获得这样的燃尽图报表：<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-12.png" alt="无用的燃尽图"></p><p>初始点y值为0，guideline完全贴在X轴，没有任何sprint初始Estimation，之后再录入任何一条issue的估点，都被展示成“Scope change”。<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-13.png" alt="燃尽图下面的track表格"><br>而真正的涉及到Scope change的issue track就会傻傻地无法区分。</p><h4 id="6-修改Active-board-column。">6. 修改Active board column。</h4><p>进入board配置页面，选择Columns page。<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-14.png" alt="初始columns"></p><p>JIRA默认的Columns一般分为3条 —— TODO、In progress、Done，一般status和columns是对不上的，可以进行添加和修改。<br>点击[Add column]，可添加一列，也可以直接点击已有的Column对其进行修改。<br>然后，将对应的status分配到Column中。<br>在不同的column之间移动的issue时，issue的状态会自动流转到column对应的status。<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-15.png" alt="配置好 columns "></p><p>同时Active Sprint也会同步刷新为新的Columns布局。<br>至于status的添加和修改，需要JIRA Project admin的权限可以对workflows进行修改。</p><p><strong>特别要注意</strong></p><ul><li><strong>最后一个Done column中的status一定要明确。如果Done column中有两个及以上status时，请务必确认其相互之间不是上下游状态关系，而是非此及彼的平级关系。</strong><br>因为同一个column中，无法再通过拖动issue来变更status。<br>同时如果上下游关系的status混在一个column里也会让lead time无法很好的统计。<br>下图就是一个不好的示例 —— Done column中既有<code>QA Done</code>，也有<code>UAT Done</code>。<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-16.png" alt="Done选还是不选"></li></ul><p>其中QA Done issue count为45， UAT Done issue count为31。<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-17.png" alt="半停滞的Done column"></p><ul><li><strong>一定要确认最后一个Done column中的status是否需要transition时set resolution。</strong><br>如果还有下游的board需要流转和处理同一批issue的情况，可以暂时一部分status不需要设置set resolution。<br>否则，请将最后一个Done column中对应的status transition在workflow配置中，加入set resolution post Function。</li></ul><h4 id="7-如何对没有resolution的status添加Post-function？">7. 如何对没有resolution的status添加Post function？</h4><p>点击board页面左下角的齿轮按钮[Project setting]，在点击[workflows],选择对应workflow。<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-18.png" alt="Workflow edit"></p><p>点击[Edit]按钮，进入编辑状态。假设想要给<code>QA Done</code>添加set resolution，点击图右边transition的[post Functions] link。<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-19.png" alt="Post Functions"></p><p>点击[Add post function]，进入添加post function的引导流程。<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-20.png" alt="引导图"></p><p><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-21.png" alt="引导图"></p><p><strong>为何强调一定要加入set resolution?</strong><br>在JIRA中并不是自定义一个叫Done的status就代表这张卡片已经达到完成标准、走到了生命周期的终点，而是需要使用issue上的resolution field。<br>如果最后不添加resolution会造成的影响，会对一些报表和filter的使用造成影响。<br>官方说明见下：<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-22.png" alt="官方resolution说明"></p><p><strong>特别说明燃尽图报表：</strong><br>燃尽图报表中的issue是否complete，是否burndown，与resolution field无关 —— 仅于board上最右的column有关。<br>只要issue移动到最右的column，即会显示burndown。<br>官方说明见下：<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-24.png" alt="官方burndown chart说明"></p><h4 id="8-JIRA-board-users在sprint中，领取issue和传递issue时，一定要记得及时挪卡。">8. JIRA board users在sprint中，领取issue和传递issue时，一定要记得及时挪卡。</h4><h4 id="9-在sprint结束时，一定要记得及时手动点击complete-sprint。">9. 在sprint结束时，一定要记得及时手动点击complete sprint。</h4><p><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-25.png" alt="complete sprint"><br>点击右上角link[Complete Sprint]，这时对于未Done的issue会进行提示：<br><img src="/2019/09/12/jian-dan-jira-scrum-board-zi-shi/JIRA-26.png" alt="complete sprint dialog"><br>可以选择移入backlog，或者移入新的sprint中。<br>在这里不要因为Sprint时间到了，仍有未完成的issue，而害怕将Sprint complete。<br>所有的track行为都应该以实际情况为准，这样生成的数据才能真实进行反馈，为将来的改进提供有效的建议和数据支持。</p><p>Sprint complete了之后，如velocity report就可以计算和汇总这次sprint velocity了。</p><h3 id="总结">总结</h3><p>既然用了有用的工具，就要有效的使用起来。<br>要避免仅将JIRA当成一个可视化电子墙的误区。</p>]]></content>
      
      
      <categories>
          
          <category> 敏捷开发管理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 敏捷开发管理 </tag>
            
            <tag> JIRA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>写业务代码真的有那么无聊吗</title>
      <link href="/2019/07/19/xie-ye-wu-dai-ma-zhen-de-you-na-me-wu-liao-ma/"/>
      <url>/2019/07/19/xie-ye-wu-dai-ma-zhen-de-you-na-me-wu-liao-ma/</url>
      
        <content type="html"><![CDATA[<blockquote><p><em>前面先写一点废话。</em><br><em>由于最近在整理一些DDD、微服务、架构相关的知识总结，一边看一边回忆一些经历，又由于本人看的东西有时候很杂，记忆力又大不如前，本打算仅用私人手账的形式记录一下。</em><br><em>但回看了一下2019年年前立的flag —— 50篇博客（应该是完不成了吧。。），又想到最近一段时间接触到的咨询同事的写作能力，唉。</em><br><em>虽然对自身写作和语言表述能力有些萎靡不振，但，人不能不上进。</em><br><em>因此，准备开始简书。</em></p><p><em>这里有人可能要问了：你不是跑去搞区块链了吗，怎么又跑回来微服务、DDD了？</em><br><em>嗯。。这个问题问的好。这里就不得不提到本人去搞区块链之前的一段近两年的项目经历了。</em><br><em>怎么说呢，这个项目虽然在我的项目经历中已经完结了，但它遗留在我心中的问题还没有完结。</em><br><em>就是这样。</em></p></blockquote><h4 id="1-有时候你不得不去写的业务代码">1. 有时候你不得不去写的业务代码</h4><p>最近出差回来，遇到一些之前项目上的同事聊到自己当前的新项目，无不感叹——不用再像以前一样不停地写业务代码了。<br>嗯，可以多玩一些技术、或者新的技术，总是可以让搞技术的人兴奋很久。<br>但是，比较可惜，所谓技术要盈利，就要交付产品。要交付产品，必然就会有业务。即使是DevOps平台这种纯技术型的产品，技术上的CI/CD就是它的业务。<br>写业务代码，对每个开发来说，基本上都必不可少。<br>这时候，技术需要通过实现业务，来展现价值。</p><h4 id="2-写了这么多业务代码，你是否真的会写业务代码">2. 写了这么多业务代码，你是否真的会写业务代码</h4><p>一定会有人觉得这个问题很奇怪，业务代码不就是一个不断累加的过程么，有什么会与不会？<br>说实话，在没有之前那次两年经验的时候，我也是这样想的。但通过那两年的经历，我意识到 —— <strong>复杂业务系统</strong>，业务绝对不是 1+1=2 这么简单。<br>但即使这样，在我经历最近一个短期项目，跟客户合作开发的时候，又意识到 —— 即使是 <strong>简单业务系统</strong>，如果开发人员没有 建模意识、或者面向对象的经验、甚至说是没有业务的理解消化能力，写出的代码甚至连 1+1=2 都做不到。</p><span id="more"></span><p>这个事情是这样的。<br><strong>背景</strong>：项目是做一款区块链的手机钱包（当然这里要说的与区块链知识无关）。<br>可以简单的理解一下 —— 每一个该APP的<strong>User</strong>可以通过”手机号+验证码“登录该APP，而每个User下可以有一批账户<strong>Account</strong>。<br>可以想象比对为，某银行app的一网通账号 -&gt; User，一网通账号下有多张银行卡、信用卡账户 -&gt; Account。<br><strong>业务需求</strong>：进入APP首页的时候，首页展示的**”当前Account“**默认为最近一次使用的Account。<br><strong>实现背景</strong>：后台保存数据状态，使用的MySQL数据库。（有一些其他背景，我这里就不另描述为何不采用APP前端保存等方式）<br><strong>表结构类似</strong>：<br><img src="/2019/07/19/xie-ye-wu-dai-ma-zhen-de-you-na-me-wu-liao-ma/question.png" alt="现有表结构"></p><p>看到这里，每个人应该内心都有自己的实现方式了。<br>基于这是一个业务简单的系统，可以尝试直接用数据模型的形式表述一下。<br>是不是很简单？</p><p>相信许多人都会觉得很简单，它的确也挺简单。<br>甚至，当时在项目上第一版代码实现出来的时候，即使code review没有通过，我也没有觉得它是个问题，即使实现方是客户方的Dev。直到正式team code review，在与客户方Dev的沟通中，我才发现，对一些Dev来说，它的确是一个问题。</p><p>那，看一下你实现的数据模型是下面哪一种：<br><img src="/2019/07/19/xie-ye-wu-dai-ma-zhen-de-you-na-me-wu-liao-ma/answers.png" alt="现有表结构"></p><p>很不幸，当时的第一版代码实现是 <strong>1</strong>。犯了将 Account 的属性泄露到User中的大原则问题。<br><strong>(排除)</strong></p><p>再看下 <strong>2</strong>，<strong>“默认账户”</strong>，这是个什么鬼？也许有人会说，这只是字段起名的问题。或者也有人会说，就是”默认要显示的账户“啊。相比于<strong>1</strong>，User 和 Account 之间的关联使用了id，比 <strong>1</strong> 要好很多。但是，User 需要关心是哪个 Account 要显示吗？这种双向关联的设计是必要的吗？好，我们先把 <strong>2</strong> 放一下。</p><p>那看下 <strong>3</strong>，每个 account 都有一个 bool 标记，用以标记自己是不是当前 User 下的默认账号。好处是，User 完全不用关心旗下的 Account 被选择的问题。但，先不提 <strong>默认账户</strong> 关键字的问题，可以想象一下，当每次 User 切换了当前的 Account，系统就需要整体检查一遍当前 User 下所有的 Account 的 <code>is_default</code>值，并且进行修改。虽然在并发竞争低的场景下，貌似也勉强勉强接受，再想一下是不是有更好的办法？</p><p>最后看下 <strong>4</strong>，在 <strong>3</strong> 的基础上再想一下，到底是什么决定了当前 User 所属的所有 Account 中那唯一一条true标记？这个时候 —— <strong>请把，需求拿出来再仔细看一遍。</strong><br><strong>这很重要。</strong></p><blockquote><p>”进入APP首页的时候，首页展示的<strong>当前Account</strong>默认为 <strong>最近一次使用</strong> 的 Account。“</p></blockquote><p><strong>如果觉得不确定，甚至可以拉上 team 上的 BA 再认真聊一下</strong>。<br>DEV：最近一次使用，意思是账号的最近一次使用的时间点很重要？<br>BA：我不确认”最近一次使用的时间点“是不是很重要。首页这个场景下，我只关心显示的是最后一次使用的账号。但对于首页上手动点击切换 Account 的弹出层上，Account List 我觉得倒是可以采用根据各自的 <strong>最近一次使用的时间点</strong> 来排序展示。</p><p>到这里，可以再拿出之前还没完全排除掉的<strong>2、3、4</strong>，事情就很好解决了。<br><strong>2</strong> 和 <strong>3</strong> 莫名其妙地突出了一个<strong>默认账号</strong>的问题，并且让事情变得复杂 —— <strong>2</strong> 多了双向关联，<strong>3</strong> 多了批量更新，同时都遗漏对了每个“<strong>最近一次使用的时间点</strong>”的记录。<br>而 <strong>4</strong> 在抓到“<strong>最近一次使用的时间点</strong>”这个关键信息，并且得到业务认可的同时，解决了首页展示的业务case，并且能很好的支持扩展。</p><h4 id="3-知识消化、理解业务意图、分析建模、或者是whatever">3. 知识消化、理解业务意图、分析建模、或者是whatever</h4><p>上面的例子有点长，本人也比较担心自己的表述不太好，让举证方向发展到比较奇怪的地方。或者，有时候不同的人的经历总是可以看出不一样的味道。</p><p>当然，这篇博客的目的也并不是为了直奔DDD主题。<br>只是想要强调一点：写业务代码其实也没那么简单和单调。Dev在开发之前，或者是开发的过程中，都要确保自己对业务知识进行了消化，掌握了业务意图，然后进行建模、实现开发。<br>即便是在不需要运用DDD的简单业务系统中。</p><p>最后引用《领域驱动设计与模式、原理与实践》中的一句话：</p><blockquote><p>代码输入并非交付产品的瓶颈；编码是开发过程中最简单的一部分。在非功能性需求之外创建并维持一个能够满足业务用例的领域的有用软件模型才是难点所在。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> DDD </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DDD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编程价值观、原则、模式</title>
      <link href="/2018/12/10/bian-cheng-jie-zhi-guan-yuan-ze-mo-shi/"/>
      <url>/2018/12/10/bian-cheng-jie-zhi-guan-yuan-ze-mo-shi/</url>
      
        <content type="html"><![CDATA[<p>读自《实现模式》</p><hr><p><strong>模式</strong>，即是针对特定问题的通用解决方案。<br>每个模式都承载这一点点理论，但实际编程中存在着一些更加深远的影响力，远不是孤立的模式所能概括的。</p><p><strong>价值观</strong>是编程过程的统一支配性主题，影响在编程中所作的每一个决策。<br>价值观有普遍的意义，但往往难以直接应用；模式虽然可以直接应用，却针对的是特定情境；<strong>原则</strong>在价值观和模式之间搭建了桥梁。</p><p>价值观 -&gt; 原则 -&gt; 模式<br>模式描述了要做什么，价值观提供了动机，原则则把动机转化成了实际行动。</p><p>在为用哪种方式做事而争论的同时，如果在价值观、原则上存在根本层次分歧，那么首先要从价值观、原则上达成共识，不然就是在浪费时间。</p><h3 id="价值观">价值观</h3><h5 id="1-可读性（沟通）">1. 可读性（沟通）</h5><p>编写出计算机能运行的代码很简单，编写出让人能很好理解的代码没那么容易。</p><p>在编程时，我们很容易从计算机的角度进行思考。但只有一面编程一面思考其他人的感受，才能写出更好的代码。</p><p>从经济学来说，软件的绝大部分成本都是在第一次部署以后才产生的。从经验来看，花费在阅读既有代码上的时间要比编写全新的代码长得多。<br>因此，为了减少阅读代码所带来的开销，就应该让它容易读懂。</p><h5 id="2-简单">2. 简单</h5><p>代码中的复杂有两种：有些复杂性是内在的，他们准确反映了所要解决的问题的复杂性；另一些复杂性的产生则是因为我们忙着让程序运行起来，未认真考虑，从而造出了多余的复杂。</p><p>多余的复杂性降低了软件的价值：一是让软件正确运行的可能性降低，再是将来也很难进行正确的改动。</p><p>追求简单推动了软件的进化。<br>编程过程中如果发现某种简化会使程序难以理解，这时优先考虑可读性。</p><h5 id="3-灵活">3. 灵活</h5><p>同样，因为程序的绝大部分开销都是在第一次部署以后才产生的，所以程序必须容易改动。</p><p>灵活是衡量那些低效编码与设计实践的一把标尺。<br>但同时想象中明天或许会用得上的灵活性，可能与真正修改代码所需要的灵活性不是一回事。<br>这时候，<strong>保持简单性和大规模测试</strong>所带来的灵活性比<strong>专门设计出来的灵活性</strong>更为有效。</p><p>灵活性的提高可能以复杂性的提高为代价，因此在设计的度上需要有个权衡。</p><h3 id="原则">原则</h3><p>原则是另一个的通用思想，比价值观更贴近与编程实际，同时又是模式的基础。<br>原则可以解释模式背后的动机。</p><h5 id="1-局部化影响">1. 局部化影响</h5><p>减少变化所引起的代价，因此在组织代码结构时，要保证变化只会产生局部化影响，避免连锁反应或者被扩散。</p><h5 id="2-最小化重复">2. 最小化重复</h5><p>这里的重复，仅先限制在真正意义上的副本性重复 —— 编码中从对应的领域到实现。<br>重复的来源之一，是复制。复制的越多，变化的代价、需要改动的代价就越大。<br>最小化重复也有助于局部化影响。</p><h5 id="3-将逻辑与数据绑定">3. 将逻辑与数据绑定</h5><p>可以理解为，将数据于行为绑定。比如类的封装。</p><h5 id="4-对称性">4. 对称性</h5><p>识别出代码的对称性，把它清晰地表达出来，代码将更容易阅读。<br>一旦阅读者理解了对称性涵盖地某一半，就能很快理解另一半。</p><h5 id="5-声明式表达">5. 声明式表达</h5><p>如，能写成一个语义清晰、功能相同的annotation，就绝不将其放在一个通用的工具类或方法中。</p><h5 id="6-变化率">6. 变化率</h5><p>变化率具有时间上的对称性。<br>把相同变化率的逻辑、数据放在一起，把不同变化率的逻辑和数据分离。</p>]]></content>
      
      
      <categories>
          
          <category> 代码架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 代码架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>雷达哔哔哔 - Ethereum</title>
      <link href="/2018/12/09/lei-da-bi-bi-bi-ethereum/"/>
      <url>/2018/12/09/lei-da-bi-bi-bi-ethereum/</url>
      
        <content type="html"><![CDATA[<h2 id="位置">位置</h2><p>2017年3月第16期技术雷达，<strong>平台</strong>象限，建议<strong>评估</strong></p><h2 id="目标受众：">目标受众：</h2><p>区块链产品经理、架构师、开发人员</p><h2 id="关注问题：">关注问题：</h2><p>在比特币货币网络启动后的几年，加密货币和区块链技术逐渐进入公众视野。虽然比特币主要目的是为金融交易提供信任支撑，但作为仅有一种单一的状态主体（比特币）、无法图灵完备进行编程的区块链网络，其对于区块链技术的运用场景非常受限。<br>而为了在区块链技术上，或者说是为了在比特币引领的密码学货币的基础上（以太坊白皮书中提到）构建高级应用，以太坊做出了打造开源平台的尝试。</p><h2 id="解决方案：">解决方案：</h2><p>以太坊在借鉴了比特币，同样使用了底层密码学货币、区块链、去中心化的共识机制和矿工机制基础上，提供了以Solidity为首选的四种专用编程语言和虚拟机EVM，支持图灵完备的智能合约，用以支持在此平台上构建更为复杂和灵活的区块链应用。</p><h2 id="解读：">解读：</h2><p>一个一直以来的说法——如果把比特币网络看成是全球账本的话，那么就可以把以太坊看做是一台“全球计算机”。</p><p>智能合约，作为运行在这台全球计算机上的主体，是以太坊最重要的概念之一，即以计算机程序的方式来缔结和运行各种合约 —— 满足合约条件即会强制执行，执行结果会对以太坊网络上记录的状态进行更新。这些修改由于经过了以太坊网络中的共识，一旦确认后无法被伪造和篡改。</p><p>在以太坊这个平台上，对于智能合约的编写和发布，基于以下几个条件：</p><ul><li>运行环境：EVM虚拟机</li><li>开发语言：Solidity（类JavaScript）、solc编译器</li><li>燃料：Gas，通过以太币换取</li><li>账户：以太币拥有者的账户，由私钥控制<br><img src="/2018/12/09/lei-da-bi-bi-bi-ethereum/contract.png" alt="State"><br>上图中：</li></ul><ol><li>开发者使用Solidity语言编写智能合约文件，由Solc编译工具将合约文件编译成字节码。</li><li>使用可以与以太坊节点通讯的JSON RPC工具(如JavaScript版本的Web3.js)，向以太坊节点发送一条“创建合约”的交易。</li><li>以太坊节点接收到此交易后，先检查该开发者账户上是否有足够的以太币余额用以支付交易中声明的Gas。如果足够，节点开始创建合约，并消耗Gas。</li></ol><p>以太坊中，Gas是个有意思的设定。以太币会被定义为燃料货币基本来源于此。<br>一方面，它让交易发送方承担运行交易的成本；另一方面，可以用来预防过重、过长的合约执行，以及保护以太网络受到无限循环的蓄意攻击。</p><p>在发送的交易中，会有两个固定部分：gasLimit和gasPrice。</p><ul><li>gasLimit: 发送方愿意支付的执行这一交易的Gas最大数量。这个数额是预先设定和支付的。</li><li>gasPrice：发送方愿意支付每单位Gas所需执行交易的GWei数量。</li><li>gasLimit x gasPrice，就是发送方愿意为此次交易支付的以太币成本。</li></ul><p>在每一次交易中，gasLimit用来控制交易执行指令的上限。如果实际消耗的gas小于gasLimit，剩余的gas会被退回给发送方；如果一个交易过于复杂到还未执行结束，而gas已经消耗完时，交易执行终止并且状态回滚。<br>gasPrice，主要用来提升交易的“打包费”，price越高越容易被矿工提前打包进区块。</p><p>因此，智能合约的编写，应该秉承尽量简单的原则，不然成本就会相当昂贵。</p><h2 id="相关Blip">相关Blip</h2><ul><li><a href="https://www.thoughtworks.com/radar/languages-and-frameworks/solidity">Solidity | Languages and Frameworks | Technology Radar | ThoughtWorks</a></li><li><a href="https://www.thoughtworks.com/radar/languages-and-frameworks/truffle">Truffle | Languages and Frameworks | Technology Radar | ThoughtWorks</a></li><li><a href="https://www.thoughtworks.com/radar/languages-and-frameworks/openzeppelin">Openzeppelin | Languages and Frameworks | Technology Radar | ThoughtWorks</a></li><li><a href="https://www.thoughtworks.com/radar/platforms/ethereum">Ethereum | Platforms | Technology Radar | ThoughtWorks</a></li><li><a href="https://www.thoughtworks.com/radar/platforms/quorum">Quorum | Platforms | Technology Radar | ThoughtWorks</a></li></ul><h2 id="延展阅读">延展阅读</h2><ul><li><a href="https://github.com/ethereum/wiki/wiki/White-Paper">以太坊白皮书</a></li><li><a href="https://ethereum.github.io/yellowpaper/paper.pdf">以太坊黄皮书</a></li><li><a href="https://medium.com/@preethikasireddy/how-does-ethereum-work-anyway-22d1df506369">How does Ethereum work, anyway?</a></li><li><a href="https://blog.qtum.org/diving-into-the-ethereum-vm-6e8d5d2f3c30">Diving Into The Ethereum Virtual Machine</a></li></ul><h2 id="工具：">工具：</h2><ul><li><a href="https://solidity.readthedocs.io/en/v0.4.24/">Solidity</a></li><li><a href="https://github.com/ethereum/wiki/wiki/Ethereum-Virtual-Machine-(EVM)-Awesome-List">EVM</a></li><li><a href="https://github.com/trufflesuite/truffle">Truffle</a></li><li><a href="https://truffleframework.com/ganache">Ganache</a></li><li><a href="https://metamask.io/">MetaMask</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Ethereum </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
            <tag> Blockchain </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>build.gradle中的外部变量</title>
      <link href="/2018/12/05/build.gradle-zhong-de-wai-bu-bian-liang/"/>
      <url>/2018/12/05/build.gradle-zhong-de-wai-bu-bian-liang/</url>
      
        <content type="html"><![CDATA[<p>使用gradle命令的时候，经常被Option -P\-D搞得混淆。其实很容易区分一下。</p><h3 id="Project-property">Project property</h3><p>在build.gradle文件中，能直接通过变量名访问 或者 project前缀访问的是project property。</p><h5 id="设置">设置</h5><p>project property可以通过5种方式自定义设置(优先级从低到高)：</p><ol><li>gradle.properties文件<br>(user gradle home下的gradle.properties文件优先级高于工程目录下的gradle.properties文件)</li></ol><pre class="line-numbers language-none"><code class="language-none">branchName=t1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>环境变量</li></ol><pre class="line-numbers language-none"><code class="language-none">ORG_GRADLE_PROJECT_branchName=t2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>命令行-D</li></ol><pre class="line-numbers language-none"><code class="language-none">./gradlew clean build -Dorg.gradle.project.branchName=t3<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>命令行-P</li></ol><pre class="line-numbers language-none"><code class="language-none">./gradlew clean build -PbranchName=t4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="5"><li>build.gradle自身文件内, 定义时使用前缀ext。</li></ol><pre class="line-numbers language-none"><code class="language-none">ext {  branchName=t5}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="访问">访问</h5><p>读取project property时需要注意，如果值不存在，构建将直接失败。因此，如果有值不存在的情况需要判断时，使用方法<code>Project.hasProperty(java.lang.String) </code>。</p><h3 id="System-property">System property</h3><p>看了上面第3项中，有个<strong>命令行-D</strong>。<br>其可以传递一个system property给gradle运行的JVM中，跟Java -D的功用相同。</p><h5 id="设置-2">设置</h5><p>system property可以使用两种方式自定义：</p><ol><li>gradle.properties文件。使用前缀systemProp：</li></ol><pre class="line-numbers language-none"><code class="language-none">systemProp.branchName=y1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>需要注意，在multi project build中，只有root directory下的gradle.properties文件中配置的systemProp才会生效。其他子模块中的会被忽略。</p><ol start="2"><li>命令行-D</li></ol><pre class="line-numbers language-none"><code class="language-none">./gradlew clean build -DbranchName=y2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="访问-2">访问</h5><p>需要在build.gradle文件中使用时，需要调用：</p><pre class="line-numbers language-none"><code class="language-none">System.properties['system']<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Gradle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring cloud Netflix中的超时配置</title>
      <link href="/2018/12/04/spring-cloud-netflix-zhong-de-chao-shi-pei-zhi/"/>
      <url>/2018/12/04/spring-cloud-netflix-zhong-de-chao-shi-pei-zhi/</url>
      
        <content type="html"><![CDATA[<p>一般SpringCloud中超时配置，含Hystrix/Ribbon两部分：</p><pre class="line-numbers language-none"><code class="language-none">ribbon:  ReadTimeout: 120000  ConnectTimeout: 120000  hystrix:  command:    default:      execution:        isolation:          strategy: THREAD          thread:            timeoutInMilliseconds: 120000<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>hystrix thread timeout需要比ribbon timeout设置时间长。<br>ribbon有retry机制，如果timeout设置时间短，则无法retry。</p><p>在zuul中，如果使用的是服务发现，ribbon timeout同上。<br>如果使用的指定URL形式，ribbon timeout需要如下配置：</p><pre class="line-numbers language-none"><code class="language-none">zuul:  host:    connect-timeout-millis: 120000    socket-timeout-millis: 120000<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://cloud.spring.io/spring-cloud-netflix/multi/multi__router_and_filter_zuul.html#_zuul_timeouts">Zuul官方说明</a></p><blockquote><p>8.13 Zuul Timeouts<br>If you want to configure the socket timeouts and read timeouts for requests proxied through Zuul, you have two options, based on your configuration:<br>If Zuul uses service discovery, you need to configure these timeouts with the ribbon.ReadTimeout and ribbon.SocketTimeout Ribbon properties.<br>If you have configured Zuul routes by specifying URLs, you need to use <strong>zuul.host.connect-timeout-millis</strong> and <strong>zuul.host.socket-timeout-millis</strong>.</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Spring Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spring Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>尽量不要在 Spring Config Server 中使用太长的数组</title>
      <link href="/2018/10/07/jin-liang-bu-yao-zai-spring-config-server-zhong-shi-yong-tai-chang-de-shu-zu/"/>
      <url>/2018/10/07/jin-liang-bu-yao-zai-spring-config-server-zhong-shi-yong-tai-chang-de-shu-zu/</url>
      
        <content type="html"><![CDATA[<p>上周second vendor在使用我们搭建好的config server向API-Gateway中追加配置项的时候，发生了一个小插曲。</p><p>本来本意是想<strong>追加</strong>一条 <em>忽略去校验Token</em> 的API Pattern, 但是失误操作成<strong>覆盖</strong>整个 <em>忽略去校验Token</em> 的API Pattern Array.</p><hr><p>来看一下我们的yaml配置文件application-default.yml中的结构：</p><pre class="line-numbers language-none"><code class="language-none">ignoredValidateTokenUrl:  - /api/user/password-reset  - /tablet/js/**  - /integration/**  …………<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>整个Array由于日积月累，length已经长达四五十。<br>之前追加新的条目，大家相互心照不宣地都是在default yaml中编写，于是在QA、UAT等环境中，也就并没有在config server里再另行定制维护。</p><p>这次second vendor的想法很简单，只是想在这四五十条的后面再追加一条新的API。于是他在UAT环境的application-uat.yml中这样做的：</p><pre class="line-numbers language-none"><code class="language-none">ignoredValidateTokenUrl:  - /api/d2d<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后，那天我们UAT环境一下午都无法登录。。</p><p>这其中，起因固然是second vendor的小伙伴对<strong>Spring config server</strong>或者说是对<strong>Spring Profile-specific properties</strong>的不熟悉造成的。<br>但换个角度来看，由于<em>Spring config server</em>、<em>Spring Profile-specific properties</em>对配置进行覆盖的主原则就是根据key，如果value是一个数组，也就是数组内所有元素都共用一个key。<br>因此，这时候的覆盖就是整个数组进行覆盖，其内部是不能再次进行细化操作的。</p><p>而如果数组元素配置在各环境重复度相当高，且又在config server中不同环境都维护一套的话，容易造成：</p><ol><li>维护成本增加。<br>每次修改的时候，不仅检查当前环境yaml文件，还要与default文件进行比对，以免遗漏。</li><li>容易失误出错，无法溯源。<br>需要经常与default进行对比，一旦遗漏，就会出错。又若是遗漏后长时间未发现，发现时已很难分辨到底是失误还是特殊定制。</li></ol><p>因此当使用Array作为property-value时，应该依如下顺序进行一下考虑：</p><ol><li>length大概只有2~5个的，可以考虑直接用key-Array，或者key-strings都行。如Zuul sensitiveHeaders，长度最多只有3。</li><li>如果Array中的每一个元素项可以找到有具体涵义的名称作为key的话，就将key-Array的实现解构成多个key-value，如Zuul的routes。</li><li>如果是数组长度又长，基本不需要profile-special的，可以考虑不配置在<em>Spring config server</em>、<em>Spring Profile-specific properties</em>中。可以考虑将其持久在其他文件介质中、数据库中等等。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Spring Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spring Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java分布式复习题</title>
      <link href="/2018/09/14/java-fu-xi-ti/"/>
      <url>/2018/09/14/java-fu-xi-ti/</url>
      
        <content type="html"><![CDATA[<h4 id="RMI">RMI</h4><h4 id="RPC">RPC</h4><h4 id="CAP-定理">CAP 定理</h4><p>CAP 定理对分布式数据存储<code>系统</code>的特性进行高度抽象，提炼成了3个维度：</p><ul><li><code>Consistency</code> 一致性, 每一次读取操作，要么系统返回最新的数据写入值（无论读取到哪一个数据节点），要么返回系统错误。</li><li><code>Availability</code> 可用性, 每一次读取操作都能获得系统的返回，但不保证返回的是最新的数据写入值。</li><li><code>Partition Tolerance</code> 分区容错性，当数据节点之间发生网络分区（包括网络丢包、连接中断阻塞等），系统仍然要继续工作。<br>这其中的底层逻辑是：分布式数据存储各节点之间通过网络连接，在运行期间不可避免存在网络分区的风险。<br>保证分区容错性，就是当发生网络分区异常时，整个系统仍然运行并继续工作，这时候提供的服务维度只可能在 Consistency 和 Availability 中保证一项。</li><li>确保一致性，牺牲可用性。<br>系统会通过内部策略，自动修复集群，最终确保 Consistency 声明的强一致性。在自动修复完成之前，外部请求会返回系统出错或者超时。</li><li>确保可用性，牺牲一致性。<br>系统在自动修复集群期间，没有达成数据一致性的各节点仍会对外及时响应，确保 Availability 声明的高可用性。</li></ul><p>狭义上来讲，CAP 定理中 Consistency 是忽略数据复制的网络延迟的，即：假设数据复制是瞬间完成，并且系统马上对外提供数据读取。<br>广义上，达成 Consistency 的网络延迟是可以接受的，不算网络分区，即使延迟了几分钟。<br>如果想要将<code>网络延迟</code>的影响加入到数据分布式的架构讨论中，可以参照 CAP 定理的延伸 <code>PACELC 理论</code>：<br>PAC 各字母同 CAP 理论， E (Else) 仅是连接词，L (latency) 、C (consistency)。意思就是，当没有出现网络分区、系统正常运行时，低延时（低于数据达成一致所需的平均延时水平） 和 数据一致性，二者需要选择其一，不能同时保证。<br>比如，MongoDB 集群的就是典型的 PA/EC 系统：在出现网络分区时，MongoDB 集群优先保证可用性，数据可能不是最新；在集群正常状态下，优先保证数据一致性。</p><h4 id="BASE-原则">BASE 原则</h4><p>CAP 定理在应用系统开发中的一种解决方案。<br><code>Basically Available</code> 基本可用<br><code>Soft state</code> 软状态<br><code>Eventually consistent</code> 最终一致性<br>当应用无法做到强一致性时，每个应用可以根据自身的业务特点，采用适当的方式来使得系统达到最终一致性。</p><h4 id="RAFT-共识算法">RAFT 共识算法</h4><h4 id="SOA">SOA</h4><h4 id="分布式系统">分布式系统</h4><p>《分布式系统原理与范型》里总结：</p><blockquote><p>分布式系统是若干独立计算机的集合，这些计算机对于用户来说就像是单个相关系统。<br>从物理结构上来看，多台计算机资源通过计算机网络技术相连接，达成构建同一个系统的目的，这个计算机网络就叫做<code>分布式系统</code>。<br>相对的, 使用单一的计算机来构建系统的，这个单处理器系统就叫做<code>集中式系统</code>。</p></blockquote><p>从系统架构的历史进程来看，从最早的<code>纵向分层式架构</code>，通过使用数据库服务、中间件服务等，将系统构建中一些通用的职责被代理到独立的计算资源上 —— 就已经是分布式系统了。<br>再到<code>横向高可用架构</code>的复制集、数据分片、集群架构等，又到现在的根据业务类型和职责划分的面向服务化、微服务架构等，都是分布式系统的范畴。<br>只不过对于当前 Java 应用开发来，提到<code>分布式架构</code>，主要讨论的点多是涉及面向服务化、微服务架构这方面，其次是纵向分层式架构。</p><p><strong>Java应用 分布式系统带来的优缺点</strong><br><strong>优点</strong></p><ol><li>通过服务拆分实现了单一职责原则，带来了更好的封装性、扩展性、边界隔离</li></ol><ul><li><p>业务上<br>单一业务高内聚于一个服务中，当有业务变更时，仅需要修改、检查业务对应的服务即可，不会带来辐射式代码修改的成本，或者需求冲突造成需求很难实现的问题；<br>当系统面临外部业务环境的适应性挑战时，服务具有的高扩展性，可以更好地支持系统外部引进的业务变化和创新；<br>同时，由于服务边界的存在，当前系统运行中不涉及变更的其他服务，依然保持线上运行，降低了缺陷风险和验证成本。</p></li><li><p>数据上<br>现在的应用服务，基于用户量和数据量的增长，很难仅使用一台数据库服务器就完成所有的数据存储与读写，相比于迁移到新型分布式数据库，<br>服务拆分将存储了不同领域字段的大表，根据业务域拆分成多个小表，从数据列的维度上解决了数据库的负载和压力问题。</p></li><li><p>管理上<br>服务拆分与组织/团队划分相匹配，可以减少系统需求的不确定性、知识消耗和沟通的成本、降低研发时长、实现快速发布等。</p></li></ul><ol start="2"><li>通过服务化 + 云原生平台，带来了运算容量的弹性</li></ol><ul><li>构建初期不需要预估和预制高容量资源，可以根据线上资源的占用情况，进行后置资源扩容。</li><li>针对不同服务间的资源利用率，更有针对性地对处于资源瓶颈的服务进行扩容，避免了整体资源扩容带来的浪费。</li></ul><ol start="3"><li><p>同时由于服务划分了核心域、支撑域、通用域，不同的服务可以根据业务情况，选取不同的上线时间，最终可以达成业务的快速推出、反馈和验证。</p></li><li><p>提高了应用的健壮性和高可用性<br>纵向架构上，通过使用专业的分布式缓存、文件托管、消息队列、数据库等各类型中间件产品服务，降低了开发人力成本的同时，提升了开发质量和应用的健壮性。<br>横向架构上，服务的拆分和独立发布，以及服务实例集的使用，保障了应用整体的可用性 —— 不会因为一个服务的问题，造成整个应用的不可用。</p></li></ol><p><strong>缺点</strong></p><ol><li>技术运营能力的挑战</li><li>服务间集成的挑战</li><li>服务状态和数据分片的问题<br>比如，分布式任务调度、消息消费等等。</li><li>诊断和可视化的问题<br>比如，动态调用链、traceID、日志等等。</li><li>性能问题</li><li>安全问题<br>等等</li></ol><p>总的来说，分布式系统带来了很多好处，同时也带来了不少的技术能力挑战和成本。</p><h4 id="分布式定时任务">分布式定时任务</h4><p>解决的数据分片问题<br>quartz<br>elastic-job<br>xxl-job</p><h4 id="session">session</h4><p>无状态<br>cookie id + session 下沉</p><h4 id="数据全局唯一ID">数据全局唯一ID</h4><p>雪花算法</p><h4 id="分布式锁">分布式锁</h4><h4 id="分布式事务">分布式事务</h4><h3 id="Spring-cloud">Spring cloud</h3>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring cloud Feign</title>
      <link href="/2018/07/25/spring-cloud-feign/"/>
      <url>/2018/07/25/spring-cloud-feign/</url>
      
        <content type="html"><![CDATA[<h4 id="1-dependency">1. dependency</h4><pre class="line-numbers language-none"><code class="language-none">dependencies {    compile("org.springframework.cloud:spring-cloud-starter-feign")    ……}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-annotation">2. annotation</h4><pre class="line-numbers language-none"><code class="language-none">@SpringBootApplication@EnableFeignClientspublic class Application {    public static void main(String[] args) {        SpringApplication.run(Application.class, args);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="3-feign-client">3. feign client</h4><pre class="line-numbers language-none"><code class="language-none">#不使用服务发现，直接配置url；#使用服务发现，不配置url，name为service_id，另外project注意加入服务发现依赖、打开服务发现配置@FeignClient(name = "invokeClient", url = "localhost:8001")public interface InvokeClient {@GetMapping("/user/{id}/username")    public String name(@PathVariable("id") String id);}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意，虽然支持spring MVC的annotation，但@PathVariable、@RequestParam、@RequestHeader等参数名的注解，一定要设置value值，这点与写controller不同。</p><h4 id="4-打开feign-log">4. 打开feign log</h4><p>feign clients默认的Logger.Level对象定义的是NONE级别，要想打开：<br>首先：</p><pre class="line-numbers language-none"><code class="language-none">@Configurationpublic class GlobalFeignConfiguration {    @Bean    Logger.Level feignLoggerLevel() {        return Logger.Level.FULL;    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后，开启具体feign client logger:</p><pre class="line-numbers language-none"><code class="language-none">#application.yamllogging:  level:    &lt;packageName&gt;.&lt;FeignInterfaceName&gt;: DEBUG<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>或者针对性对feignClient进行配置：</p><pre class="line-numbers language-none"><code class="language-none">@FeignClient(name = "invokeClient", configuration = GlobalFeignConfiguration.class, url = "localhost:8001")public interface InvokeClient {}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="附：">附：</h4><p>controller与feignClient的接口定制方式相同，实践中可以考虑由provider，也就是controller方提供统一接口，避免重复。</p>]]></content>
      
      
      <categories>
          
          <category> Spring Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spring Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring config server</title>
      <link href="/2018/06/13/spring-config-server/"/>
      <url>/2018/06/13/spring-config-server/</url>
      
        <content type="html"><![CDATA[<h3 id="Server端">Server端</h3><h4 id="1-添加依赖">1. 添加依赖</h4><pre class="line-numbers language-none"><code class="language-none">dependencies {    compile 'org.springframework.cloud:spring-cloud-config-server'    compile 'org.springframework.cloud:spring-cloud-starter-eureka'    compile 'org.springframework.boot:spring-boot-starter-actuator'}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-添加annotation">2. 添加annotation</h4><pre class="line-numbers language-none"><code class="language-none">@SpringBootApplication@EnableConfigServerpublic class ConfigServerApp {    public static void main(String[] args) {        SpringApplication.run(ConfigServerApp.class, args);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="3-application-yaml配置文件添加config-repo">3. application.yaml配置文件添加config repo</h4><pre class="line-numbers language-none"><code class="language-none">spring:  application:    name: config-server  cloud:    config:      server:        git:          uri: file://${user.home}/space/app-config          search-paths: '{application}/{profile}'server:  port: 7001<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面使用的本地文件系统方式进行配置仓库的内容管理，该方式仅用于开发和测试。在生产环境中务必搭建自己的Git配置库。</p><h4 id="4-将config-server注册进服务发现，application-yaml">4. 将config server注册进服务发现，application.yaml</h4><pre class="line-numbers language-none"><code class="language-none">eureka:  client:    serviceUrl:      defaultZone: http://localhost:11111/eureka    healthcheck:      enabled: true<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="5-同时可以考虑开启actuator-endpoints。">5. 同时可以考虑开启actuator endpoints。</h4><p>endpoints.enabled默认true。其中/health在后面Git配置库中有更多作用。</p><pre class="line-numbers language-none"><code class="language-none">management:  security:    enabled: false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="client端">client端</h3><h4 id="1-添加依赖-2">1. 添加依赖</h4><pre class="line-numbers language-none"><code class="language-none">dependencies {    compile 'org.springframework.cloud:spring-cloud-starter-eureka'    compile 'org.springframework.cloud:spring-cloud-starter-config'    compile 'org.springframework.boot:spring-boot-starter-actuator'}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-bootstrap-yml配置">2. bootstrap.yml配置</h4><pre class="line-numbers language-none"><code class="language-none">spring:  cloud:    config:#      uri: http://localhost:7001      discovery:        enabled: true        service-id: config-server      fail-fast: true  application:    name: hello-cloud  profiles:    active: ${SPRING_PROFILES_ACTIVE:local}eureka:  client:    serviceUrl:      defaultZone: http://localhost:11111/eureka    healthcheck:      enabled: trueserver:  port: 8001<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面spring.application.name即会用在search-paths的{application}，spring.profiles.active即是search-paths的{profile}。<br>同时从服务发现中查找config-server。如果不使用服务发现，可使用spring.cloud.config.uri指定静态的url。<br>spring.cloud.config.fail-fast用于快速验证config server的连接可用状态，防止container前期load时长过长，到后面config server才发现不能用而启动失败。</p><h4 id="3-添加服务发现的annotation">3. 添加服务发现的annotation</h4><pre class="line-numbers language-none"><code class="language-none">@EnableDiscoveryClient@SpringBootApplicationpublic class Application {    public static void main(String[] args) {        new SpringApplicationBuilder(Application.class).web(true).run(args);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="4-开启actuator-endpoints。其中-refresh可以对配置进行动态刷新。">4. 开启actuator endpoints。其中/refresh可以对配置进行动态刷新。</h4><pre class="line-numbers language-none"><code class="language-none">management:  context-path: /actuator  security:    enabled: false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="5-写一个支持刷新Example。">5. 写一个支持刷新Example。</h4><pre class="line-numbers language-none"><code class="language-none">@RefreshScope@RestControllerpublic class HelloController {    private final Logger logger = Logger.getLogger(getClass().getName());    @Value("${from}")    private String from;    @GetMapping("/from")    public String from(){        return this.from;    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="刷新操作">刷新操作</h3><ol><li>修改配置库内from value。</li><li>curl -X POST <a href="http://localhost:8001/actuator/refresh%E3%80%82">http://localhost:8001/actuator/refresh。</a></li><li>再次访问<a href="http://localhost:8001/from">http://localhost:8001/from</a></li></ol><h3 id="在config-server添加多个配置库">在config server添加多个配置库</h3><ol><li>application.yaml</li></ol><pre class="line-numbers language-none"><code class="language-none">spring:  application:    name: config-server  cloud:    config:      server:        git:          uri: git@github.com:XXX/app-config.git          search-paths: '{application}/{profile}'          passphrase: ********          force-pull: true          repos:            none_prod:              pattern:                - '*/dev'              uri: git@github.com:XXX/app-config.git              searchPaths: '{application}/{profile}'            prod:              pattern:                - '*/prod'              uri: git@github.com:XXX/prod-app-config.git              searchPaths: '{application}'        health:          repositories:            none_prod:              name: none_prod              profiles: devserver:  port: 7001eureka:  client:    serviceUrl:      defaultZone: http://localhost:11111/eureka    healthcheck:      enabled: true<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>spring.cloud.config.server.git.uri为默认配置库。<br>spring.cloud.config.server.health.repositories用来配置/health endpoint中健康检查的repos。</p><ol start="2"><li>这里采用使用本地ssh setting的方式。</li></ol><ul><li>首先，本地${user.home}/.ssh下有ssh key。</li><li>再次，ssh key加入ssh-agent。主要要确定config和know_host文件中记录。</li></ul><pre class="line-numbers language-none"><code class="language-none">$ eval "$(ssh-agent -s)"# 添加config文件# Host gitlab.com# HostName gitlab.com# AddKeysToAgent yes# UseKeychain yes# User TTT# IdentityFile ~/.ssh/id_tw_rsa$ ssh-add -K ~/.ssh/id_tw_rsa# 查看agent public keys$ ssh-add -l<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>最后，如果key中有设置passphrase，在application.yaml一定要配置spring.cloud.config.server.git.passphrase。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Spring Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spring Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spring boot actuator 基本配置</title>
      <link href="/2018/06/08/spring-boot-actuator-ji-ben-pei-zhi/"/>
      <url>/2018/06/08/spring-boot-actuator-ji-ben-pei-zhi/</url>
      
        <content type="html"><![CDATA[<p><a href="https://docs.spring.io/spring-boot/docs/1.5.13.RELEASE/reference/htmlsingle/#production-ready">1.5.3版本官方doc</a></p><p>spring-boot-actuator包自动提供了默认的management endpoint，用以监控容器内部的各种状态和指标。</p><h3 id="import">import</h3><pre class="line-numbers language-none"><code class="language-none">dependencies {compile("org.springframework.boot:spring-boot-starter-actuator")}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="打开endpoints">打开endpoints</h3><p>endpoints默认状态就是打开的。如果想全部关掉，然后分别打开：</p><pre class="line-numbers language-none"><code class="language-none">management:  context-path: /actuator  security:    enabled: falseendpoints:  enabled: false  health:    enabled: true    time-to-live: 10000  info:    enabled: true<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="关于security">关于security</h3><p>如果系统没有@EnableWebSecurity自行定制security的话，可以使用<code>management.security.enabled</code>来控制management endpoint中sensitive的访问权限，以及not sensitive的显示内容范围。如下：</p><pre class="line-numbers language-none"><code class="language-none">management:  context-path: /actuator  security:    enabled: truesecurity:  basic:    enabled: true  user:    name: admin    password: secret<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当@EnableWebSecurity后，所有访问权限都由WebSecurityConfigurerAdapter的子类full controll。</p><p>spring boot 1.4可以通过<code>management.security.enabled=false</code>来关闭对management endpoints的security check，是由于spring boot实现的一个bug。<br>spring boot 1.5中已经修复。<br>而在spring boot 2.0中已经将<code>management.security.enabled</code>去掉。<br>因此，在custom WebSecurityConfigurerAdapter中，还是使用正确的姿势对management endpoints进行特别设置：</p><pre class="line-numbers language-none"><code class="language-none">....antMatchers("/info", "/health", "/metrics").permitAll()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="关于management-port">关于management.port</h3><p><code>management.port=9999</code>虽然可以将management endpoint开放在独立的端口上，但<code>/health</code>check并不能自动检测主端口是否可用。<br>因此，如果使用<code>management.port</code>时，可能需要自行定制一个HealthIndicator来ping主服务端口。</p>]]></content>
      
      
      <categories>
          
          <category> Spring Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spring Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ethereum 开发工具</title>
      <link href="/2018/06/05/ethereum-kai-fa-gong-ju/"/>
      <url>/2018/06/05/ethereum-kai-fa-gong-ju/</url>
      
        <content type="html"><![CDATA[<h2 id="Using-Remix">Using Remix</h2><p>有个叫<a href="http://remix.ethereum.org/">Remix</a>的在线IDE，快速地验证智能合约，或者一些基本调试，还是特别方便的。</p><h2 id="Using-truffle">Using truffle</h2><h4 id="安装ganache">安装ganache</h4><p>可以选择安装有图形界面的<a href="https://github.com/trufflesuite/ganache">ganache</a>，或者无图形界面的命令行<a href="https://github.com/trufflesuite/ganache-cli">ganache-cli</a>。</p><p>按个人喜好选择。<br>本人两种都安装了，但使用时更喜好命令行版。</p><pre class="line-numbers language-none"><code class="language-none">$ npm install -g ganache-cli$ ganache-cli //即可运行<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="安装truffle">安装truffle</h4><pre class="line-numbers language-none"><code class="language-none">$ npm install -g truffle<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="build-project">build project</h4><pre class="line-numbers language-none"><code class="language-none">$ mkdir hello-solidity-truffle$ cd hello-solidity-truffle$ truffle init<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="truffle常用命令">truffle常用命令</h4><pre class="line-numbers language-none"><code class="language-none">truffle migratetruffle testtruffle console<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="安装MetaMask">安装MetaMask</h3><p>MetaMask是一个以Chrome浏览器插件形式实现的轻钱包。<br>进入Chrome Web Store查找安装后即可。</p><p>然后要记得创建的口令和密码。</p>]]></content>
      
      
      <categories>
          
          <category> Ethereum </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
            <tag> Blockchain </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring Cloud Eureka 服务治理</title>
      <link href="/2018/05/15/spring-cloud-eureka-fu-wu-zhi-li/"/>
      <url>/2018/05/15/spring-cloud-eureka-fu-wu-zhi-li/</url>
      
        <content type="html"><![CDATA[<h3 id="服务注册中心">服务注册中心</h3><p>在服务治理框架中，通常有一个 <code>服务注册中心</code>，提供：</p><ol><li>服务注册。<br>每个服务单元向其登记自己提供的服务，将主机、端口号、版本号等告知注册中心，注册中心按 <code>服务名</code> 来组织清单。</li><li>服务发现。<br>服务调用方需要调用某个服务名的实例提供的服务，则向服务注册中心获取所有服务实例的清单，以实现对具体服务实例的访问。</li></ol><pre class="line-numbers language-none"><code class="language-none"># first build.gradledependencies {    compile 'org.springframework.cloud:spring-cloud-starter-eureka-server'    compile 'org.springframework.boot:spring-boot-starter-web'    ……}# second application.yamlserver:  port: 11111eureka:  instance:    hostname: localhost  lease-renewal-interval-in-seconds: 30  lease-expiration-duration-in-seconds: 90  server:    enable-self-preservation: false  client:    fetch-registry: false    register-with-eureka: false    serviceUrl:      defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/# third Application.java@EnableEureKaServer<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Netflix Eureka由于使用Restful API协议，因此支持跨语言跨平台的微服务应用进行注册。</p><h3 id="服务提供者">服务提供者</h3><p>Eureka客户端：</p><ol><li>向注册中心登记自身提供的服务，并且周期性地发送心跳来更新它的服务租约。</li><li>从注册中心查询服务清单，把它们缓存到本地，并周期性地刷新服务状态。</li></ol><h3 id="服务续约-renew">服务续约(renew)</h3><p>在服务注册完成之后，服务提供者维护一个心跳用来持续告知服务中心，以防止被服务列表中剔除。<br>使用spring boot actuator提供的/health来维护心跳、提供健康检查。</p><pre class="line-numbers language-none"><code class="language-none">#first build.gradledependencies {    compile 'org.springframework.cloud:spring-cloud-starter-eureka'    compile 'org.springframework.boot:spring-boot-starter-actuator'    ……}#second application.yamleureka:  client:        serviceUrl:defaultZone: http://localhost:11111/eureka#third Application.java@EnableDiscoveryClient<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="服务下线">服务下线</h3><p>服务提供者正常关闭时，会触发一个服务下线的Restful请求给注册中心。注册中心在收到请求后，会将该服务编辑为下线，并广播此事件。</p><h3 id="服务剔除">服务剔除</h3><p>注册中心会定时每个一段时间 <em>lease-renewal-interval-in-seconds</em> ，将服务清单中超过时间 <em>lease-expiration-duration-in-seconds</em> 秒没有续约的服务剔除出去。</p><h3 id="自我保护">自我保护</h3><p>基于上面服务剔除的，注册中心在运行期间，会统计心跳失败的比例在15分钟内是否低于85%，如果是，注册中心会将当前注册信息保护起来，让其不会过期。<br>由于本地很容易触发保护机制，因此本地开发时关闭自我保护。</p><pre class="line-numbers language-none"><code class="language-none"># application.yamlserver:    enable-self-preservation: false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Spring Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spring Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Solidity Zombies 学习笔记</title>
      <link href="/2018/05/03/solidity-zombies-xue-xi-bi-ji/"/>
      <url>/2018/05/03/solidity-zombies-xue-xi-bi-ji/</url>
      
        <content type="html"><![CDATA[<p>以太坊的一个<a href="https://cryptozombies.io/">加密僵尸游戏</a>。<br>为了便于记忆，将其中的教程产出code贴了出来。</p><p>ZombieFactory.sol</p><pre class="line-numbers language-none"><code class="language-none">pragma solidity ^0.4.19;import "./ownable.sol";contract ZombieFactory is Ownable {    event NewZombie(uint zombieId, string name, uint dna);    uint dnaDigits = 16;    uint dnaModulus = 10 ** dnaDigits;    uint cooldownTime = 1 days;    struct Zombie {      string name;      uint dna;      uint32 level;      uint32 readyTime;    }    Zombie[] public zombies;    mapping (uint =&gt; address) public zombieToOwner;    mapping (address =&gt; uint) ownerZombieCount;    function _createZombie(string _name, uint _dna) internal {        uint id = zombies.push(Zombie(_name, _dna, 1, uint32(now + cooldownTime))) - 1;        zombieToOwner[id] = msg.sender;        ownerZombieCount[msg.sender]++;        NewZombie(id, _name, _dna);    }    function _generateRandomDna(string _str) private view returns (uint) {        uint rand = uint(keccak256(_str));        return rand % dnaModulus;    }    function createRandomZombie(string _name) public {        require(ownerZombieCount[msg.sender] == 0);        uint randDna = _generateRandomDna(_name);        randDna = randDna - randDna % 100;        _createZombie(_name, randDna);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Ownable是来自 OpenZeppelin Solidity 库的 Ownable 合约。<br>事件 是合约和区块链通讯的一种机制。你的前端应用“监听”某些事件，并做出反应。如：</p></blockquote><pre class="line-numbers language-none"><code class="language-none">var abi = // abi是由编译器生成的  var ZombieFactoryContract = web3.eth.contract(abi)  var contractAddress = /// 发布之后在以太坊上生成的合约地址  var ZombieFactory = ZombieFactoryContract.at(contractAddress)   // ZombieFactory能访问公共的函数以及事件// 监听NewZombie事件, 并且更新UI  var event = ZombieFactory.NewZombie(function(error, result) {    if (error) return  generateZombie(result.zombieId, result.name, result.dna)})  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ZombieFeeding.sol</p><pre class="line-numbers language-none"><code class="language-none">pragma solidity ^0.4.19;import "./zombiefactory.sol";contract KittyInterface {    function getKitty(uint256 _id) external view returns (      bool isGestating,      bool isReady,      uint256 cooldownIndex,      uint256 nextActionAt,      uint256 siringWithId,      uint256 birthTime,      uint256 matronId,      uint256 sireId,      uint256 generation,      uint256 genes    );  }contract ZombieFeeding is ZombieFactory {  KittyInterface kittyContract;  modifier ownerOf(uint _zombieId) {    require(msg.sender == zombieToOwner[_zombieId]);    _;  }  function setKittyContractAddress(address _address) external onlyOwner {    kittyContract = KittyInterface(_address);  }  function _triggerCooldown(Zombie storage _zombie) internal {    _zombie.readyTime = uint32(now + cooldownTime);  }  function _isReady(Zombie storage _zombie) internal view returns (bool) {      return (_zombie.readyTime &lt;= now);  }  function feedAndMultiply(uint _zombieId, uint _targetDna, string _species) internal ownerOf(_zombieId) {    Zombie storage myZombie = zombies[_zombieId];    require(_isReady(myZombie));    _targetDna = _targetDna % dnaModulus;    uint newDna = (myZombie.dna + _targetDna) / 2;    if (keccak256(_species) == keccak256("kitty")) {      newDna = newDna - newDna % 100 + 99;    }    _createZombie("NoName", newDna);    _triggerCooldown(myZombie);  }  function feedOnKitty(uint _zombieId, uint _kittyId) public {    uint kittyDna;    (,,,,,,,,,kittyDna) = kittyContract.getKitty(_kittyId);    feedAndMultiply(_zombieId, kittyDna, "kitty");  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>在 Solidity 中，有一些全局变量可以被所有函数调用。 其中一个就是 msg.sender，它指的是当前调用者（或智能合约）的 address。<br>Solidity 使用自己的本地时间单位。<br>变量 now 将返回当前的unix时间戳（自1970年1月1日以来经过的秒数）。我写这句话时 unix 时间是 1515527488。</p><p>注意：Unix时间传统用一个32位的整数进行存储。这会导致“2038年”问题，当这个32位的unix时间戳不够用，产生溢出，使用这个时间的遗留系统就麻烦了。所以，如果我们想让我们的 DApp 跑够20年，我们可以使用64位整数表示时间，但为此我们的用户又得支付更多的 gas。真是个两难的设计啊！</p><p>Solidity 还包含秒(seconds)，分钟(minutes)，小时(hours)，天(days)，周(weeks) 和 年(years) 等时间单位。它们都会转换成对应的秒数放入 uint 中。所以 1分钟 就是 60，1小时是 3600（60秒×60分钟），1天是86400（24小时×60分钟×60秒），以此类推。</p></blockquote><p>ZombieHelper.sol</p><pre class="line-numbers language-none"><code class="language-none">pragma solidity ^0.4.19;import "./zombiefeeding.sol";contract ZombieHelper is ZombieFeeding {  uint levelUpFee = 0.001 ether;  modifier aboveLevel(uint _level, uint _zombieId) {    require(zombies[_zombieId].level &gt;= _level);    _;  }  function withdraw() external onlyOwner {    owner.transfer(this.balance);  }  function setLevelUpFee(uint _fee) external onlyOwner {    levelUpFee = _fee;  }  function levelUp(uint _zombieId) external payable {    require(msg.value == levelUpFee);    zombies[_zombieId].level++;  }  function changeName(uint _zombieId, string _newName) external aboveLevel(2, _zombieId) ownerOf(_zombieId) {    zombies[_zombieId].name = _newName;  }  function changeDna(uint _zombieId, uint _newDna) external aboveLevel(20, _zombieId) ownerOf(_zombieId) {    zombies[_zombieId].dna = _newDna;  }  function getZombiesByOwner(address _owner) external view returns(uint[]) {    uint[] memory result = new uint[](ownerZombieCount[_owner]);    uint counter = 0;    for (uint i = 0; i &lt; zombies.length; i++) {      if (zombieToOwner[i] == _owner) {        result[counter] = i;        counter++;      }    }    return result;  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>msg.value 是一种可以查看向合约发送了多少以太的方法，另外 ether 是一个內建单元。<br>这里发生的事是，一些人会从 web3.js 调用这个函数 (从DApp的前端)， 像这样 :</p></blockquote><pre class="line-numbers language-none"><code class="language-none">// 假设 `OnlineStore` 在以太坊上指向你的合约:    OnlineStore.buySomething().send(from: web3.eth.defaultAccount, value: web3.utils.toWei(0.001))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>ZombieBattle.sol</p><pre class="line-numbers language-none"><code class="language-none">pragma solidity ^0.4.19;import "./zombiehelper.sol";contract ZombieBattle is ZombieHelper {  uint randNonce = 0;  uint attackVictoryProbability = 70;  function randMod(uint _modulus) internal returns(uint) {    randNonce++;    return uint(keccak256(now, msg.sender, randNonce)) % _modulus;  }  function attack(uint _zombieId, uint _targetId) external ownerOf(_zombieId) {    Zombie storage myZombie = zombies[_zombieId];    Zombie storage enemyZombie = zombies[_targetId];    uint rand = randMod(100);    if (rand &lt;= attackVictoryProbability) {      myZombie.winCount++;      myZombie.level++;      enemyZombie.lossCount++;      feedAndMultiply(_zombieId, enemyZombie.dna, "zombie");    } else {      myZombie.lossCount++;      enemyZombie.winCount++;      _triggerCooldown(myZombie);    }  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Ethereum </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
            <tag> Blockchain </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MongoDB 查询语句</title>
      <link href="/2017/02/17/mongodb-cha-xun-yu-ju/"/>
      <url>/2017/02/17/mongodb-cha-xun-yu-ju/</url>
      
        <content type="html"><![CDATA[<p><a href="https://docs.mongodb.com/getting-started/shell/">Get Started</a><br><a href="https://docs.mongodb.com/manual/">Official Manual</a></p><p>借用官网的例子数据：db.inventory</p><pre class="line-numbers language-none"><code class="language-none">{ item: "journal", qty: 25, status: "A", size: { h: 14, w: 21, uom: "cm" }, tags: ["blank", "red"], dim_cm: [ 14, 21 ] }{ item: "notebook", qty: 50, status: "A", size: { h: 8.5, w: 11, uom: "in" }, tags: ["red", "blank"], dim_cm: [ 14, 21 ] }{ item: "paper", qty: 100, status: "D", size: { h: 8.5, w: 11, uom: "in" }, tags: ["red", "blank", "plain"], dim_cm: [ 14, 21 ] }{ item: "planner", qty: 75, status: "D", size: { h: 22.85, w: 30, uom: "cm" }, tags: ["blank", "red"], dim_cm: [ 22.85, 30 ] }{ item: "postcard", qty: 45,  status: "A", size: { h: 10, w: 15.25, uom: "cm" }, tags: ["blue"], dim_cm: [ 10, 15.25 ] }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="查找所有：">查找所有：</h4><pre class="line-numbers language-none"><code class="language-none">db.inventory.find( {} )<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="简单匹配普通属性：">简单匹配普通属性：</h4><pre class="line-numbers language-none"><code class="language-none">db.inventory.find( { status: "D" } )<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>使用操作符匹配普通属性：</p><pre class="line-numbers language-none"><code class="language-none">db.inventory.find( { status: { $in: [ "A", "D" ] } } )<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>多个属性匹配，之间是且的关系：</p><pre class="line-numbers language-none"><code class="language-none">db.inventory.find( { status: "A", qty: { $lt: 30 } } )<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>或的关系需要另加操作符：</p><pre class="line-numbers language-none"><code class="language-none">db.inventory.find( { $or: [ { status: "A" }, { qty: { $lt: 30 } } ] } )<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>且 和 或 共同使用的时：</p><pre class="line-numbers language-none"><code class="language-none">db.inventory.find( {      status: "A",      $or: [ { qty: { $lt: 30 } }, { item: /^p/ } ]  } )<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="查找，数组-对象属性中有满足匹配的子项">查找，数组/对象属性中有满足匹配的子项</h4><pre class="line-numbers language-none"><code class="language-none">db.inventory.find( { tags: "red" } )db.inventory.find( { "size.uom": "in" } )<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>数组/对象完全匹配查找（子项顺序必须完全相同，不然匹配不到）</p><pre class="line-numbers language-none"><code class="language-none">db.inventory.find( { size: { h: 14, w: 21, uom: "cm" } } )db.inventory.find( { tags: ["red", "blank"] } )<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="匹配数组时注意：默认多元素子项可分摊匹配">匹配数组时注意：默认多元素子项可分摊匹配</h4><pre class="line-numbers language-none"><code class="language-none">db.inventory.find( { dim_cm: { $gt: 15, $lt: 20 } } )<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>The following example queries for documents where the dim_cm array contains elements that in some combination satisfy the query conditions; e.g., one element can satisfy the greater than 15 condition and another element can satisfy the less than 20 condition, or a single element can satisfy both.</p></blockquote><h4 id="匹配数组：期望元素子项内匹配">匹配数组：期望元素子项内匹配</h4>  <pre class="line-numbers language-none"><code class="language-none">db.inventory.find( { dim_cm: { $elemMatch: { $gt: 22, $lt: 30 } } } )<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>The following example queries for documents where the dim_cm array contains at least one element that is both greater than ($gt) 22 and less than ($lt) 30.</p></blockquote><h4 id="匹配数组可以用索引（索引从0开始）">匹配数组可以用索引（索引从0开始）</h4><pre class="line-numbers language-none"><code class="language-none">db.inventory.find( { "dim_cm.1": { $gt: 25 } } )<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="匹配数组，可以多元素捆绑匹配">匹配数组，可以多元素捆绑匹配</h4><pre class="line-numbers language-none"><code class="language-none">db.inventory.find( { tags: { $all: ["red", "blank"] } } )<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>同（既包含’red’, 也包含’blank’的）：</p><pre class="line-numbers language-none"><code class="language-none">db.inventory.find({ $and: [ { tags: "red" }, { tags: "blank" } ] })<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> NoSQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MongoDB </tag>
            
            <tag> NoSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker学习笔记</title>
      <link href="/2016/11/08/docker-xue-xi-bi-ji/"/>
      <url>/2016/11/08/docker-xue-xi-bi-ji/</url>
      
        <content type="html"><![CDATA[<p>本地用的Docker for Mac，使用<a href="https://docs.docker.com/docker-for-mac/">official tutorial</a> 进行前期安装工作。</p><p>安装好后，运行第一个命令 <code>docker --version</code></p><blockquote><p>Docker version 1.12.1, build 6f9534c</p></blockquote><p>官方文档上面一直提到一个Docker Toolbox，是针对不满足Docker for Mac的系统配置要求"<em>macOS 10.10.3 Yosemite or newer</em>"，则建议安装Docker Toolbox。</p><h3 id="如何运行-container">如何运行 container</h3><h4 id="1-简单运行起来一个container。">1. 简单运行起来一个container。</h4><p>从 Docker hub 上搜索一个 image。</p><pre class="line-numbers language-none"><code class="language-none">$ docker search hello-world<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>从 Docker hub 上 pull 一个 image。</p><pre class="line-numbers language-none"><code class="language-none">$ docker pull hello-world<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>基于 image 运行一个 container。</p><pre class="line-numbers language-none"><code class="language-none">$ docker run hello-world<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="2-其实用一条命令就直接完成上面的三项：docker-run-hello-world">2. 其实用一条命令就直接完成上面的三项：<strong>docker run hello-world</strong></h4><p>运行<strong>docker run</strong>的时候，docker engine其实做了三个动作：</p><ul><li>检查本地是否有 hello-world 的 image</li><li>如果本地没有，从 Docker hub 下载 hello-world 的 image（不只是Docker hub上）</li><li>加载 image 去运行一个 container</li></ul><h4 id="3-列举出所有-container-和-image">3. 列举出所有 container 和 image</h4><p>显示所有运行中的 container</p><pre class="line-numbers language-none"><code class="language-none">$ docker ps<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>显示所有被创建的 container</p><pre class="line-numbers language-none"><code class="language-none">$ docker ps -a<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>显示最近一个被创建的 container</p><pre class="line-numbers language-none"><code class="language-none">$ docker ps -l<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>显示本地所有 image</p><pre class="line-numbers language-none"><code class="language-none">$ docker images<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-image-和-container-的定义">4. image 和 container 的定义</h4><blockquote><p>Docker Engine provides the core Docker technology that enables images and containers.<br>An image is a filesystem and parameters to use at runtime. It doesn’t have state and never changes. A container is a running instance of an image.</p></blockquote><h4 id="5-在-container-内运行命令">5. 在 container 内运行命令</h4><pre class="line-numbers language-none"><code class="language-none">$ docker run ubuntu echo "hello word"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通常当命令执行完毕时，container 即会停止。</p><pre class="line-numbers language-none"><code class="language-none">$ docker run -t -i ubuntu /bin/bash<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>host 运行一个 container，并且打开一条交互连接。</p><blockquote><p><strong>-t</strong> flag assigns a pseudo-tty or terminal inside the new container.<br><strong>-i</strong> flag allows you to make an interactive connection by grabbing the standard input (STDIN) of the container.</p></blockquote><pre class="line-numbers language-none"><code class="language-none">$ docker run -d ubuntu /bin/sh -c "while true; do echo hello world; sleep 1; done"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>用后台进程的形式运行命令。</p><blockquote><p>-d flag runs the container in the background (to daemonize it).</p></blockquote><p><strong>注意：如果不指定 contrainer name，docker 将自动生成 container name。</strong></p><h4 id="6-查看指定-container-的标准输出信息">6. 查看指定 container 的标准输出信息</h4><pre class="line-numbers language-none"><code class="language-none">$ docker logs &lt;containerId&gt;[&lt;containerName&gt;]$ docker logs -f &lt;containerId&gt;[&lt;containerName&gt;] //-f 效果同tail -f<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="7-停止-启动-删除container">7. 停止/启动/删除container</h4><pre class="line-numbers language-none"><code class="language-none">$ docker stop &lt;containerID&gt;[&lt;containerName&gt;]$ docker start &lt;containerID&gt;[&lt;containerName&gt;]$ docker rm &lt;containerID&gt;[&lt;containerName&gt;]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="如何创建-Image">如何创建 Image</h3><blockquote><p>There are two ways you can update and create images.<br>You can update a container created from an image and commit the results to an image.<br>You can use a Dockerfile to specify instructions to create an image.</p></blockquote><h4 id="1-第一种，更新一个-image-并且-commit。">1. 第一种，更新一个 image 并且 commit。</h4><pre class="line-numbers language-none"><code class="language-none"># 创建&amp;运行一个container，并开启交互模式$ docker run -t -i training/sinatra /bin/bash# 进入container terminal bash，安装ruby，安装包，退出root@0b2616b0e5a8:/# apt-get install -y ruby2.0-dev ruby2.0root@0b2616b0e5a8:/# gem2.0 install jsonroot@0b2616b0e5a8:/# exit# 提交变更，-m message/ -a author，containerId， commit后的image name$ docker commit -m "Added json gem" -a "Kate Smith" 0b2616b0e5a8 ouruser/sinatra:v2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>commit 之后在本地 images 中就可以看见 ouruser/sinatra:v2 的 image 了，之后可以选择从这个 image 来创建一个新的 container，或者将其 push 到 docker bub 上。</p><h4 id="2-第二种，使用-Dockerfile-文件">2. 第二种，使用 Dockerfile 文件</h4><ul><li>创建一个 Dockfile 文件</li></ul><pre class="line-numbers language-none"><code class="language-none">$ mkdir mydockerbuild$ cd mydockerbuild$ touch Dockerfile<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>打开 Dockerfile，并进行编写</li></ul><pre class="line-numbers language-none"><code class="language-none">FROM docker/whalesay:latest  RUN apt-get -y update &amp;&amp; apt-get install -y fortunes# CMD /usr/games/fortune -a | cowsay<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>build image</li></ul><pre class="line-numbers language-none"><code class="language-none">$ docker build -t docker-whale .<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>The docker build -t docker-whale . command takes the Dockerfile in the current directory, and builds an image called docker-whale on your local machine.</p></blockquote><h4 id="3-上传-image">3. 上传 image</h4><p>附： 如果需要将image发布到docker hub上，首先需要sign up一个 <a href="https://hub.docker.com/">docker hub</a> 的账号。<br>然后本地命令行</p><pre class="line-numbers language-none"><code class="language-none">$ docker login$ docker push yourhubname/docker-whale<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>添加一个 tag</p><pre class="line-numbers language-none"><code class="language-none">$ docker tag &lt;imageId&gt;[&lt;imageName&gt;] yourhubname/docker-whale:latest<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-删除-image">4. 删除 image</h4><pre class="line-numbers language-none"><code class="language-none">$ docker rmi &lt;imageID&gt;[&lt;imageName&gt;]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Markdown 书写方式</title>
      <link href="/2016/07/14/markdown-shu-xie-fang-shi/"/>
      <url>/2016/07/14/markdown-shu-xie-fang-shi/</url>
      
        <content type="html"><![CDATA[<ol><li><p>斜体<br><code>_content_</code></p></li><li><p>粗体<br><code>**content**</code></p></li><li><p>header<br><code>#(number) 代表header number</code></p></li></ol><pre class="line-numbers language-none"><code class="language-none">###This is header 3.<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>链接<br><code>[text context](url)</code></li></ol><pre class="line-numbers language-none"><code class="language-none">[Search for it.](www.google.com)[You're *really, really* going to want to see this](www.dailykitten.com).<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="5"><li>图片<br><code>![text](url)</code></li></ol><pre class="line-numbers language-none"><code class="language-none">![A Catburn](http://octodex.github.com/images/octdrey-catburn.jpg)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="6"><li>reference</li></ol><blockquote><p>Do you want to [see something fun][a fun place]?<br>Well, do I have [the website for you][another fun place]!<br>[a fun place]: <a href="http://www.zombo.com">www.zombo.com</a><br>[another fun place]: <a href="http://www.stumbleupon.com">www.stumbleupon.com</a></p><p>![The first father][First Father]<br>![The second first father][Second Father]<br>[First Father]: <a href="http://octodex.github.com/images/founding-father.jpg">http://octodex.github.com/images/founding-father.jpg</a><br>[Second Father]: <a href="http://octodex.github.com/images/foundingfather_v2.png">http://octodex.github.com/images/foundingfather_v2.png</a></p></blockquote><ol start="7"><li><p>Blockquotes</p><p><code>&gt; paragraph </code></p></li><li><p>列表<br>无序列表 <code>* content</code><br>有序列表 <code>1. content</code><br>嵌套列表 <code>&lt;空格&gt;* content</code></p></li><li><p>换行<br>hard（间距大） 空一行<br>soft（间距小） 结尾用两个空格</p></li><li><p>画表格</p></li></ol><pre class="line-numbers language-none"><code class="language-none">| Number     | Next number | Previous number || :--------- |:----------- | :-------------- || Five       | Six         | Four            || Ten        | Eleven      | Nine            || Seven      | Eight       | Six             || Two        | Three       | One             |<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="11"><li>代码书写</li></ol><pre class="line-numbers language-none"><code class="language-none">```code```<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>或者</p><pre class="line-numbers language-none"><code class="language-none">~~~code~~~<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>详情可见<a href="http://www.markdowntutorial.com/">markdown tutorial</a></p>]]></content>
      
      
      <categories>
          
          <category> 轻量型文档 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 轻量型文档 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java S3 Example</title>
      <link href="/2016/06/24/java-s3-example/"/>
      <url>/2016/06/24/java-s3-example/</url>
      
        <content type="html"><![CDATA[<p>最近听了一次亮哥他们AWS的首次session，中间稍微提到了一下IAM account的access key。没想到在项目中给别人code review的时候就接触到了，是针对AWS S3的。具体S3说明，见 <a href="http://aws.amazon.com/s3/">http://aws.amazon.com/s3/</a></p><hr><h2 id="Setting-up-project">Setting up project</h2><p>1. AWS SDK for Java</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>com.amazonaws<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>aws-java-sdk<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.9.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2. 使用一个IAM account，如果没有创建一个，获取到它的“Access key”和“Secret Access Key”。</p><h2 id="Authenticate-with-Amazon-S3">Authenticate with Amazon S3</h2><p>1. 使用Access Key进行验证</p><p>1） 环境变量Environment Variables – AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY.</p><p>2） Java System Properties – aws.accessKeyId and aws.secretKey.</p><p>3） 默认用户下profiles文件， ~/.aws/credentials</p><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown">[default]aws_access_key_id={YOUR_ACCESS_KEY_ID}aws_secret_access_key={YOUR_SECRET_ACCESS_KEY}[profile2]...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4） 代码中直接填写</p><p>前三种使用验证链：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">AmazonS3</span> s3Client <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AmazonS3Client</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//or</span><span class="token comment">//The following line of code is effectively equivalent to the preceding example:</span><span class="token class-name">AmazonS3</span> s3Client <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AmazonS3Client</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">DefaultAWSCredentialsProviderChain</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>第四种：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">AWSCredentials</span> credentials <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BasicAWSCredentials</span><span class="token punctuation">(</span><span class="token string">"YourAccessKeyID"</span><span class="token punctuation">,</span> <span class="token string">"YourSecretAccessKey"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">AmazonS3</span> s3client <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AmazonS3Client</span><span class="token punctuation">(</span>credentials<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2. 从AWS Security Token Service (<a href="http://aws.amazon.com/documentation/iam/">AWS STS</a>) 获取临时证书，见<a href="http://docs.aws.amazon.com/AWSSdkDocsJava/latest/DeveloperGuide/prog-services-sts.html?highlight=awssecuritytokenserviceclient">Document</a></p><h2 id="SDK-Example">SDK Example</h2><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">ByteArrayInputStream</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">File</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">InputStream</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">List</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">com<span class="token punctuation">.</span>amazonaws<span class="token punctuation">.</span>auth<span class="token punctuation">.</span></span><span class="token class-name">AWSCredentials</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">com<span class="token punctuation">.</span>amazonaws<span class="token punctuation">.</span>auth<span class="token punctuation">.</span></span><span class="token class-name">BasicAWSCredentials</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">com<span class="token punctuation">.</span>amazonaws<span class="token punctuation">.</span>services<span class="token punctuation">.</span>s3<span class="token punctuation">.</span></span><span class="token class-name">AmazonS3</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">com<span class="token punctuation">.</span>amazonaws<span class="token punctuation">.</span>services<span class="token punctuation">.</span>s3<span class="token punctuation">.</span></span><span class="token class-name">AmazonS3Client</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">com<span class="token punctuation">.</span>amazonaws<span class="token punctuation">.</span>services<span class="token punctuation">.</span>s3<span class="token punctuation">.</span>model<span class="token punctuation">.</span></span><span class="token class-name">Bucket</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">com<span class="token punctuation">.</span>amazonaws<span class="token punctuation">.</span>services<span class="token punctuation">.</span>s3<span class="token punctuation">.</span>model<span class="token punctuation">.</span></span><span class="token class-name">CannedAccessControlList</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">com<span class="token punctuation">.</span>amazonaws<span class="token punctuation">.</span>services<span class="token punctuation">.</span>s3<span class="token punctuation">.</span>model<span class="token punctuation">.</span></span><span class="token class-name">ObjectMetadata</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">com<span class="token punctuation">.</span>amazonaws<span class="token punctuation">.</span>services<span class="token punctuation">.</span>s3<span class="token punctuation">.</span>model<span class="token punctuation">.</span></span><span class="token class-name">PutObjectRequest</span></span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token import"><span class="token namespace">com<span class="token punctuation">.</span>amazonaws<span class="token punctuation">.</span>services<span class="token punctuation">.</span>s3<span class="token punctuation">.</span>model<span class="token punctuation">.</span></span><span class="token class-name">S3ObjectSummary</span></span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">AmazonS3Example</span> <span class="token punctuation">{</span><span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">SUFFIX</span> <span class="token operator">=</span> <span class="token string">"/"</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">// credentials object identifying user for authentication</span><span class="token comment">// user must have AWSConnector and AmazonS3FullAccess for </span><span class="token comment">// this example to work</span><span class="token class-name">AWSCredentials</span> credentials <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BasicAWSCredentials</span><span class="token punctuation">(</span><span class="token string">"YourAccessKeyID"</span><span class="token punctuation">,</span> <span class="token string">"YourSecretAccessKey"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// create a client connection based on credentials</span><span class="token class-name">AmazonS3</span> s3client <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AmazonS3Client</span><span class="token punctuation">(</span>credentials<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// create bucket - name must be unique for all S3 users</span><span class="token class-name">String</span> bucketName <span class="token operator">=</span> <span class="token string">"javatutorial-net-example-bucket"</span><span class="token punctuation">;</span>s3client<span class="token punctuation">.</span><span class="token function">createBucket</span><span class="token punctuation">(</span>bucketName<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// list buckets</span><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Bucket</span> bucket <span class="token operator">:</span> s3client<span class="token punctuation">.</span><span class="token function">listBuckets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">" - "</span> <span class="token operator">+</span> bucket<span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment">// create folder into bucket</span><span class="token class-name">String</span> folderName <span class="token operator">=</span> <span class="token string">"testfolder"</span><span class="token punctuation">;</span><span class="token function">createFolder</span><span class="token punctuation">(</span>bucketName<span class="token punctuation">,</span> folderName<span class="token punctuation">,</span> s3client<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// upload file to folder and set it to public</span><span class="token class-name">String</span> fileName <span class="token operator">=</span> folderName <span class="token operator">+</span> <span class="token constant">SUFFIX</span> <span class="token operator">+</span> <span class="token string">"testvideo.mp4"</span><span class="token punctuation">;</span>s3client<span class="token punctuation">.</span><span class="token function">putObject</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">PutObjectRequest</span><span class="token punctuation">(</span>bucketName<span class="token punctuation">,</span> fileName<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">"C:\\Users\\user\\Desktop\\testvideo.mp4"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">withCannedAcl</span><span class="token punctuation">(</span><span class="token class-name">CannedAccessControlList<span class="token punctuation">.</span>PublicRead</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">deleteFolder</span><span class="token punctuation">(</span>bucketName<span class="token punctuation">,</span> folderName<span class="token punctuation">,</span> s3client<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// deletes bucket</span>s3client<span class="token punctuation">.</span><span class="token function">deleteBucket</span><span class="token punctuation">(</span>bucketName<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">createFolder</span><span class="token punctuation">(</span><span class="token class-name">String</span> bucketName<span class="token punctuation">,</span> <span class="token class-name">String</span> folderName<span class="token punctuation">,</span> <span class="token class-name">AmazonS3</span> client<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">// create meta-data for your folder and set content-length to 0</span><span class="token class-name">ObjectMetadata</span> metadata <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ObjectMetadata</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>metadata<span class="token punctuation">.</span><span class="token function">setContentLength</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// create empty content</span><span class="token class-name">InputStream</span> emptyContent <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ByteArrayInputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// create a PutObjectRequest passing the folder name suffixed by /</span><span class="token class-name">PutObjectRequest</span> putObjectRequest <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">PutObjectRequest</span><span class="token punctuation">(</span>bucketName<span class="token punctuation">,</span>folderName <span class="token operator">+</span> <span class="token constant">SUFFIX</span><span class="token punctuation">,</span> emptyContent<span class="token punctuation">,</span> metadata<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// send request to S3 to create folder</span>client<span class="token punctuation">.</span><span class="token function">putObject</span><span class="token punctuation">(</span>putObjectRequest<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment">/** * This method first deletes all the files in given folder and than the * folder itself */</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">deleteFolder</span><span class="token punctuation">(</span><span class="token class-name">String</span> bucketName<span class="token punctuation">,</span> <span class="token class-name">String</span> folderName<span class="token punctuation">,</span> <span class="token class-name">AmazonS3</span> client<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token class-name">List</span> fileList <span class="token operator">=</span> client<span class="token punctuation">.</span><span class="token function">listObjects</span><span class="token punctuation">(</span>bucketName<span class="token punctuation">,</span> folderName<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getObjectSummaries</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">S3ObjectSummary</span> file <span class="token operator">:</span> fileList<span class="token punctuation">)</span> <span class="token punctuation">{</span>client<span class="token punctuation">.</span><span class="token function">deleteObject</span><span class="token punctuation">(</span>bucketName<span class="token punctuation">,</span> file<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span>client<span class="token punctuation">.</span><span class="token function">deleteObject</span><span class="token punctuation">(</span>bucketName<span class="token punctuation">,</span> folderName<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> AWS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Groovy 语法小结</title>
      <link href="/2016/02/22/goovy-yu-fa-xiao-jie/"/>
      <url>/2016/02/22/goovy-yu-fa-xiao-jie/</url>
      
        <content type="html"><![CDATA[<p>1. 安全导航操作符 ?.,只有对象引用不为空时才会分派调用。</p><pre class="line-numbers language-none"><code class="language-none">def&nbsp;aa?.isEmpty()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2. groovy不强迫捕获我们不关心的异常。</p><p>捕获所有Exception</p><pre class="line-numbers language-none"><code class="language-none">try{}catch(ex){}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>3. groovy默认都是public的。</p><p>4. groovy默认提供构造器。</p><pre class="line-numbers language-none"><code class="language-none">class&nbsp;Robot{&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;type,&nbsp;height,&nbsp;width}&nbsp;robot&nbsp;=&nbsp;new&nbsp;Robot(type:&nbsp;'arm',&nbsp;width:&nbsp;10,&nbsp;height:&nbsp;40)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>5. groovy传参</p><p>出现键值对的形式，groovy会将所有键值对作为第一个形参（Map）的Entry，其余参数按顺序赋给剩余形参。</p><pre class="line-numbers language-none"><code class="language-none">class&nbsp;Robot{&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;access(location,&nbsp;weight,&nbsp;fragile){&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print&nbsp;"$fragile,&nbsp;$weight,&nbsp;$location"&nbsp;&nbsp;&nbsp;&nbsp;}}robot.access(x:&nbsp;30,&nbsp;y:&nbsp;20,&nbsp;z:10,&nbsp;5,&nbsp;true)//可改变顺序robot.access(5,&nbsp;true,&nbsp;x:&nbsp;30,&nbsp;y:&nbsp;20,&nbsp;z:10)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意：使用键值对传参，最好是当参数仅有一个Map时使用；</p><p>如果一定要使用一个Map + 多个参数传递的形式，请显示声明Map类型。</p><pre class="line-numbers language-none"><code class="language-none">class&nbsp;Robot{&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;access(Map&nbsp;location,&nbsp;weight,&nbsp;fragile){&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print&nbsp;"$fragile,&nbsp;$weight,&nbsp;$location"&nbsp;&nbsp;&nbsp;&nbsp;}}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当实参包含的不是两个对象和一个任意键值对，代码就会报错。</p><p>6. 可选形参, 方法可以不用再写重载</p><pre class="line-numbers language-none"><code class="language-none">def&nbsp;log(x,&nbsp;base&nbsp;=&nbsp;10){&nbsp;&nbsp;&nbsp;&nbsp;Math.log(x)&nbsp;/&nbsp;Math.log(base)}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>6.1 变长传参</p><p>最后一位形参是数组形式</p><pre class="line-numbers language-none"><code class="language-none">def&nbsp;receiveVarArgs(int&nbsp;a,&nbsp;int...&nbsp;b){}def&nbsp;receiveVarArg(int&nbsp;a,&nbsp;int[]&nbsp;b){}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>注意：Groovy将 [2, 3]看作是ArrayList的一个实例对象，因此调用时：</p><pre class="line-numbers language-none"><code class="language-none">receiveVarArgs（1，&nbsp;[2,&nbsp;3,&nbsp;4]&nbsp;as&nbsp;int[]）<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可参考Groovy创建数组、列表的区别：</p><pre class="line-numbers language-none"><code class="language-none">int[]&nbsp;arr&nbsp;=&nbsp;[1,&nbsp;2,&nbsp;3]def&nbsp;arr1&nbsp;=&nbsp;[1,&nbsp;2,&nbsp;3]&nbsp;as&nbsp;int[]def&nbsp;arr2&nbsp;=&nbsp;[1,&nbsp;2,&nbsp;3]&nbsp;//ArrayList类型<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>7. 多赋值。返回数组，被多赋值给各个变量。</p><p>等号左边变量多的，将设为null（不能默认null的，抛异常），右边值多的，将丢弃。</p><pre class="line-numbers language-none"><code class="language-none">def&nbsp;splitName(fullName){fullName.split('&nbsp;')}def&nbsp;(firstName,&nbsp;lastName)&nbsp;=&nbsp;splitName('James&nbsp;Bond')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>因此可以延伸为交换变量</p><pre class="line-numbers language-none"><code class="language-none">def&nbsp;a&nbsp;=&nbsp;1def&nbsp;b&nbsp;=&nbsp;2(a,&nbsp;b)&nbsp;=&nbsp;[b,&nbsp;a]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>8. 实现接口</p><p>一接口，单方法</p><pre class="line-numbers language-none"><code class="language-none">def&nbsp;diaplyMouseLocation&nbsp;=&nbsp;{positionLabel.setText("$it.x,&nbsp;$it.y")}frame.addMouseListener(diaplyMouseLocation&nbsp;as&nbsp;MouseListener)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>一接口，多方法</p><pre class="line-numbers language-none"><code class="language-none">def&nbsp;handleFocus&nbsp;=&nbsp;[&nbsp;&nbsp;&nbsp;&nbsp;focusGained&nbsp;:&nbsp;{}&nbsp;&nbsp;&nbsp;&nbsp;focusLost&nbsp;:&nbsp;{}]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>动态实现接口， asType()作为什么的接口实现</p><pre class="line-numbers language-none"><code class="language-none">events&nbsp;=&nbsp;['WindowListener',&nbsp;'ComponentListener']//可以是更动态的一些输入handler&nbsp;=&nbsp;{msgLabel.setText("$it")}for(event&nbsp;in&nbsp;events){&nbsp;&nbsp;&nbsp;&nbsp;handlerImpl&nbsp;=&nbsp;handler.asType(Class.forName("java.awt.event.${event}"))&nbsp;&nbsp;&nbsp;&nbsp;frame."add${event}"(handlerImpl)}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>9. 默认布尔处理</p><p>groovy基本都为对象，除引用对象不为空为true外，有些对象还有如下情况也为true。</p><p>| Boolean | 值为true |<br>| Collection | 不为空 |<br>| Map | 映射不为空 |<br>| Char | 不为0 |<br>| 字符串 | 长度大于0 |<br>| 数字 | 不为0 |<br>| 数组 | 长度大于0 |<br>| 其他类型 | 不为null |<br>| 自定制 | 通过asBoolean()方法来重写 |</p><p>10. forEach</p><pre class="line-numbers language-none"><code class="language-none">for(String&nbsp;greet&nbsp;:&nbsp;greetings){}for(def&nbsp;greet&nbsp;:&nbsp;greetings){}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>不想指定类型：</p><pre class="line-numbers language-none"><code class="language-none">for(greet&nbsp;in&nbsp;greetings){}<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>或者 内部迭代器 each()</p><p>10. 静态导入支持别名</p><pre class="line-numbers language-none"><code class="language-none">import&nbsp;static&nbsp;Math.random&nbsp;as&nbsp;randdouble&nbsp;value&nbsp;=&nbsp;rand()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>11. java的编译时注解被忽略，如Override。</p><p>12. groovy既支持动态类型，又支持泛型。泛型在执行时进行检查生效。</p><p>13. Groovy可以重载操作符，因为每个操作符都被映射到一个标准的方法。</p><p>14. 使用注解生成代码</p><p><a href="http://my.oschina.net/u/2345489">@Canonical</a> 标注于类上，用于生成toString():逗号分隔各属性，可排除属性</p><pre class="line-numbers language-none"><code class="language-none">@Canonical(excludes='lastName,&nbsp;age')class&nbsp;Person{}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><a href="http://my.oschina.net/delegate">@Delegate</a> 用于引入被委托类相应的方法包装器，用于委派任务。引入的具体实例方法与顺序有关。</p><p>查找还未有的方法进行一次引入。</p><pre class="line-numbers language-none"><code class="language-none">class&nbsp;Worker{&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;work(){}&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;analyze(){}}class&nbsp;Expert{&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;analyze(){}}class&nbsp;Manager{&nbsp;&nbsp;&nbsp;&nbsp;@Delegate&nbsp;Expert&nbsp;expert&nbsp;=&nbsp;new&nbsp;Expert()//引入Expert实例的analyze方法&nbsp;&nbsp;&nbsp;&nbsp;@Delegate&nbsp;Worker&nbsp;worker&nbsp;=&nbsp;new&nbsp;Worker()//引入Worker实例的work方法}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>@Immutable 标注在类上，用于便捷生成不可变值对象，即属性final。同时提供hashCode()、equals()、toString()方法。</p><pre class="line-numbers language-none"><code class="language-none">@Immutableclass&nbsp;CreditCard{&nbsp;&nbsp;&nbsp;&nbsp;String&nbsp;cardNumber&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;creditLimit}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="http://my.oschina.net/u/145675">@Lazy</a> 标注于属性上，懒加载</p><pre class="line-numbers language-none"><code class="language-none">class&nbsp;Heavy{}class&nbsp;AsNeeded&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;@Lazy&nbsp;Heavy&nbsp;heavy&nbsp;=&nbsp;new&nbsp;Heavy()}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><a href="http://my.oschina.net/u/674">@Singleton</a> 标注于类上，实现单例模式</p><pre class="line-numbers language-none"><code class="language-none">@Singleton(lazy&nbsp;=&nbsp;true)class&nbsp;TheUnique{}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>15. ==</p><p>== 等于调用java的equals()，除非实现Comparable接口的类型，== 等于compareTo()</p><p>is()等于java的==</p><p>16. groovy匿名内部类使用可能会有问题，会将{……}实现体当做闭包。</p>]]></content>
      
      
      <categories>
          
          <category> Groovy </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Groovy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jasmine 基础 API</title>
      <link href="/2015/12/16/jasmine-ji-chu-api/"/>
      <url>/2015/12/16/jasmine-ji-chu-api/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Jasmine官网documen地址">1.  Jasmine官网documen地址</h4><p><a href="http://jasmine.github.io/2.4/introduction.html">http://jasmine.github.io/2.4/introduction.html</a></p><h4 id="2-下载发布包，参照示例进行使用">2.  下载发布包，参照示例进行使用</h4><p>github 上下载最新的 Release 的 zip 包，本地解压后打开：SpecRunner.html(运行文件)、src（js源文件夹）、spec（js测试文件夹）、lib（jasmine依赖的js库）</p><h4 id="3-打开SpecRunner-html文件，在注释说明的相应位置添加源文件、测试文件。">3.  打开SpecRunner.html文件，在注释说明的相应位置添加源文件、测试文件。</h4><pre class="line-numbers language-none"><code class="language-none">&lt;!DOCTYPE&nbsp;html&gt;&lt;html&gt;&lt;head&gt;&nbsp;&nbsp;&lt;meta&nbsp;charset="utf-8"&gt;&nbsp;&nbsp;&lt;title&gt;Jasmine&nbsp;Spec&nbsp;Runner&nbsp;v2.3.4&lt;/title&gt;&nbsp;&nbsp;&lt;link&nbsp;rel="shortcut&nbsp;icon"&nbsp;type="image/png"&nbsp;href="lib/jasmine-2.3.4/jasmine_favicon.png"&gt;&nbsp;&nbsp;&lt;link&nbsp;rel="stylesheet"&nbsp;href="lib/jasmine-2.3.4/jasmine.css"&gt;&nbsp;&nbsp;&lt;script&nbsp;src="lib/jasmine-2.3.4/jasmine.js"&gt;&lt;/script&gt;&nbsp;&nbsp;&lt;script&nbsp;src="lib/jasmine-2.3.4/jasmine-html.js"&gt;&lt;/script&gt;&nbsp;&nbsp;&lt;script&nbsp;src="lib/jasmine-2.3.4/boot.js"&gt;&lt;/script&gt;&nbsp;&nbsp;&lt;!--&nbsp;include&nbsp;source&nbsp;files&nbsp;here...&nbsp;--&gt;&nbsp;&nbsp;&lt;script&nbsp;src="src/Player.js"&gt;&lt;/script&gt;&nbsp;&nbsp;&lt;script&nbsp;src="src/Song.js"&gt;&lt;/script&gt;&nbsp;&nbsp;&lt;!--&nbsp;include&nbsp;spec&nbsp;files&nbsp;here...&nbsp;--&gt;&nbsp;&nbsp;&lt;script&nbsp;src="spec/SpecHelper.js"&gt;&lt;/script&gt;&nbsp;&nbsp;&lt;script&nbsp;src="spec/PlayerSpec.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="4-spec-js文件基本格式">4.  spec.js文件基本格式</h4><pre class="line-numbers language-none"><code class="language-none">describe("A&nbsp;suite&nbsp;is&nbsp;just&nbsp;a&nbsp;function",&nbsp;function()&nbsp;{&nbsp;&nbsp;var&nbsp;a;&nbsp;&nbsp;it("and&nbsp;so&nbsp;is&nbsp;a&nbsp;spec",&nbsp;function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;=&nbsp;true;&nbsp;&nbsp;&nbsp;&nbsp;expect(a).toBe(true);&nbsp;&nbsp;});});<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>describe\it都是function，describe用来定义spec suite，it用来定义spec。</p><p>第一个参数都为字符串，第二个为测试块。</p><blockquote><p>describe：“The string is a name or title for a spec suite – usually what is being tested. The function is a block of code that implements the suite.”</p><p>it：“The string is the title of the spec and the function is the spec, or test. A spec contains one or more expectations that test the state of the code. An expectation in Jasmine is an assertion that is either true or false.&nbsp;”</p></blockquote><h4 id="5-基础API的使用">5.  基础API的使用</h4><p><strong>Matcher</strong>：</p><pre class="line-numbers language-none"><code class="language-none">expect().toBe();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//同===expect().not.toBe();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//所有的断言都可用not取反expect().toEqual();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//可比较字面量或者变量指向的对象内容expect().toMatch(/bar/);&nbsp;&nbsp;&nbsp;&nbsp;//正则expect().toBeDefined();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//是否被定义，未定义是undefinedexpect().toBeUndefined();&nbsp;&nbsp;&nbsp;//是否未定义expect().toBeNull();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//是否是nullexpect().toBeTruthy();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//是否为truthyexpect().toBeFalsy();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//是否未falsyexpect().toContain();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//数组是否包含某元素,基与equals对比expect().toBeLessThan();&nbsp;&nbsp;&nbsp;&nbsp;//小于某值,&nbsp;可比较数字、字符串、时间expect().toBeGreaterThan();&nbsp;//大于某值expect().toBeCloseTo(,&nbsp;0);&nbsp;&nbsp;//根据第二位参数所给的精度，保留相应精度，其后“Round_half_down”，比较值是否相等expect(fn1).toThrow()；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//断言fn1运行会抛出异常//断言fn1运行会抛出具体异常expect(fn1).toThrowError("foo&nbsp;bar&nbsp;baz");&nbsp;&nbsp;&nbsp;&nbsp;expect(fn1).toThrowError(/bar/);expect(fn1).toThrowError(TypeError);expect(fn1).toThrowError(TypeError,&nbsp;"foo&nbsp;bar&nbsp;baz");<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>手动失败</strong>：</p><pre class="line-numbers language-none"><code class="language-none">fail("Callback&nbsp;has&nbsp;been&nbsp;called");<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>Setup and Teardown</strong>：</p><pre class="line-numbers language-none"><code class="language-none">beforeEach,&nbsp;afterEach,&nbsp;beforeAll,&nbsp;afterAll<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在嵌套describe的情况，在it之前会按照由外靠内的顺序执行beforeEach，结束后又由内到外执行afterEach。</p><p><strong>this</strong>：</p><p>在一个spec的beforeEach/it/afterEach范围内有效分享对象的方式。</p><p>“Each spec’s<code>beforeEach</code>/<code>it</code>/<code>afterEach</code>&nbsp;has the&nbsp;<code>this</code>&nbsp;as the same empty object that is set back to empty for the next spec’s&nbsp;<code>beforeEach</code>/<code>it</code>/<code>afterEach</code>.”</p><pre class="line-numbers language-none"><code class="language-none">describe("A&nbsp;spec",&nbsp;function()&nbsp;{&nbsp;&nbsp;beforeEach(function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;this.foo&nbsp;=&nbsp;0;&nbsp;&nbsp;});&nbsp;&nbsp;it("can&nbsp;use&nbsp;the&nbsp;`this`&nbsp;to&nbsp;share&nbsp;state",&nbsp;function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;expect(this.foo).toEqual(0);&nbsp;&nbsp;&nbsp;&nbsp;this.bar&nbsp;=&nbsp;"test&nbsp;pollution?";&nbsp;&nbsp;});&nbsp;&nbsp;it("prevents&nbsp;test&nbsp;pollution&nbsp;by&nbsp;having&nbsp;an&nbsp;empty&nbsp;`this`&nbsp;created&nbsp;for&nbsp;the&nbsp;next&nbsp;spec",&nbsp;function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;expect(this.foo).toEqual(0);&nbsp;&nbsp;&nbsp;&nbsp;expect(this.bar).toBe(undefined);&nbsp;&nbsp;});});<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>Disabling Suites</strong>:</p><pre class="line-numbers language-none"><code class="language-none">xdescribe("A&nbsp;spec",&nbsp;function()&nbsp;{});<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>Pending Specs</strong>:</p><p>“Pending specs do not run, but their names will show up in the results as<code>pending</code>”。且方法内的一切断言将被忽视。</p><pre class="line-numbers language-none"><code class="language-none">//三种方式xit("can&nbsp;be&nbsp;declared&nbsp;'xit'",&nbsp;function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;expect(true).toBe(false);&nbsp;&nbsp;});&nbsp;&nbsp;it("can&nbsp;be&nbsp;declared&nbsp;with&nbsp;'it'&nbsp;but&nbsp;without&nbsp;a&nbsp;function");//该方法内部调用了pending，将标记为pending方法，参数传达pending原因。it("can&nbsp;be&nbsp;declared&nbsp;by&nbsp;calling&nbsp;'pending'&nbsp;in&nbsp;the&nbsp;spec&nbsp;body",&nbsp;function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;expect(true).toBe(false);&nbsp;&nbsp;&nbsp;&nbsp;pending('this&nbsp;is&nbsp;why&nbsp;it&nbsp;is&nbsp;pending');&nbsp;&nbsp;});<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>Spies</strong>:</p><p>“&nbsp;A spy can stub any function and tracks calls to it and all arguments.&nbsp;”</p><pre class="line-numbers language-none"><code class="language-none">spyOn(foo,&nbsp;'setBar');&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//创建spy，并拦截对方法的调用spyOn(foo,&nbsp;'getBar').and.callThrough();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//创建spy，并代理真实方法的调用//创建spy，并拦截结果的返回，给予结果定义。所有的返回结果被替换。spyOn(foo,&nbsp;"getBar").and.returnValue(745);&nbsp;&nbsp;&nbsp;//创建spy，并拦截结果的返回，按照调用顺序给予结果定义spyOn(foo,&nbsp;"getBar").and.returnValues("fetched&nbsp;first",&nbsp;"fetched&nbsp;second");&nbsp;//fake一个方法spyOn(foo,&nbsp;"getBar").and.callFake(function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;1001;&nbsp;&nbsp;&nbsp;&nbsp;});&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;spyOn(foo,&nbsp;"setBar").and.throwError("quux");&nbsp;&nbsp;//所有的调用将抛出异常//and.stub(),fake一个空方法体spyOn(foo,&nbsp;'setBar');foo.setBar.and.stub();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>jasmine.createSpy</strong></p><pre class="line-numbers language-none"><code class="language-none">whatAmI&nbsp;=&nbsp;jasmine.createSpy('whatAmI');&nbsp;&nbsp;&nbsp;&nbsp;//创建一个方法用于spy，不需要该方法已经定义,&nbsp;context为定义时的上下文tape&nbsp;=&nbsp;jasmine.createSpyObj(['play',&nbsp;'pause',&nbsp;'stop',&nbsp;'rewind']);&nbsp;&nbsp;&nbsp;&nbsp;//创建一个对象，且属性也同时被定义<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>matcher：</strong></p><pre class="line-numbers language-none"><code class="language-none">expect(foo.setBar).toHaveBeenCalled();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//已经被调用expect(foo.setBar).toHaveBeenCalledWith(123);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//已经通过参数XX调用//======期望值的matcher======expect(foo).toHaveBeenCalledWith(jasmine.any(Number),&nbsp;jasmine.any(Function));&nbsp;&nbsp;&nbsp;&nbsp;//jasmine.any(构造函数名)，此类型的任何对象即可匹配expect(foo).toHaveBeenCalledWith(12,&nbsp;jasmine.anything());&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//jasmine.anything()，非undefined\null的即可匹配expect(foo).toEqual(jasmine.objectContaining({bar:&nbsp;"baz"}));&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//jasmine.objectContaining，包含此属性的对象即可匹配expect(foo).toEqual(jasmine.arrayContaining([3,&nbsp;1]));&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//jasmine.arrayContaining，包含其元素子集的数组即可匹配expect({foo:&nbsp;'bar'}).toEqual({foo:&nbsp;jasmine.stringMatching(/^bar$/)});&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//jasmine.stringMatching，包含此字符串匹配方式的即可匹配（参数方式可参见toMatch）//自定义任何想要的期望匹配：asymmetricMatchdescribe("custom&nbsp;asymmetry",&nbsp;function()&nbsp;{&nbsp;&nbsp;var&nbsp;tester&nbsp;=&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;asymmetricMatch:&nbsp;function(actual)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;secondValue&nbsp;=&nbsp;actual.split(',')[1];&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;secondValue&nbsp;===&nbsp;'bar';&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;&nbsp;};&nbsp;&nbsp;it("dives&nbsp;in&nbsp;deep",&nbsp;function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;expect("foo,bar,baz,quux").toEqual(tester);&nbsp;&nbsp;});&nbsp;&nbsp;describe("when&nbsp;used&nbsp;with&nbsp;a&nbsp;spy",&nbsp;function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;it("is&nbsp;useful&nbsp;for&nbsp;comparing&nbsp;arguments",&nbsp;function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;callback&nbsp;=&nbsp;jasmine.createSpy('callback');&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;callback('foo,bar,baz');&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expect(callback).toHaveBeenCalledWith(tester);&nbsp;&nbsp;&nbsp;&nbsp;});&nbsp;&nbsp;});});<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>spy.calls：</strong></p><p>“Every call to a spy is tracked and exposed on the&nbsp;<code>calls</code>&nbsp;property.” 对spy的完整track信息。</p><pre class="line-numbers language-none"><code class="language-none">expect(foo.setBar.calls.any()).toEqual(false);&nbsp;//spy的函数被调用至少一次，则返回trueexpect(foo.setBar.calls.count()).toEqual(0);&nbsp;&nbsp;&nbsp;//spy的函数被调用的次数//函数被调用的索引对应的参数列表：foo.setBar.calls.argsForfoo.setBar(123);foo.setBar(456,&nbsp;"baz");expect(foo.setBar.calls.argsFor(0)).toEqual([123]);expect(foo.setBar.calls.argsFor(1)).toEqual([456,&nbsp;"baz"]);//被调用的历史完整列表：foo.setBar.calls.allArgsexpect(foo.setBar.calls.allArgs()).toEqual([[123],[456,&nbsp;"baz"]]);//track的历史所有完整信息：foo.setBar.calls.all（注意是数组）expect(foo.setBar.calls.all()).toEqual([{object:&nbsp;foo,&nbsp;args:&nbsp;[123],&nbsp;returnValue:&nbsp;undefined}]);//track的最近一次的完整信息：foo.setBar.calls.mostRecentexpect(foo.setBar.calls.mostRecent()).toEqual({object:&nbsp;foo,&nbsp;args:&nbsp;[456,&nbsp;"baz"],&nbsp;returnValue:&nbsp;undefined});//track的第一次的完整信息：foo.setBar.calls.firstexpect(foo.setBar.calls.first()).toEqual({object:&nbsp;foo,&nbsp;args:&nbsp;[123],&nbsp;returnValue:&nbsp;undefined});expect(spy.calls.first().object).toBe(foo);&nbsp;&nbsp;&nbsp;&nbsp;//object为调用上下文contextfoo.setBar.calls.reset();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//清除track历史记录，重置<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>Jasmine Clock</strong>：</p><pre class="line-numbers language-none"><code class="language-none">beforeEach中jasmine.clock().install();afterEach中jasmine.clock().uninstall();it中使用jasmine.clock().tick(101);&nbsp;调用时模拟时间已经走了101毫秒，好似时间加速器//模拟绝对时间var&nbsp;baseTime&nbsp;=&nbsp;new&nbsp;Date(2013,&nbsp;9,&nbsp;23);jasmine.clock().mockDate(baseTime);jasmine.clock().tick(50);expect(new&nbsp;Date().getTime()).toEqual(baseTime.getTime()&nbsp;+&nbsp;50);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>Asynchronous Support</strong>：done</p><p>可使用在beforeEach/it/afterEach中，function注入done即可。注入done声明此处有异步调用，测试需要等待。</p><p>如在“jasmine.DEFAULT_TIMEOUT_INTERVAL”超时之前都未有调用done方法，其后将失败。可通过beforeEach/afterEach的第二个参数，it的第三个参数声明超时时间。</p><pre class="line-numbers language-none"><code class="language-none">it("takes&nbsp;a&nbsp;long&nbsp;time",&nbsp;function(done)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;setTimeout(function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;done();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},&nbsp;9000);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},&nbsp;10000);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> JavaScript </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
            <tag> unit test </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在使用 AngularJS 的过程中了解 Promise（二）</title>
      <link href="/2015/12/05/zai-shi-yong-angularjs-de-guo-cheng-zhong-liao-jie-promise-er/"/>
      <url>/2015/12/05/zai-shi-yong-angularjs-de-guo-cheng-zhong-liao-jie-promise-er/</url>
      
        <content type="html"><![CDATA[<p>公司最近有个博客大赛，OP甚至亲自在team stand-up上要求大家积极投稿。对于我这种热爱写代码、记流水账、提炼式总结的人，拽文真的不是太想做，但是，好吧，这是所谓的impact中最容易做到的一种，那就去做吧。</p><hr><p>Promise，对擅长前端的Dev应该众所周知，对于典型的后端Dev来说，基本可以总结为一句话：<strong>来自于Promise/A+，CommonJS指定规范，解决JS中的回调地狱和异步调用。</strong></p><p><strong>异步调用</strong>，由于在浏览器中JavaScript单线程运行，为了减小那些占用时间长的方法调用的线程等待时间（如向服务器请求资源），定义的某些方法需要在固定事件或响应后才调用执行。</p><p>而所谓<strong>回调地狱</strong>，就是指下面这种可以无限延伸、可读性差、可维护性差的代码调用。</p><pre class="line-numbers language-none"><code class="language-none">$.get('api/xxx/a',&nbsp;function(a)&nbsp;{&nbsp;&nbsp;$.get('api/xxx/b',&nbsp;function(b)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;$.get('api/xxx/c',&nbsp;function(c)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;...&nbsp;&nbsp;&nbsp;&nbsp;},&nbsp;errorCallback);&nbsp;&nbsp;},&nbsp;errorCallback);},&nbsp;errorCallback);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>先来简单说一下AngularJS的Promise的使用，其实主要是两大对象deferred和promise。也可以准确来说，promise是deferred的一个属性对象。</p><p>defer - 延迟，promise - 承诺。</p><p>defer就好像遥控器，promise就是被遥控的炸弹。装配这一套装置的技术员他承诺，按下遥控上的绿色按钮时，左边的炸弹会被引爆，按下红色，右边的炸弹会灰飞烟灭。</p><p>他安装好了这一切，然后拿着遥控器这个句柄，去喝了茶去逛了个街，最主要的是他打了份报告——向上级申请执行引爆，上级经过深思熟虑通过了审批，还顺便选了个黄道吉日，于是技术员按下了遥控上的一个按钮，不出意外对应的炸弹被引爆。</p><p>从遥控炸弹安装完成，到最后被引爆，这一段跨越时间的执行就达到了延迟。</p><p>好吧，这是个蹩脚的比喻，在这里本人只是想将defer/promise这两个词具象一下，其不能完全说明Promise包含的完整机制。因为如果这是看上面这个举例，根本就是一个单纯的Command Pattern就可以实现。</p><p>这里回归正题，deferred和promise：</p><p>promise有一个最主要的方法then，用于注册三类回调函数：successCallBack/errorCallBack/notificationCallBack，然后生成一个新的nextPromise并将其返回。</p><p>deferred对象包含三个方法，resolve()/reject()/notify()，被调用时分别对应执行本实例promise注册的三个回调（见上行，按顺序一对一）。注意resolve和reject是二选一，也就是说炸弹的遥控器是一次性的，它只代表一次延时，炸掉一个就已经成为既定事实不可再改。</p><p>所以对于对于promise而言有三种状态，pending（还在延迟中）、resolve、reject。resolve\reject也同时叫fullfilled，即完成状态。</p><p>一段简单的使用代码：</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;deferred&nbsp;=&nbsp;$q.defer();deferred.promise.then(function&nbsp;success(data)&nbsp;{&nbsp;&nbsp;console.log(data);},function&nbsp;error(reason)&nbsp;{&nbsp;&nbsp;console.error(reason);},function&nbsp;notification(progress)&nbsp;{&nbsp;&nbsp;console.info(progress);});$timeout(function(){&nbsp;&nbsp;&nbsp;&nbsp;deferred.resolve('simple');},&nbsp;3000);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>看，基本上就是这样。至于我为什么说炸弹的例子不太恰当，“一”就是resolve是可以传递参数的，callback函数会对其进行加工。而炸弹的遥控器…这个无法再塞进去任何东西传递给炸弹。</p><p>考虑到这些promise更像是香肠加工流水线，定制好职能和顺序，塞进去一头猪，经历层层加工，最后出来的是香肠。</p><p>而“二”是最有意思的地方，promise支持链状调用，即promise.then(…).then(…)……。同时，达到的效果是，当defer.resolve()/reject()后，首先调用按状态调用then1的callback，then2中的callback始终是在then1的callback调用执行完以后才执行，即串行。</p><p>为什么觉得有意思呢？链状结构无非就是callback函数的最后一句return this不就得了么？</p><p>查看下angular1.3.15源码，事实上，并不是。(项目中用的是angularJS 1.2.26，因此本文中angular书写方式还是1.2的，但1.2源码释义性没有1.3的高，因此本人贴的源码都是1.3的，请谅解。)</p><p>如本人前面所写的“promise有一个最主要的方法then……，然后生成一个新的nextPromise并将其返回”。</p><pre class="line-numbers language-none"><code class="language-none">&nbsp;then:&nbsp;function(onFulfilled,&nbsp;onRejected,&nbsp;progressBack)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;result&nbsp;=&nbsp;new&nbsp;Deferred();&nbsp;&nbsp;&nbsp;&nbsp;this.$$state.pending&nbsp;=&nbsp;this.$$state.pending&nbsp;||&nbsp;[];&nbsp;&nbsp;&nbsp;&nbsp;this.$$state.pending.push([result,&nbsp;onFulfilled,&nbsp;onRejected,&nbsp;progressBack]);&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(this.$$state.status&nbsp;&gt;&nbsp;0)&nbsp;scheduleProcessQueue(this.$$state);&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;result.promise;&nbsp;&nbsp;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>而它为何要这样做呢？它的目的其实是，当第一组炸弹引爆后的推动力可以顺利触发第二组炸弹的遥控器按钮。defer2.resolve(promise2callback())。</p><p>因此promise有连接几个then进行调用，即使生成了几个promise，每一个promise对应的defer遥控都在前一个promise的callback结束处，并且将callback的返回值作为resolve()的参数值。</p><p>完全可以进行验证，见下</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;deferred&nbsp;=&nbsp;$q.defer(),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;promise&nbsp;=&nbsp;deferred.promise;&nbsp;&nbsp;&nbsp;&nbsp;promise.then(function(val){&nbsp;&nbsp;&nbsp;&nbsp;console.log("A&nbsp;"&nbsp;+&nbsp;val);&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;"A";&nbsp;&nbsp;});&nbsp;&nbsp;&nbsp;&nbsp;promise.then(function(val){&nbsp;&nbsp;&nbsp;&nbsp;console.log("B&nbsp;"&nbsp;+&nbsp;val);&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;"B";&nbsp;&nbsp;});&nbsp;&nbsp;&nbsp;&nbsp;deferred.resolve("P");<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果认为promise.then的链状调用，每次都是返回当前promise的话，上面这段代码就应该与promise.then().then()其实是同一个意思，然后很可惜，执行结果是</p><ul><li><p>“A P”</p></li><li><p>“B P”</p></li></ul><p>这里可以想一下为何Promise采用此种链状实现方式。实现Promise的目的是解决回调地狱和异步回调，也就是说痛点原型是这样：</p><pre class="line-numbers language-none"><code class="language-none">asyncTask1('a',&nbsp;function(val1)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;console.log('start&nbsp;task1&nbsp;callback',&nbsp;val1&nbsp;+=&nbsp;'b');&nbsp;&nbsp;&nbsp;&nbsp;asyncTask2(val1,&nbsp;function(val2)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;console.log('start&nbsp;task2&nbsp;callback',&nbsp;val2&nbsp;+=&nbsp;'c');&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;asyncTask3(val2,&nbsp;function(val3)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;console.log('start&nbsp;task3&nbsp;callback',&nbsp;val3&nbsp;+=&nbsp;'d');&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;console.log('end&nbsp;task3&nbsp;callback');&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;});&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;console.log('end&nbsp;task2&nbsp;callback');&nbsp;&nbsp;&nbsp;&nbsp;});&nbsp;&nbsp;&nbsp;&nbsp;console.log('end&nbsp;task1&nbsp;callback');&nbsp;&nbsp;});<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面如果按照期望的链状设计想法，执行下来效果预想如下：</p><pre class="line-numbers language-none"><code class="language-none">"start&nbsp;task1&nbsp;callback""ab""end&nbsp;task1&nbsp;callback""start&nbsp;task2&nbsp;callback""abc""end&nbsp;task2&nbsp;callback""start&nbsp;task3&nbsp;callback""abcd""end&nbsp;task3&nbsp;callback"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>而事实上，按照方法栈后进先出的原则，其实结果是：</p><pre class="line-numbers language-none"><code class="language-none">"start&nbsp;task1&nbsp;callback""ab""start&nbsp;task2&nbsp;callback""abc""start&nbsp;task3&nbsp;callback""abcd""end&nbsp;task3&nbsp;callback""end&nbsp;task2&nbsp;callback""end&nbsp;task1&nbsp;callback"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对按照方法栈的原则，这是不可违背的事实，但是JavaScript幸运的有setTimeout\angularJS有nextTick，在每一个asyncTask调用其回调函数时，仅需使用setTimeout\nextTick来调用callback即可。</p><p>这时链状执行asyncTask1(callback)-&gt;asyncTask2(callback) -&gt;asyncTask3(callback)的顺序就可实现，回过头来再看一眼，callback1对于asyncTask2的调用到底提供了什么？提供执行后的结果作为入参 + 触发其调用而已，除此之外他们可以是各自完整的封装，他们连接成链（链状数据结构的“链”）。</p><p>因此上面那个例子，由promise调用，其实是这样的：</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;asyncTask1&nbsp;=&nbsp;function(data,&nbsp;millisecond)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;defer&nbsp;=&nbsp;$q.defer();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$timeout(function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;defer.resolve(data);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},&nbsp;millisecond);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;defer.promise;&nbsp;&nbsp;&nbsp;&nbsp;},&nbsp;&nbsp;&nbsp;&nbsp;asyncTask2&nbsp;=&nbsp;asyncTask1,&nbsp;&nbsp;&nbsp;&nbsp;asyncTask3&nbsp;=&nbsp;asyncTask1;&nbsp;&nbsp;asyncTask1('a',&nbsp;5000).then(function(val1)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;val1&nbsp;+=&nbsp;'b';&nbsp;&nbsp;&nbsp;&nbsp;console.log('task1&nbsp;callback',&nbsp;val1);&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;asyncTask2(val1,&nbsp;3000);&nbsp;&nbsp;}).&nbsp;&nbsp;then(function(val2)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;val2&nbsp;+=&nbsp;'c';&nbsp;&nbsp;&nbsp;&nbsp;console.log('task2&nbsp;callback',&nbsp;val2);&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;asyncTask3(val2,&nbsp;1000);&nbsp;&nbsp;}).&nbsp;&nbsp;then(function(val3)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;val3&nbsp;+=&nbsp;'d';&nbsp;&nbsp;&nbsp;&nbsp;console.log('task3&nbsp;callback',&nbsp;val3);&nbsp;&nbsp;});<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>angularJS Promise这块代码实现颇为有趣，另外1.3版本比之1.2，这块源码大量被重构，释义提升了不少。</p><p>总的来说，Promise的链状实现两点起到很大作用：</p><p>1、setTimeout/nextTick让回调跳出了先进后出的尴尬；</p><p>2、每一对Defer/Promise对象都是天生“绝”配。链状的执行，其实是前一个promise注册的回调与下一个defer的resolve/reject尾首向触发的过程。</p><p>这里也只是拿多个异步任务回调粗略的描述了一下，在项目中用的最多的then链形式，还是一个异步触发多个顺序回调处理而已，由于其从第一个then回调开始就直接return“确定内容的对象”，后续 promise 状态及入参判断简单，这里对于这样情况就不再描述。</p>]]></content>
      
      
      <categories>
          
          <category> AngularJS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AngularJS </tag>
            
            <tag> Promise </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaScript 启示录总结</title>
      <link href="/2015/11/24/javascript-qi-shi-lu-zong-jie/"/>
      <url>/2015/11/24/javascript-qi-shi-lu-zong-jie/</url>
      
        <content type="html"><![CDATA[<p>JavaScript1.5版本，相当于ECMAScript第三版。</p><hr><p>1. 创建复杂对象（非原始对象）的三种方式：</p><ul><li>new Object（首先创建出的是无预定义属性或者方法的空对象）</li></ul><pre class="line-numbers language-none"><code class="language-none">var&nbsp;codyA&nbsp;=&nbsp;new&nbsp;Object();codyA.name&nbsp;=&nbsp;'张三';<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>构造器</li></ul><pre class="line-numbers language-none"><code class="language-none">var&nbsp;Person&nbsp;=&nbsp;function&nbsp;(name)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;this.name&nbsp;=&nbsp;name;&nbsp;&nbsp;&nbsp;&nbsp;},&nbsp;&nbsp;&nbsp;&nbsp;codyB&nbsp;=&nbsp;new&nbsp;Person('张三');<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ul><li>字面量</li></ul><pre class="line-numbers language-none"><code class="language-none">var&nbsp;codyC&nbsp;=&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;"张三"};<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>三种方式，构造器方式中构造函数可以当成一个强大、集中定义的对象“工厂”，可用于复用来创建更多的Person对象。</p><p>* 为自定义对象创建自定义构造函数的同时，也为Person()实例创建了原型继承；使用字面量来构造，会避开了原型继承的使用。</p><p>2. new</p><p>构造函数只是一个函数，除非使用关键字new来调用。</p><p>JavaScript给予的动作：</p><ul><li><p>将该函数的this值设置为正在构建的新对象</p></li><li><p>默认返回新创建的对象，即返回this（新对象被认为是构建该对象的构造函数的实例，即Person()的实例）</p></li></ul><p>注意：</p><ul><li><p>构造函数名首字母大写</p></li><li><p>如果不使用new来调用构造函数，this将指向包装该函数的“父”对象。</p></li></ul><p>3. JavaScript内置（或者叫预包装）了9个原生对象构造函数：Number()、String()、Boolean()、Object()、Array()、Function()、Date()、RegExp()、Error()。</p><p>JavaScript又叫“预包装若干原生对象构造函数的语言” —— JavaScript主要是由这9个对象以及 原始值（布尔、数字、字符串）来创建。</p><p>注意：Math对象是静态对象，不是构造函数，只是一个对象命名空间，用于存储数学函数。</p><p>4. 原始值（字符串、数字、布尔）与String()、Number()、Boolean()。原始值还有null、undefined等。</p><p>原始值皆不为对象。原始值特殊之处在于表示简单值，很多时候作为不可再细化的进行复制和操作。</p><p>字符串、数字、布尔&nbsp;有其对应的包装构造函数。应<strong>尽量使用原始值</strong>：</p><ul><li><p>typeof “a” =&gt; “string”，而typeof (new String(‘b’)) =&gt; “object”</p></li><li><p>在原始值被视为对象的情况下才会创建实际的复杂对象。如“a”.length在使用时，JS会在幕后为字面量创建一个包装器对象，以便将该值被视为一个对象。调用方法以后，JS即抛弃包装对象，该值返回字面量类型。</p></li><li><p>原始值的constructor属性，会显示其包装对象的构造函数String()、Number()、Boolean()</p></li><li><p>String(‘test’)\Number(‘10’)\Boolean(‘true’)也可以获取原始值，注意前面没有new。</p><p>由此可见，<strong>JavaScript中所有东西都用成对象</strong>，而非那句“JavaScript中所有东西都是对象”。</p></li></ul><p>5. 字面量是JavaScript提供的一种快捷方式，使用字面量创建对象与构造函数方式基本相同，除了字符串、数字、布尔字面量。</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;myNumber&nbsp;=&nbsp;123,&nbsp;&nbsp;myString&nbsp;=&nbsp;'hello',&nbsp;&nbsp;myBoolean&nbsp;=&nbsp;true,&nbsp;&nbsp;myObject&nbsp;=&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;'Jack'&nbsp;&nbsp;},&nbsp;&nbsp;myArray&nbsp;=&nbsp;['foo',&nbsp;'bar'],&nbsp;&nbsp;myFunction&nbsp;=&nbsp;function(x,&nbsp;y)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;x&nbsp;+&nbsp;y;&nbsp;&nbsp;},&nbsp;&nbsp;myRegExp&nbsp;=&nbsp;/\b[a-z]+\b/;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>6. 原始值null、undefined</p><p>两者没有包装类型构造函数。</p><p>可以用null来显式指出对象属性不包含值。</p><p>undefined两种方式：1、声明的变量未初始化；2、试图访问的对象没有被定义（即还没被命名），并且不存在于原型链中。</p><p>只允许JavaScript使用undefined是一种很好的方法。永远不要将一个值设置为undefined。如果制定一个属性或变量值不可用，应该使用null。</p><p>7. === 与 ==</p><p>尽量不要都不要使用==，== 会自动执行类型转换。</p><p>=== 比较原始值时，是进行值比较。对复杂对象进行比较时，是进行对象引用比较，可理解为比较的是对象引用地址的值，只有当操作符两端是同一个对象时才为true。</p><p></p><p>8. typeof</p><p>typeof返回正在使用值的类型。</p><pre class="line-numbers language-none"><code class="language-none">console.log(typeof&nbsp;null);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//object&nbsp;&nbsp;&nbsp;&nbsp;!!console.log(typeof&nbsp;undefined);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//undefined&nbsp;!!console.log(typeof&nbsp;123);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//numberconsole.log(typeof&nbsp;'hello');&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//stringconsole.log(typeof&nbsp;true);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//booleanconsole.log(typeof&nbsp;(new&nbsp;Number(123)));&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//objectconsole.log(typeof&nbsp;(new&nbsp;Boolean(true)));&nbsp;&nbsp;&nbsp;&nbsp;//objectconsole.log(typeof&nbsp;(new&nbsp;String('hello')));&nbsp;&nbsp;//objectconsole.log(typeof&nbsp;(new&nbsp;Object()));&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//objectconsole.log(typeof&nbsp;(new&nbsp;Array('foo',&nbsp;'bar')));&nbsp;//objectconsole.log(typeof&nbsp;(new&nbsp;Function("x",&nbsp;"y",&nbsp;"return&nbsp;x&nbsp;+&nbsp;y")));&nbsp;//function&nbsp;&nbsp;!!console.log(typeof&nbsp;(new&nbsp;Date()));&nbsp;//objectconsole.log(typeof&nbsp;(new&nbsp;RegExp('\\b[a-z]+\\b')));&nbsp;//objectconsole.log(typeof&nbsp;(new&nbsp;Error('Crap!')));&nbsp;//object<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>9. 构造函数生成的对象实例</p><ul><li>拥有指向其构造函数的constructor属性</li></ul><pre class="line-numbers language-none"><code class="language-none">function&nbsp;Test(){&nbsp;&nbsp;this.name&nbsp;=&nbsp;"zhangsan";}var&nbsp;a&nbsp;=&nbsp;{},&nbsp;&nbsp;B&nbsp;=&nbsp;function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;this.name&nbsp;=&nbsp;"Jack";&nbsp;&nbsp;},&nbsp;&nbsp;d&nbsp;=&nbsp;new&nbsp;B(),&nbsp;&nbsp;&nbsp;&nbsp;e&nbsp;=&nbsp;new&nbsp;Test();console.log(a.constructor&nbsp;===&nbsp;Object);&nbsp;//trueconsole.log(d.constructor&nbsp;===&nbsp;B);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//trueconsole.log(e.constructor&nbsp;===&nbsp;Test);&nbsp;&nbsp;&nbsp;//true<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>可拥有自己的独立属性</li></ul><pre class="line-numbers language-none"><code class="language-none">var&nbsp;myString&nbsp;=&nbsp;new&nbsp;String('hello');myString.prop&nbsp;=&nbsp;'test';<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>源于JavaScript对象的动态属性特性，原始值无动态属性支持。</p><p>动态属性支持易变对象，因此甚至可以通过其来该院JavaScript本身原生对象的预配置特性，但不建议这样做。</p><p>即使Function对象也可以添加独立属性：</p><pre class="line-numbers language-none"><code class="language-none">function&nbsp;Test(){&nbsp;&nbsp;this.name&nbsp;=&nbsp;"zhangsan";}Test.go&nbsp;=&nbsp;"hello";console.log(Test.go);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>10. 可当做容器的复杂对象：Object()、Array()、Function(), 可以包含其他复杂对象。</p><p>注意Function并非指动态属性（此功能在Object()中），Function见下：</p><pre class="line-numbers language-none"><code class="language-none">function&nbsp;Test()&nbsp;{&nbsp;&nbsp;var&nbsp;getTest&nbsp;=&nbsp;function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;get&nbsp;=&nbsp;function(){&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//TODO&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;&nbsp;}}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>11. 获取、设置、更新对象属性</p><p>两种：点表示法、中括号表示法，尽量使用点表示法。</p><p>中括号表示法仅在：1、需要传递获取的属性名为变量； 2、使用关键字为属性名的情况。</p><p>同时，字面量声明对象时，属性名没必要使用为字符串，除非是下面几种情况: 1、是保留关键字；2、包含空格或者特殊字符；3、以数字开头。</p><p>12. delete操作符</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;test&nbsp;=&nbsp;{name:&nbsp;'Jack'};delete&nbsp;test.name;console.log(test.name);&nbsp;&nbsp;&nbsp;&nbsp;//undefined<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li><p>delete是将属性从一个对象删除的唯一方法。将属性设置为undefined或null只能改变属性的值，不会将属性从对象删除。</p></li><li><p>delete不会删除在原型链上找到的属性。</p></li></ul><p>13. 属性、方法的获取，以及原型链</p><p>如果试图访问对象中没有的属性、方法，JavaScript会试图使用 原型链来查找。</p><p>查找myArray.foo, 首先查找创建对象的构造函数(MyArray())，并检查器原型属性(MyArray.prototype)，然后会寻找另外两个位置：(Array.prototype，然后是Object.prototype)，对象的构造函数prototype对象上查找它。</p><p>例子：</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;myArray&nbsp;=&nbsp;['foo',&nbsp;'bar'];console.log(myArray.hasOwnProperty('join'));&nbsp;//输出false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>当 JavaScript创建Array构造函数时，join()方法等作为Array()原型属性的一个属性被添加。</p><ul><li>prototype属性是JavaScript为每一个Function()实例创建的一个对象。它将通过new关键字创建的对象实例链接回创建他们的构造函数。实例才可以共享或继承通用方法和属性。共享发生在<strong>属性查找</strong>时。</li></ul><p>JavaScript会为每个函数创建原型对象，不论是否是构造函数。</p><ul><li>所有函数都是由Function()构造函数创建的。当创建函数实例时，它总有一个prototype属性，它是一个<strong>空对象</strong>。</li></ul><pre class="line-numbers language-none"><code class="language-none">var&nbsp;myFunction&nbsp;=&nbsp;function(){};console.log(myFunction.prototype);&nbsp;//同{}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>当函数使用new关键字创建对象时，它都会在<strong>创建的实例对象</strong>和<strong>创建实例对象的构造函数的prototype属性</strong>之间添加一个隐性链接__proto__。这样就形成了原型链，原型链将每个实例都链接至其构造函数的prototype属性。</li></ul><p>如果需要使用__proto__属性，正确的写法是：myObject.constructor.prototype</p><p>原型链最后的是Object.prototype</p><ul><li>用新对象替换prototype属性会删除默认的构造函数属性。但是可以手动指定一个。</li></ul><pre class="line-numbers language-none"><code class="language-none">var&nbsp;Foo&nbsp;=&nbsp;function(){console.log('good');};Foo.prototype&nbsp;=&nbsp;{constructor:&nbsp;Foo};var&nbsp;fooInstance&nbsp;=&nbsp;new&nbsp;Foo();console.log(fooInstance.constructor&nbsp;===&nbsp;Foo);console.log(fooInstance.constructor);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>打印：</p><p>“good” &nbsp; true &nbsp;function(){console.log(‘good’);}</p><ul><li><p>prototype引用的对象是动态的，原型链查找出的内容也会是动态的。</p></li><li><p>用新对象替换prototype属性不会更新以前已创建的实例，因此一旦开始创建实例，就不应该在替换构造函数的原型属性。</p></li></ul><p>14. hasOwnProperty 和 in操作符</p><p>in操作符可以检查一个对象的属性，包括来自原型链的属性；</p><p>hasOwnProperty方法可以检查来自非原型链属性的对象。</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;myObject&nbsp;=&nbsp;{foo:&nbsp;'value'};console.log(myObject.hasOwnProperty('foo'));console.log(myObject.hasOwnProperty('toString'));console.log('toString'&nbsp;in&nbsp;myObject);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>for…in循环遍历对象的属性，并且只遍历可枚举的属性（即可用属性），例如构造函数属性就不会显示。可以使用obj.propertyIsEnumerable(prop)来检查可枚举属性。</p><p>注意：访问属性的顺序并不一定是定义的顺序。</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;cody&nbsp;=&nbsp;{&nbsp;&nbsp;age:&nbsp;23,&nbsp;&nbsp;gender:&nbsp;'male'};for&nbsp;(var&nbsp;key&nbsp;in&nbsp;cody)&nbsp;{&nbsp;&nbsp;//避免来自原型链的属性&nbsp;&nbsp;if&nbsp;(cody.hasOwnProperty(key))&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;console.log(key);&nbsp;&nbsp;}}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>15. 对象和函数</p><ul><li><p>Object（）创建出的实例，也可叫Object()对象实例，拥有的属性：constructor以及隐藏属性__proto__；实例方法：hasOwnProperty()等等。</p></li><li><p>Function() 函数属性：prototype, Function.prototype;&nbsp;Object（）这个函数具有属性：prototype, 即Object.prototype。</p><p>Function()对象实例属性：arguments、constructor(函数也是对象)、length；实例方法：call()、apply()等。</p></li></ul><p>所有的实例(new Object())都拥有constructor和__proto__属性。所有的函数(new Function())都有prototype属性。</p><p>16. 函数</p><p>函数是可执行语句的唯一作用域。函数总有返回值，如果没有指定返回值，默然返回undefined。</p><p>函数创建的三种方式：1. new Function(arg…, functionBody); 2. 函数表达式 var name = function(){}；3. 函数语句，字面量形式 function name(){};</p><p>new方式少用，原因同eval()。</p><p>函数的使用：所有函数体中，this和arguments都是可用的。</p><p><strong>arguments</strong>：即使在函数定义中不指定参数，如果在调用时发送了参数，还是可以依靠arguments来访问参数。</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;add&nbsp;=&nbsp;function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;arguments[0]&nbsp;+&nbsp;arguments[1];}console.log(add(3,&nbsp;4));<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>arguments对象拥有名为callee的属性，是对当前执行函数的引用。当函数需要递归调用时，非常有用。</p><p><strong>this</strong>: 是对包含函数的对象的引用。如果不在对象中，this是全局对象，浏览器是window。</p><p><strong>length</strong>: 定义的参数数量（却不能直接使用），用法arguments.callee.length。argments也有一个length属性, Javascript1.4开始废弃，不同处是 调用时属性的长度。</p><p>使用4中不同的场景或模式调用函数：</p><ul><li><p>作为函数(仅作为函数调用，this会被指向head对象)</p></li><li><p>作为方法（在对象中）</p></li><li><p>作为构造函数</p></li><li><p>使用apply（）或者call（）</p></li></ul><p>apply与call的区别是参数传递的不同:</p><pre class="line-numbers language-none"><code class="language-none">function&nbsp;print(text,&nbsp;extra)&nbsp;{&nbsp;&nbsp;console.log(this.name&nbsp;+&nbsp;text&nbsp;+&nbsp;extra);}var&nbsp;zhang&nbsp;=&nbsp;{&nbsp;&nbsp;name:&nbsp;'zhang'};print.apply(zhang,&nbsp;['&nbsp;good',&nbsp;'&nbsp;morning']);print.call(zhang,&nbsp;'&nbsp;nice',&nbsp;'&nbsp;day');<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>自调用的匿名函数，需要使用括号，或者任何将函数转化成表达式的符号。</p><pre class="line-numbers language-none"><code class="language-none">(function&nbsp;(msg){&nbsp;&nbsp;console.log(msg);}('Hello'));var&nbsp;a&nbsp;=&nbsp;function&nbsp;(msg){&nbsp;&nbsp;console.log(msg);&nbsp;&nbsp;return&nbsp;'ok';}('Hello');<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>函数可以嵌套，并且嵌套的深度是没有限制的。但<strong>嵌套函数的this值是head对象</strong>。</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;test&nbsp;=&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;'Jack',&nbsp;&nbsp;&nbsp;&nbsp;say:&nbsp;function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;name&nbsp;=&nbsp;function(){&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;this.name;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;};&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;console.log('hello&nbsp;'&nbsp;+&nbsp;name());&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;&nbsp;},&nbsp;&nbsp;name&nbsp;=&nbsp;'head';test.say();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>**自动提升：**在真正定义函数语句之前，可以在执行时调用该语句。因为在运行代码之前，函数语句已经被编译器解释，并添加至执行堆栈、上下文中。</p><p>注意：只有“函数语句”形式的被提升，“函数表达式”的函数不会提升。</p><p>17. head/全局对象</p><p>JavaScript代码本身必须包含在对象内部，如Web浏览器环境中，JavaScript被包含在window对象内，并且在其内部执行，这个window对象被认为是“head对象”。</p><p><strong>head对象</strong>是JavaScript环境中可用的最高作用域/上下文。</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;myStringVar&nbsp;=&nbsp;'myString';console.log('myStringVar'&nbsp;in&nbsp;window);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>**“全局对象”**是指直接包含在head对象内部的值。如上myStringVar就是一个全局对象，是head对象的一个属性。</p><p>head对象内的<strong>全局函数</strong>（JavaScript附带的一些预定义函数）：parseInt()\parseFloat()\decodeURI()\decodeURIComponent()\encodeURI()\encodeURIComponent()\eval()\isFinite()\isNaN()</p><p><strong>引用head对象</strong>：1、使用head对象的名称（如浏览器中，是window）； 2、在全局作用域中使用this关键字；</p><p>但一般head对象是隐式的，通常不显示引用(除非命名太简单易被遮盖住)。同时，性能方面alert()比window.alert()代价要低。（即使我们知道想要的属性在全局作用域中，但如果只依靠作用域离链，并避免显式地引用head对象，会更快）</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;foo&nbsp;=&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;method:&nbsp;function(text)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;alert('nice&nbsp;'&nbsp;+&nbsp;text);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;window.alert('good&nbsp;'&nbsp;+&nbsp;window.text);&nbsp;//想访问text遮盖中的全局text变量&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;&nbsp;},&nbsp;&nbsp;text&nbsp;=&nbsp;'zhang';foo.method('li');<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>18. this</p><p>创建函数时，系统会创建一个名为this的关键字，它链接到运行该函数的对象。或者说是链接到执行上下文中。</p><p>除了new关键字和call()\apply()的情况例外：</p><ul><li><p>new调用构造函数时，this引用“即将调用的对象”；</p></li><li><p>call\apply会使用context对象改写this值。say.call(context, args…)</p></li></ul><pre class="line-numbers language-none"><code class="language-none">var&nbsp;myObject&nbsp;=&nbsp;{name:&nbsp;'zhang'},&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;=&nbsp;'li',&nbsp;&nbsp;&nbsp;&nbsp;sayHello&nbsp;=&nbsp;function(){&nbsp;&nbsp;console.log('hello&nbsp;'&nbsp;+&nbsp;this.name);};myObject.sayHello&nbsp;=&nbsp;sayHello;myObject.sayHello();sayHello();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>打印：“hello zhang” “hello li”</p><p>**&nbsp;&nbsp;&nbsp;&nbsp;在传递函数或者有多个函数的引用<strong>时，要意识到this值会根据调用函数所在的上下文而改变。除了</strong>this<strong>和</strong>arguments**之外所有变量都遵守“词法作用域”规则。</p><p>在嵌套函数中this关键字引用head对象，ES5中开始固定规定。即当this值的寄主函数被封装在另一个函数的内部或者在另一个函数的上下文中调用时，this将永远指向head对象的引用。</p><p>可以充分利用作用域链来避免this被改写。</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;myObject&nbsp;=&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;'zhang',&nbsp;&nbsp;&nbsp;&nbsp;say:&nbsp;function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;that&nbsp;=&nbsp;this;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(function&nbsp;helper()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;console.log(that.name);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;console.log(this.name);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;})();&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;&nbsp;},&nbsp;&nbsp;name&nbsp;=&nbsp;'win';myObject.say();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>打印: “zhang” “win”</p><p>原型方法内的this关键字引用构造函数实例。当在prototype对象中的方法内部使用this关键字时，this可用于引用实例。如果实例中不包含要查找的属性，则使用原型链查找。</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;Person&nbsp;=&nbsp;function(name){&nbsp;&nbsp;if(name){&nbsp;&nbsp;&nbsp;this.name&nbsp;=&nbsp;name;&nbsp;&nbsp;&nbsp;}};Person.prototype.sayHello&nbsp;=&nbsp;function(){&nbsp;&nbsp;console.log('hello&nbsp;'&nbsp;+&nbsp;this.name);};var&nbsp;zhang&nbsp;=&nbsp;new&nbsp;Person('zhang');zhang.sayHello();Object.prototype.name&nbsp;=&nbsp;'default';var&nbsp;d&nbsp;=&nbsp;new&nbsp;Person();d.sayHello();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>19. 作用域</p><p>JavaScript作用域有三种：全局作用域、局部作用域（函数作用域）和eval作用域。</p><ul><li><p>全局作用域是作用域链中的最高层/最后一个</p></li><li><p>包含函数的函数，会创建堆栈执行作用域。又叫作用域栈。</p></li><li><p>JavaScript没有块级作用域。</p></li></ul><p><strong>作用域链（词法作用域）</strong></p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;x&nbsp;=&nbsp;10,&nbsp;&nbsp;foo&nbsp;=&nbsp;function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;y&nbsp;=&nbsp;20;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;function()&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;z&nbsp;=&nbsp;30;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;console.log(x&nbsp;+&nbsp;y&nbsp;+&nbsp;z);&nbsp;&nbsp;&nbsp;&nbsp;};&nbsp;&nbsp;};var&nbsp;y&nbsp;=&nbsp;500;foo()();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>打印：60</p><p>y在解释时就已经绑定。即<strong>函数定义时确定作用域，而非调用时确定，作用域链是根据函数定义时的位置确定的，也叫“词法作用域”</strong>。与this、arguments区分开。</p><p>作用域链式基于代码的编写方式创建的，而不是基于调用函数所在的上下文。这使得函数即使从一个不同的上下文调用函数，也能够访问最初编写代码时所在的作用域，这被称为“<strong>闭包</strong>”。</p><p>20. Array()</p><p>创建数组的两种形式：1、new Array(length) 2、[element1, element2,…]</p><p>第一种预定义数组的长度，并且每个元素都是undefined。</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;myArray&nbsp;=&nbsp;[];myArray[50]&nbsp;=&nbsp;'blue';console.log(myArray.length);&nbsp;&nbsp;&nbsp;&nbsp;//51,50之前的元素都是undefined填充<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>可以通过设置数组长度来来添加或删除值。</p><p>21. 0、-0、null、false、 NaN、undefined和空字符串（“”）外的任何有效JavaScript值都将被转换为true。</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;falseBoolean&nbsp;=&nbsp;new&nbsp;Boolean(false);console.log(falseBoolean);if(falseBoolean){&nbsp;&nbsp;&nbsp;&nbsp;//即使是false的布尔对象，实际上是true对象&nbsp;&nbsp;console.log('falseBoolean&nbsp;is&nbsp;truthy');}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> JavaScript </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在使用AngularJS的过程中了解Promise（一）</title>
      <link href="/2015/11/16/zai-shi-yong-angularjs-de-guo-cheng-zhong-liao-jie-promise/"/>
      <url>/2015/11/16/zai-shi-yong-angularjs-de-guo-cheng-zhong-liao-jie-promise/</url>
      
        <content type="html"><![CDATA[<p>好吧，我承认最近的确在重新学浏览器端的技术。OMG，刚入行的时候我就觉得最糟心的浏览器端语言 —— 心中一直想要回避的区域，并且NB前端工程师需要克服种种与后端工程师属性不和的区域（跨浏览器跨设备、标准不统一、JS单线程下的效率与工作流程、UI风格美不美位置准不准确等等等等），对于我这种不关心审美也没多少耐心厌恶无标准的死板后台工程师来说，心中一直只想说：请放过我。</p><p>最近在做一个AngularJS的项目，其致力于前后端分离、提供前端模板、标准web页面组件等等，在其中遇见了一个Promise，才发现脱离前端关注已经很久了，不知不觉中前端也在不断往前发展。废话就不多说了，后面是自己使用部分的一点总结。</p><hr><p>Promise来自于Promise/A+，CommonJS指定规范。解决JS中的回调地狱和异步调用。</p><h3 id="Promise简单使用">Promise简单使用</h3><p>抛开AngularJS实现的源码不说的话，使用Promise其实主要分为两部分：deferred和promise 两个对象。</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;deferred&nbsp;=&nbsp;$q.defer();deferred.promise.then(function(){&nbsp;&nbsp;console.log('hello');});deferred.resolve();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>"defer"英文单词“延迟”，"promise"给予“承诺”。</p><p>promise是deffered的一个属性，带有最主要的then方法，用于注册三类回调函数：successCallBack/errorCallBack/notificationCallBack，并且生成一个新的promise。</p><p>而deferred的三个方法，分别针对于出发这三类回调的发生：resolve()/reject()/notify().</p><p>而一个延迟任务，resolve()/reject()只能二选一进行触发。</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;deferred&nbsp;=&nbsp;$q.defer();var&nbsp;promise&nbsp;=&nbsp;deferred.promise;promise.then(function&nbsp;success(data)&nbsp;{&nbsp;&nbsp;console.log(data);},function&nbsp;error(reason)&nbsp;{&nbsp;&nbsp;console.error(reason);},function&nbsp;notification(progress)&nbsp;{&nbsp;&nbsp;console.info(progress);});var&nbsp;progress&nbsp;=&nbsp;0;var&nbsp;interval&nbsp;=&nbsp;$interval(function()&nbsp;{&nbsp;&nbsp;if&nbsp;(progress&nbsp;&gt;=&nbsp;100)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;$interval.cancel(interval);&nbsp;&nbsp;&nbsp;&nbsp;deferred.resolve('All&nbsp;done!');&nbsp;&nbsp;}&nbsp;&nbsp;progress&nbsp;+=&nbsp;10;&nbsp;&nbsp;deferred.notify(progress&nbsp;+&nbsp;'%...');&nbsp;&nbsp;},&nbsp;100);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在我看来deferred就像由它生出的promise这颗炸弹的遥控器，deferred按下resolve()按钮，successCallBack被调用；或者按下reject()按钮，errorCallBack被调用；延迟加载中，notify()触发notificationCallBack。</p><p>这个比喻虽然形象，但是其实并不能很好的概括promise的所有功能。比如：参数的传递。</p><p>resolve(result) -&gt; function successCallBack(result){}</p><p>reject(reason) -&gt; function&nbsp;errorCallBack(reason){}</p><p>notify(progress) -&gt; function&nbsp;notificationCallBack(progress){}</p><p>参数对象可以为普通对象也可以为promise对象，如果为promise，效果同链式向下传递。</p><h3 id="Promise链式使用">Promise链式使用</h3><p>promise对象是可以使用多个then方法连续调用的，即链式书写调用。</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;deferred&nbsp;=&nbsp;$q.defer();var&nbsp;promise&nbsp;=&nbsp;deferred.promise;&nbsp;&nbsp;promise.then(function(val)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;console.log(val);&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;'B+';&nbsp;&nbsp;},&nbsp;function(val)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;console.log(val);&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;'B-';&nbsp;&nbsp;})&nbsp;&nbsp;.then(function(val)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;console.log(val);&nbsp;&nbsp;&nbsp;},&nbsp;function(val){&nbsp;&nbsp;&nbsp;&nbsp;console.log('I&nbsp;only&nbsp;want&nbsp;to&nbsp;see&nbsp;who&nbsp;will&nbsp;execute&nbsp;here');&nbsp;&nbsp;});deferred.resolve('A+');//deferred.reject('A-');<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>resolve(‘A+’)时，将打印：A+，B+</p><p>reject(‘A-’)时，将打印：A-，B-</p><p>这里需要注意的是reject(),reject()仅负责第一层then的触发。第一层then的successCallBack\errorCallBack成功执行后（无error发生），则自动触发下一层promise.then对应的resolve()方法。</p><p>所以上例中需要reject(‘A-’)时，想要打印出：A-，I only want to see who will execute here。则需要</p><pre class="line-numbers language-none"><code class="language-none">var&nbsp;deferred&nbsp;=&nbsp;$q.defer();var&nbsp;promise&nbsp;=&nbsp;deferred.promise;&nbsp;&nbsp;promise.then(function(val)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;console.log(val);&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;'B+';&nbsp;&nbsp;},&nbsp;function(val)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;console.log(val);&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;"this&nbsp;is&nbsp;error";&nbsp;&nbsp;})&nbsp;&nbsp;.then(function(val)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;console.log(val);&nbsp;&nbsp;&nbsp;},&nbsp;function(val){&nbsp;&nbsp;&nbsp;&nbsp;console.log('I&nbsp;only&nbsp;want&nbsp;to&nbsp;see&nbsp;who&nbsp;will&nbsp;execute&nbsp;here');&nbsp;&nbsp;&nbsp;&nbsp;console.log(val);&nbsp;&nbsp;});&nbsp;&nbsp;deferred.reject('A-');<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>打印结果：</p><pre class="line-numbers language-none"><code class="language-none">Athis&nbsp;is&nbsp;errorI&nbsp;only&nbsp;want&nbsp;to&nbsp;see&nbsp;who&nbsp;will&nbsp;execute&nbsp;herethis&nbsp;is&nbsp;error<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>error被打印，但任务未中断。</p><pre class="line-numbers language-none"><code class="language-none">&nbsp;&nbsp;var&nbsp;defer1&nbsp;=&nbsp;$q.defer(),&nbsp;&nbsp;&nbsp;&nbsp;defer2&nbsp;=&nbsp;$q.defer(),&nbsp;&nbsp;&nbsp;&nbsp;promise1&nbsp;=&nbsp;defer1.promise,&nbsp;&nbsp;&nbsp;&nbsp;promise2&nbsp;=&nbsp;defer2.promise;&nbsp;&nbsp;promise1.then(function(val)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;console.log("I'm&nbsp;promise1&nbsp;success");&nbsp;&nbsp;&nbsp;&nbsp;console.log(val);&nbsp;&nbsp;},&nbsp;function(reason)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;console.log("I'm&nbsp;promise1&nbsp;error");&nbsp;&nbsp;});&nbsp;&nbsp;var&nbsp;promise3&nbsp;=&nbsp;promise2.then(function(val)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;console.log("I'm&nbsp;promise2&nbsp;success"&nbsp;+&nbsp;val);&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;'2';&nbsp;&nbsp;}).then(function(val){&nbsp;&nbsp;&nbsp;&nbsp;console.log("I'm&nbsp;promise2&nbsp;success"&nbsp;+&nbsp;val);&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;'3';&nbsp;&nbsp;}).then(function(val){&nbsp;&nbsp;&nbsp;&nbsp;console.log("I'm&nbsp;promise2&nbsp;success"&nbsp;+&nbsp;val);&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;'4';&nbsp;&nbsp;});&nbsp;&nbsp;&nbsp;&nbsp;defer1.resolve(promise3);&nbsp;&nbsp;defer2.resolve('1');<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>打印：</p><pre class="line-numbers language-none"><code class="language-none">I'm&nbsp;promise2&nbsp;success1I'm&nbsp;promise2&nbsp;success2I'm&nbsp;promise2&nbsp;success3I'm&nbsp;promise1&nbsp;success4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里refer.resolve参数即为一个promise，所以defer1.promise上注册的回调会在promise3已知的回调执行完以后在进行调用。</p>]]></content>
      
      
      <categories>
          
          <category> AngularJS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AngularJS </tag>
            
            <tag> Promise </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
