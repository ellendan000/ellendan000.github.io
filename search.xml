<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>使用Gradio&amp;huggingface快速搭建一个ChatGPT APP</title>
      <link href="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/"/>
      <url>/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/</url>
      
        <content type="html"><![CDATA[<p>在现在的NLP领域，GPT系列模型已经成为了NLP领域的标配之一，而ChatGPT是基于GPT的一个聊天模型，可以用来生成对话，其效果非常好，可以说是目前最好的开源聊天模型了。<br>不少使用者已经将ChatGPT当做了日常工作的助手，下面这个chat界面基本已经广为人知。<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/chatGPT_conversation.png" alt="ChatGPT会话界面"></p><p>但 ChatGPT 并不仅仅是支持以上的聊天会话功能，OpenAI 公司也开放了以上会话聊天背后的 API。</p><span id="more"></span><p>这些 API 可以直接调用，使用命令行（科学上网），也可以自己搭建服务器。<br>如果仅仅只是想使用 API 构建一个会话服务，或者 Generic 聊天机器人，专门搭建一个服务器没有什么特别大的意义。<br>但如果从学习和尝试构建 ChatGPT 应用的角度、从上手程度来衡量的话，Gradio + huggingface 不失为一种快速构建的方式。<br>Gradio 是一个可以快速搭建一个Python web的工具包，Huggingface 支持源码管理、 Gradio 应用的快速构建和部署。</p><h3 id="1-使用-ChatGPT-API-编程">1. 使用 ChatGPT API 编程</h3><h4 id="1-1-Python-OpenAI-lib-下载和安装">1.1 Python OpenAI lib 下载和安装</h4><p>在新建的工程目录下，安装 openAI lib。</p><pre class="line-numbers language-none"><code class="language-none">$ pipenv install openai# 或者使用 pip 工具安装，作者本人更偏爱 pipenv，因此 Python 文章里面都使用 pipenv 作为包管理和构建工具<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="1-2-针对-ChatGPT-API-编程">1.2 针对 ChatGPT API 编程</h4><p>在工程目录下编写Chatgpt工具文件<code>chatgpt_api.py</code>。</p><pre class="line-numbers language-none"><code class="language-none">class ChatgptAPI:    def __init__(self, api_key):        openai.api_key = api_key    def get_single_completion(self, prompt, model='gpt-3.5-turbo'):        messages = [{"role": "user", "content": prompt}]        response = openai.ChatCompletion.create(            model=model,            messages=messages,            temperature=0,            max_tokens=2048,            top_p=1,        )        return response.choices[0].message['content']<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>说明：</strong><br>提前创建OpenAI账号，生成API key（各种方法各显神通，这里不做赘述）。</p><p>在上面的代码中，我们使用了 OpenAI 提供的API，其中：</p><ul><li><code>openai.api_key</code> 需要赋值 OpenAI 官网上获取的 API key</li><li><code>openai.ChatCompletion.create</code>方法（背后就是 API Endpoint: /chat/completions）</li><li><code>gpt-3.5-turbo</code> 模型</li></ul><p>查阅过OpenAPI<a href="https://platform.openai.com/docs/api-reference/chat/create">官方文档</a>，可以发现，OpenAI 提供了多种模型，可以根据自己的需求进行选择。<br>同时，不同API，支持和兼容不同的模型。<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/model_endpoint_compatibility.png" alt="model endpoint compatibility"></p><p>GPT 4 版本以下，较推荐的两个模型，一个是 <code>gpt-3.5-turbo</code>，另一个是 <code>text-davinci-003</code>。<br>这两个模型的区别在于：gpt-3.5-turbo 是一个通用的模型，而 text-davinci-003 是一个专门用于文本生成的模型。<br>但 gpt-3.5-turbo 的价格只有 text-davinci-003 的 1/10, 同时响应速度也比 text-davinci-003 更快。<br>因此，gpt-3.5-turbo 是一个性能良好且相对经济实惠的GPT模型版本，适用于许多自然语言处理任务，它提供快速的响应时间和高质量的文本生成能力。<br>相比之下，Text-davinci-003 更适合对生成文本质量要求更高、且对响应时间要求相对较低的应用场景。</p><p><strong>下面是官方对于3.5版本的模型的对比</strong>：<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/models.png" alt="GPT-3.5 models"></p><h4 id="1-3-Max-Tokens">1.3 Max Tokens</h4><p>在上面的模型对比图中，会注意到有一个<code>Max Tokens</code>的概念。</p><ul><li>首先，Tokens 本身是文本处理时进行分词的最小单位，同时也是ChatGPT报价收费的最小单位。<br>比如，gpt-3.5-turbo 价格是 $0.002 / 1K tokens，text-davinci-003 则是 $0.0200 / 1K tokens。这种收费方式看起来，跟以太坊的 GAS 比较相像。</li><li>另外，模型中的 Max Tokens 是指，每次请求的最大 tokens 数量，也就是说，会限制文本的最大长度。<br>但需要注意的是：每次请求的Max Tokens = User 请求的Tokens + AI assistant 响应的Tokens。也就意味着，如果用户请求的文本长度过长，受Max Tokens的限制，留给AI生成的 Token数量会很少，从而导致请求失败。</li></ul><p>因此，对于用户而言，Max Tokens 的限制会造成两方面的考虑：</p><ul><li>一次请求的最大文本长度，防止文本过长，造成请求失败。</li><li>处理多轮会话的策略。GPT API并不会帮助客户端缓存上下文，两次API请求之间是完全独立的，因此需要客户端自己来处理多轮会话的上下文。<br>每次请求的内容，都需要包含之前请求的文本上下文，受Max Tokens限制，对话轮数越多，请求中用户输入的文本占比就会越高，留给AI生成的Token余量就会越少。</li></ul><p>代码中针对这两项考虑，可做如下处理（且不限此方式）：</p><ul><li>设置API的 max_tokens参数，这里限制的是AI生成的Token最大数。除AI生成的Max Tokens外，请求 + 响应中总的 Max Tokens 受模型类型限制。</li><li>创建会话上下文类型（比如 Conversation），用以保存和传递多轮会话的上下文。</li></ul><pre class="line-numbers language-none"><code class="language-none">class ChatgptAPI:    ……    def get_multi_round_completion(self, prompt, conversation, model='gpt-3.5-turbo'):        conversation.append_question(prompt)        prompts = conversation.get_prompts()        response = openai.ChatCompletion.create(            model=model,            messages=prompts,            temperature=0,            max_tokens=2048,            top_p=1,        )        message = response.choices[0].message['content']        conversation.append_answer(message)        return message, conversationclass Conversation:    def __init__(self, system_prompt='', num_of_round = 5):        self.num_of_round = num_of_round        self.history = []        self.initialized = False        self.history.append({"role": "system", "content": system_prompt})        if len(system_prompt) &gt; 0:            logger.info(f'Conversation initialized with system prompt: {system_prompt}')            self.initialized = True    def is_initialized(self):        return self.initialized        def append_question(self, question):        self.history.append({"role": "user", "content": question})    def append_answer(self, answer):        self.history.append({"role": "assistant", "content": answer})        if len(self.history) &gt; self.num_of_round * 2:            del self.history[1:3]    def clear(self):        self.history.clear()        self.initialized = False    def get_prompts(self):        return self.history        def round_size(self):        return 0 if len(self.history) &lt; 2 else len(self.hitory) - 1        def get_history_messages(self):        return [(u['content'], b['content']) for u,b in zip(self.history[1::2], self.history[2::2])]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里，我们将用户的请求文本和AI assistant的响应文本，都缓存到了<code>Conversation</code>类中。在每次请求时，将 Conversaction 中缓存的文本作为<code>prompt</code>传入，从而实现多轮会话的功能。<br>同时，我们还可以在<code>Conversation</code>类中增加一些其他的方法，比如设置缓存的最大轮数，超过最大轮数则从缓存中删除最早的会话记录。</p><h3 id="2-使用-Gradio-框架构建交互层">2. 使用 Gradio 框架构建交互层</h3><p>使用 Gradio 框架，可以快速构建一个交互式的Web应用，直接使用 Python 创建前端页面和交互。</p><h4 id="2-1-安装-Gradio">2.1 安装 Gradio</h4><p>在工程目录下，继续安装 Gradio lib 包。</p><pre class="line-numbers language-none"><code class="language-none">$ pipenv install gradio<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="2-2-编写-Web-代码">2.2 编写 Web 代码</h4><p>在工程目录下，创建一个名为<code>app.py</code>的文件，用于编写 Web 代码。</p><pre class="line-numbers language-none"><code class="language-none">import loggingimport osimport gradio as grfrom tools.chatGPT_API import Conversation, ChatgptAPIchat_api = ChatgptAPI(os.environ.get("OPENAI_API_KEY"))def predict(system_input, password_input, user_input, conversation):    if password_input != os.environ.get("APP_PASSWORD"):       return [(None, "Wrong password!")], conversation, user_input    if conversation.is_initialized() == False:        conversation = Conversation(system_input, 5)    _, conversation = chat_api.get_multi_round_completion(user_input, conversation)    return conversation.get_history_messages(), conversation, Nonedef clear_history(conversation):    conversation.clear()    return None, conversationwith gr.Blocks(css="#chatbot{height:350px} .overflow-y-auto{height:600px}") as demo:    chatbot = gr.Chatbot(elem_id="chatbot")    conversation = gr.State(value=Conversation())    with gr.Row():      system_in_txt = gr.Textbox(lines=1, label="System role content:", placeholder="Enter system role content")      password_in_txt = gr.Textbox(lines=1, label="Password:", placeholder="Enter password")           with gr.Row():      user_in_txt = gr.Textbox(lines=3, label="User role content:", placeholder="Enter text...").style(container=False)        with gr.Row():      submit_button = gr.Button("Submit")      reset_button = gr.Button("Reset")        submit_button.click(predict, [system_in_txt, password_in_txt, user_in_txt, conversation], [chatbot, conversation, user_in_txt])    reset_button.click(clear_history, [conversation], [chatbot, conversation], queue=False)demo.launch()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/Gradio_UI.png" alt="界面效果"><br><strong>说明:</strong><br>- 使用了 Gradio 的 Chatbot 组件，用于展示 User 请求文本和 AI assistant 的响应文本。<br>- 使用了 Gradio 的 State 组件，用于存储用户的 Conversaction 对象。<br>- 使用了 Gradio 的 Textbox 组件，用于用户输入系统提示文本、密码和请求文本。<br>- 使用了 Gradio 的 Button 组件，用于触发用户的请求。</p><p>详细 Gradio 入门可参考：<a href="https://gradio.app/getting_started">Gradio document</a></p><h3 id="3-提交和部署到-Huggingface">3. 提交和部署到 Huggingface</h3><h4 id="3-1-创建-Huggingface-Space">3.1 创建 Huggingface Space</h4><p>在 Huggingface 上创建 Space，步骤基本跟创建 Github 的Repository一样。<br>并且，需要选择 Space 部署时</p><ul><li>Space SDK：Gradio</li><li>Space Hardware：有免费的<code>CPU</code>和付费的<code>GPU</code>可选<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/create_space_in_hugging_face.png" alt="Create Space"></li></ul><h4 id="3-2-设置环境变量">3.2 设置环境变量</h4><p>在 Space 中，需要设置环境变量，用于存储 OpenAI API Key 和 Web App 的密码(为了防止后面App bublic之后，API Key 被滥用)。<br>Gradio 启动时，会从环境变量中加载这些值。<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/new_repository_secrets.png" alt="Set Environment Variables"></p><h4 id="3-3-提交代码到-Huggingface-Space">3.3 提交代码到 Huggingface Space</h4><p>选择将 Space 的 Repository 用 git clone 到本地，使用方法跟 Github 一样。<br>然后，将前面两节编写的代码通过 git push 到 Huggingface，Huggingface 会自动完成构建，并部署 Web App。<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/build_space.png" alt="build App"></p><p>构建完成以后，Web App 会直接显示在 Huggingface Space的页面上。<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/chat_web_app.png" alt="Chat Web App"></p><h4 id="3-4-设置-Space-visibility-Public">3.4 设置 Space visibility Public</h4><p>如果在创建 Space 时，选择了将 Visibility 设置为 Private，那么只有 Space 的 Owner 和 Collaborator 才能访问到 Web App。<br>同时，也没有办法通过该 Space 的 URL 访问到 App。</p><p>若是想要其他人能通过 Space 的 URL 访问到 Web App，或者需要将 App 嵌入其他网站进行访问时，则需要将 Visibility 设置为 Public。<br>在设置成了 Public 之后，Space 的菜单会出现<code>Embed this Space</code>。<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/embed_space.png" alt="Embed this Space"><br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/embed_space_2.png" alt="Embed this Space"></p><p>根据上图的提示，将<code>&lt;script&gt;</code>和<code>&lt;gradio-app&gt;</code>标签复制到其他网站的 HTML 中，即可嵌入到其他网站中。<br>效果见后面。</p><h3 id="4-成果展示">4. 成果展示</h3><script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/3.29.0/gradio.js"></script><p><gradio-app src="https://ellendan-chat-lab.hf.space"></gradio-app></p><p>App 的 Password Input 需要输入作者个人微信号的号码，欢迎大家试用。<br>同时，由于 GPT API 的调用，有 Rate limits, API 每分钟的调用次数有限制，所以可能会出现无法响应的情况。</p><ul><li><code>RPM</code> - request per minute</li><li><code>TPM</code> - token per minute<br><img src="/2023/05/17/shi-yong-gradio-huggingface-kuai-su-da-jian-yi-ge-chatgpt-app/rate_limits.png" alt="rate limits"></li></ul>]]></content>
      
      
      <categories>
          
          <category> ChatGPT </category>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ChatGPT </tag>
            
            <tag> Python </tag>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>反手回摸Oracle</title>
      <link href="/2022/08/22/fan-shou-hui-mo-oracle/"/>
      <url>/2022/08/22/fan-shou-hui-mo-oracle/</url>
      
        <content type="html"><![CDATA[<p>最后一次用 Oracle 应该还是在2012的时候，之后就一路用开源数据库。<br>没想到现在还有反手回摸的时候。<br>回摸也就算了，等准备好 Oracle 知识回顾，最后发现计划赶不上变化，暂时用不上了。<br>重新 review 了一把自己的kanban和计划清单，赶紧记录一下，回到目标的事务上去。</p><span id="more"></span><h3 id="1-MacOS-安装-Oracle">1. MacOS 安装 Oracle</h3><p>对于已经习惯了所有工具都要本地装一装、摸一摸的工程师而言，装个单例数据库这事儿自然不在话下。<br>然而search homebrew 和 dockerhub，突然发现 —— 居然没有oracle database。这不就尴尬了嘛？<br>去 Oracle 官网查看了一下，要想在 MacOS 上安装Oracle，两种方式：1. visualBox 2. 本地 dockerfile build。<br>那自然是选择2了。</p><h4 id="1-1-Oracle-官方dockerfile大合集">1.1. Oracle 官方dockerfile大合集</h4><p>访问 Oracle 官方在 github 上 repo <a href="https://github.com/oracle/docker-images">docker-images</a>。</p><pre class="line-numbers language-none"><code class="language-none">$ git clone git@github.com:oracle/docker-images.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>子目录是 Oracle 各种产品目录。比如database，就是 <code>OracleDatabase</code>, OGG 就是 <code>OracleGoldenGate</code>。</p><h4 id="1-2-查看-dockerfile">1.2. 查看 dockerfile</h4><p>进入到本地 repo 目录 <code>OracleDatabase/SingleInstance/dockerfiles</code>，可以看到目前支持的数据库版本：<br><img src="/2022/08/22/fan-shou-hui-mo-oracle/dockerfile_list.png" alt="dockerfile_list"><br>选择一个版本，比如 19.3.0，进入目录。</p><h4 id="1-3-下载-Linux-Oracle-Database-程序包">1.3. 下载 Linux Oracle Database 程序包</h4><p>可以查找官网，也可以通过 readme 文件上的链接跳入下载页面。<br>点击链接，手动下载。<br><img src="/2022/08/22/fan-shou-hui-mo-oracle/oracle_download_page.png" alt="download_page"><br>对，2.8G。</p><h4 id="1-4-将下载的database程序包移入OracleDatabase-SingleInstance-dockerfiles-19-3-0">1.4. 将下载的database程序包移入<code>OracleDatabase/SingleInstance/dockerfiles/19.3.0/</code></h4><p><img src="/2022/08/22/fan-shou-hui-mo-oracle/zip_into_directory.png" alt="zip into directory"></p><h4 id="1-5-运行buildContainerImage">1.5. 运行buildContainerImage</h4><p>回到<code>OracleDatabase/SingleInstance/dockerfiles</code>目录，运行命令<code>buildContainerImage.sh</code>。</p><pre class="line-numbers language-none"><code class="language-none">$ ./buildContainerImage.sh -h$ ./buildContainerImage.sh -v 19.3.0 -s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><em>注意</em> 运行命令build之前，确保本地没有开启任何网络代理，不然 build 时会失败。<br>build成功之后，通过<code>docker images</code>查看image，总大小6个多G，体量感人。。</p><p>另外，如果想要安装其他版本，比如18.4.0 和 xe 版本，相同的步骤和方式，但可能需要修改dockerfile的部分语句。<br>即使进行了dockerfile修改，xe 版本本人build并没有成功过，这个需要再次检验和查看。</p><h4 id="1-6-docker-run">1.6. docker run</h4><pre class="line-numbers language-none"><code class="language-none">docker run --name oracle19 -d -p 11521:1521 -p 15500:5500 -e ORACLE_PWD=123456 -v ~/tmp-oradata:/opt/oracle/oradata oracle/database/19.3.0-se2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这时候，通过docker host本地 11521 端口，就可以连接docker oracle了。</p><h3 id="2-Oracle-Database-基础概念和语句图谱">2. Oracle Database 基础概念和语句图谱</h3><div class="markmap-container" style="height:800px">  <svg data="{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[0,1]},&quot;v&quot;:&quot;Oracle Database&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[1,2]},&quot;v&quot;:&quot;数据库概念&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[2,3]},&quot;v&quot;:&quot;数据库&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[3,4]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[4,5]},&quot;v&quot;:&quot;查看当前数据库：select name from V$DATABASE;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[5,6]},&quot;v&quot;:&quot;数据库实例&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[6,7]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[7,8]},&quot;v&quot;:&quot;查看当前数据库实例：select name from V$INSTANCE;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[8,9]},&quot;v&quot;:&quot;SID&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[9,10]},&quot;v&quot;:&quot;CDB &amp;amp; PDB&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[10,11]},&quot;v&quot;:&quot;SQLPLUS&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[11,12]},&quot;v&quot;:&quot;tnsnames.ora&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[12,13]},&quot;v&quot;:&quot;sqlnet.ora&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[13,14]},&quot;v&quot;:&quot;连接&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[14,15]},&quot;v&quot;:&quot;sqlplus username/password@host:port/SID&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[15,16]},&quot;v&quot;:&quot;conn username/password&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[16,17]},&quot;v&quot;:&quot;用户/角色/权限&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[17,18]},&quot;v&quot;:&quot;用户&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[18,19]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[19,20]},&quot;v&quot;:&quot;创建用户：create user ogg identified by ogg default tablespace customer;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[20,21]},&quot;v&quot;:&quot;查询用户：select * from dba_users where lower(username)=‘ogg';&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[21,22]},&quot;v&quot;:&quot;删除用户：drop user ogg;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[22,23]},&quot;v&quot;:&quot;角色&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[23,24]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[24,25]},&quot;v&quot;:&quot;创建角色：create role etl;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[25,26]},&quot;v&quot;:&quot;查询角色：select * from DBA_ROLES;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[26,27]},&quot;v&quot;:&quot;角色授权（系统）：grant connect,resource,create session, alter session to etl;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[27,28]},&quot;v&quot;:&quot;角色授权（对象）：grant insert,update,delete on t_custmer to etl;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[28,29]},&quot;v&quot;:&quot;给用户添加角色：grant etl01 to ogg;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[29,30]},&quot;v&quot;:&quot;删除角色：drop role etl;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[30,31]},&quot;v&quot;:&quot;权限&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[31,32]},&quot;v&quot;:&quot;定义&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[32,33]},&quot;v&quot;:&quot;系统权限&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[33,34]},&quot;v&quot;:&quot;对象权限：指用户对已有对象的操作权限。&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[34,35]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[35,36]},&quot;v&quot;:&quot;系统权限&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[36,37]},&quot;v&quot;:&quot;查询系统权限：select distinct PRIVILEGE from DBA_SYS_PRIVS;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[37,38]},&quot;v&quot;:&quot;查询grantee拥有的权限：select * from DBA_SYS_PRIVS where lower(grantee)='ogg’;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[38,39]},&quot;v&quot;:&quot;给用户添加权限：grant create session,alter session to ogg;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[39,40]},&quot;v&quot;:&quot;收回权限：revoke alter session from ogg;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[40,41]},&quot;v&quot;:&quot;对象权限&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[41,42]},&quot;v&quot;:&quot;查询grantee用户的对象权限：select grantee, table_name, privilege from dba_tab_privs where lower(grantee) = ‘ogg’;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[42,43]},&quot;v&quot;:&quot;分配对象权限：grant all on t_employees to ogg;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[43,44]},&quot;v&quot;:&quot;收回权限：revoke delete on t_employees from ogg;&quot;}]}]}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[44,45]},&quot;v&quot;:&quot;逻辑结构&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[45,46]},&quot;v&quot;:&quot;数据库/表空间/表&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[46,47]},&quot;v&quot;:&quot;数据库&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[47,48]},&quot;v&quot;:&quot;SQL&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[48,49]},&quot;v&quot;:&quot;表空间&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[49,50]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[50,51]},&quot;v&quot;:&quot;创建表空间：CREATE TABLESPACE customer datafile '/opt/oracle/oradata/XE/customer.dbf' SIZE 100M autoextend on next 20M Maxsize 500M;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[51,52]},&quot;v&quot;:&quot;删除表空间：drop tablespace customer including contents and datafiles;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[52,53]},&quot;v&quot;:&quot;查看表空间数据文件：select file_name, tablespace_name from DBA_DATA_FILES order by FILE_NAME;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[53,54]},&quot;v&quot;:&quot;查看所有表空间：SELECT TABLESPACE_NAME, STATUS, ALLOCATION_TYPE, CONTENTS FROM DBA_TABLESPACES;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[54,55]},&quot;v&quot;:&quot;表&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[55,56]},&quot;v&quot;:&quot;用户/schema/对象&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[56,57]},&quot;v&quot;:&quot;用户&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[57,58]},&quot;v&quot;:&quot;SYS/SYSTEM&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[58,59]},&quot;v&quot;:&quot;SYS 是 SYSDBA。可创建数据库。&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[59,60]},&quot;v&quot;:&quot;SYSTEM 是 SYSOPER。权限次之。&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[60,61]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[61,62]},&quot;v&quot;:&quot;查看当前库下所有用户：select username,ACCOUNT_STATUS,DEFAULT_TABLESPACE, TEMPORARY_TABLESPACE from DBA_USERS;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[62,63]},&quot;v&quot;:&quot;schema&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[63,64]},&quot;v&quot;:&quot;定义&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[64,65]},&quot;v&quot;:&quot;Schema 是用户拥有的所有对象的集合。对象包括：表、索引、视图等等。&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[65,66]},&quot;v&quot;:&quot;每个用户都会有独立的schema，schema 必须依赖用户的存在而存在。&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:10,&quot;p&quot;:{&quot;lines&quot;:[66,67]},&quot;v&quot;:&quot;SQL&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:12,&quot;p&quot;:{&quot;lines&quot;:[67,68]},&quot;v&quot;:&quot;查询当前用户和schema：select sys_context('userenv', 'current_user') current_user, sys_context('userenv', 'current_user') current_schema from dual;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[68,69]},&quot;v&quot;:&quot;对象&quot;}]}]}]}"></svg></div>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>聊聊研发效能治理方案的理论框架（下篇）</title>
      <link href="/2022/07/18/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-xia-pian/"/>
      <url>/2022/07/18/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-xia-pian/</url>
      
        <content type="html"><![CDATA[<p>已经过了一旬，下篇居然还没开始动笔。<br>反思了一下人生：P<br>书接上回。</p><span id="more"></span><h3 id="2-接上篇">2. 接上篇</h3><p>在上一节的健康度指标中，有非常重要的一项 —— Lead Time。<br>Lead Time 的定义来源于传统制造业，指从受订到出货之间间隔的时间。<br>同时，与Lead Time 一同被提起的，还有<code>"Cycle Time"</code>。 而 DevOps 的度量指标，习惯称其为<code>“Process time”</code>。<br>Cycle Time 和 Process Time, 在软件研发和 DevOps 领域基本相互等同，主要指去掉排队等待时长，处于生产任务（增值活动）执行的时长。</p><p>一定要谈下区别的话，对 DevOps 工具自动化来说，基本每个环节的执行动作都是可重复的、标准的，因此“单件”的 Process time 基本可以代表当前任务的生产性能。<br>位于 DevOps 之前的研发环节，每件制品包含知识类的创造、不是标准件、无法准确重复，因此在统计任务时长时（比如：In Dev processing, in QA processing）, 只能通过“多件”运算出均值，亦就是 Cycle time.<br><img src="/2022/07/18/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-xia-pian/lead&amp;cycle_time.png" alt="lead Time &amp; cycle time"></p><p>Lead Time 和 Cycle Time 是精益制造中重要的衡量指标。<br>自从精益生产在制造业获得成功之后，为了改善产品开发流程，软件研发行业也将精益思想引入到了产品研发之中。</p><h4 id="2-2-价值流分析和改进建议">2.2. 价值流分析和改进建议</h4><p>从研发效能来看，除了宏观的 lead time 的健康度之外，想要回答 lead time 为何会花费这么长时间、具体那些环节比较耗时、是否可以优化耗时时，就需要将研发工作流程打开来看一看。<br>想要理解和观察研发流程，有一个重要工具，就是 —— 价值流图（Value Stream Mapping， VSM）。</p><p>软件研发流程，是从需求构想到产品（或功能）发布上线的这个过程中，为了提供用户价值而采取的一系列研发活动。<br>价值流图，就是用来观察和分析价值在研发流程中流动的情况。<br>价值在整个流动的过程中，会经历增值活动、非增值但必要的活动（I型浪费）、以及非增值可以去掉的活动（II型浪费）。价值流图分析的目的，首先就是去掉 II 型浪费，然后再将 I 型浪费转化为 II 型浪费从而消除。<br><img src="/2022/07/18/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-xia-pian/vsm.png" alt="VSM"></p><p><em>也许有人会认为，上图中 QA 进行测试、Ops 进行发布，这些怎么能看做是增值行为呢？这主要是因为，不能只是从代码即是生产的角度去看待软件研发。<br>软件研发，其实是一种知识型的创造活动，虽然这些知识最终是通过代码的形式固化下来的。这种知识性的创造活动，包括PO、BA、Dev、QA、Ops所有角色的知识汇总。<br>这也是为何敏捷测试总是强调测试左移的重要性 —— 在需求分析或者 Feature kick off 阶段，QA 尽早参与到知识汇集的阶段，也可以降低 Dev 的返工率。即使是处于“开发”下游的“功能测试”，也可以从提供自动化测试代码的视角，察觉到测试的增值贡献 —— 让代码制品拥有了自动化测试代码。</em></p><p>正如图中显示，黄色标签为 I 型浪费，红色为 II 型浪费，比如“等待型浪费” —— 等待联调， “返工型浪费” —— 改 Bug。<br>那如何实施消除浪费呢？比如上面的等待联调、联调后的bug返工修复。<br>没有标准答案，但大体有如下思路：</p><ol><li>当前后端等待联调，团队的Dev是否可以发展成全栈工程师，这样前后端一个Dev就直接完成了，不存在联调。既消除了联调等待，也降低了返工率。</li><li>如果不发展全栈工程师，在story开始阶段，前后端是否可以一起设计和约定好契约（包括happy path、unhappy path、异常处理），由契约DSL上传到contract Mock server，这样可以降低联调成本和返工率。</li></ol><h4 id="2-3-敏捷-DevOps团队能力建设">2.3. 敏捷 &amp; DevOps团队能力建设</h4><p>有了前面两步治理成熟度的达成：度量评估和价值流分析，对研发效能有了不同维度整体的了解之后，接着就进入到治理动作的实施中。<br>建议使用带有整体优化能力的理论和实践框架 —— 敏捷 &amp; DevOps。这些理论和实践已经被反复验证，并且非常成熟。</p><p>敏捷，鼓励创建研发的全功能团队，提升交流和互动，以尽早和持续的交付高价值的软件为目标。一些团队甚至还鼓励成员打破角色边界，比如身兼 QA 能力的 Dev、具备 ops 能力的 Dev 等等。在这个阶段，基于Scrum、Kanban软件研发模式的普及，持续交付理念（Continuous Delivery, Jez Humble 提到的宏观角度的持续交付）也越来越被重视。</p><p>到2009年，终于有人在借鉴敏捷和精益的基础上，创造了 DevOps 这个词，旨在强调将 Ops 加入到产品研发全功能团队的充分必要性，并且兼顾开发思维、实行 infra as code的运维方式和方法，旨在提升产品交付效率和可靠性。</p><p>随着 DevOps 运动的兴起和推广， DevOps 逐渐发展，包括和涵盖了方法论、流程、自动化工具，以及特别强调的 DevOps 文化，并且逐渐影响到了整个研发价值流的参与者们遵循 DevOps 精神进行群策群力。<br>比如：Sec、QA 将安全和测试脚本加入Pipeline —— 不需要等到环境验证，在build运行的过程中就可以快速反馈到Dev，进行代码修复。</p><p>《凤凰项目》在DevOps原则，总结了三步工作法：</p><ul><li>流动原则。实现开发到运维的工作快速地从左往右流动。</li><li>反馈原则。从右往左的每个阶段中，应持续、快速地获得工作反馈。</li><li>持续学习和实验原则。团队建立持续学习和实践的文化。</li></ul><p><img src="/2022/07/18/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-xia-pian/three-steps-method.png" alt="三步法"></p><p>因此，团队针对敏捷 &amp; DevOps 进行能力建设，可以从整体优化的角度对效能进行治理和提升。<br>在具备了敏捷 &amp; DevOps 能力下，再去探索局部优化和治理。</p><h4 id="2-4-交付和运营方式转变">2.4. 交付和运营方式转变</h4><p>在敏捷 &amp; DevOps 团队具备稳定和高效地研发效率、高质量、降低了发布成本和发布风险后，让原本正确、但看起来不可实现地交付和运营方式变得可能：</p><ul><li>系统3~6个月一次大批量发布上线 <code>--&gt;</code> 每个月/甚至更短周期 小批量发布上线</li><li>由需求批量压入迭代的 Scrum 研发管理模式 <code>--&gt;</code> 需求拉动的 Kanban 研发管理模式</li><li>DevOps 2.0、持续交付2.0 逐渐实现。</li></ul><p>研发效能被提及，其目标是快速验证产品、获取用户反馈的能力，位于行业前台的系统的快速推出，还能带来抢占市场的机会。<br>因此，交付和运营方式的转变，在完成治理成熟度3之后，必要、且可顺势而行。</p><h4 id="2-5-共享的、自助的研发运营XXX一体化平台">2.5. 共享的、自助的研发运营XXX一体化平台</h4><p>也许有人会奇怪，在达成前 4 步效能成熟度之后，第 5 阶次的成熟度居然是推出 研发运营XXX一体化平台？（XXX可能是业务运营等等，反正随着 DevOps 2.0、持续交付2.0、bizDevOps这些相似概念的提出，大家旨在将产品的从概念到投入用户群体，这其中正向、反向的活动都组成一个闭环的整体）<br>将研发运营XXX一体化平台放在效能治理成熟度最后一步的逻辑是：</p><ul><li>即使不依托一体化平台，循序前四个成熟度治理，效能治理也可以在不同的企业和组织中开展。</li><li>当团队达成前四步治理成熟度，可以考虑将局部优化转化成全局优化。借助研发运营XXX一体化平台，对企业和组织内的全局优化事半功倍。</li><li>研发运营XXX一体化平台，说白了，只是一个工具，投入需要大成本。如果没有前四步成熟度的认知和达成，它也仅仅只是个工具。</li></ul><h3 id="3-总结">3. 总结</h3><p>研发效能治理方案的理论框架，基本到这里就阐述完了。<br>总结一下，就是：</p><ul><li>先度量和评估，再价值流分析</li><li>敏捷 &amp; DevOps 团队能力建设</li><li>交付和运营模式转变</li><li>推出 共享的、自助的研发运营XXX一体化平台</li></ul><h3 id="后话">后话</h3><p>在我写完（上篇）的时候，一些朋友表达了对国内越来越看重“研发效能”、“研发效能治理”这些命题和观点的不满，我其实也一样。<br>但是国内这方面的对软件定制和咨询的商机，又的确会经常出现。从我们这些公司的角度，就会去想 —— 是跪着把这钱给赚了，还是站着把这钱给赚了的问题。我自己也一直没有结论。<br>直到最近我在做一个售前方案的时候，跟公司内的一个咨询师交流，发现他对于“研发效能”这词的排斥。我内心颇有点恼，因为他讲的那些其实大家都心知肚明，反而我好像变成那个不道德和狭隘的一方。<br>因此，对于赚钱的问题，有了结论 —— 那就站着把钱给赚了吧，以后就只谈 价值交付、持续交付 2.0、DevOps。</p><p>不管怎样，立Flag后第二篇文章，总算是完成了，yeah~</p>]]></content>
      
      
      <categories>
          
          <category> 敏捷精益软件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 精益 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>聊聊研发效能治理方案的理论框架（上篇）</title>
      <link href="/2022/07/02/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-shang-pian/"/>
      <url>/2022/07/02/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-shang-pian/</url>
      
        <content type="html"><![CDATA[<p>最近几年，国内业界越来越常提及<code>“研发效能”</code>这个词，追其根源大部分是始于<code>“DevOps”</code>运动的活跃。<br>知道 DevOps 发展历史的，基本都了解 DevOps 是受敏捷的影响，是敏捷原则在软件研发到运维运营层面的延伸。<br>很多云厂商在推广自己 DevOps 平台服务的时候，也会提及对<code>“研发效能”</code>的大幅度影响，比如 AWS 对 DevOps 的描述：</p><blockquote><p>DevOps is the combination of cultural philosophies, practices, and tools that increases an organization’s ability to deliver applications and services at high velocity: evolving and improving products at a faster pace than organizations using traditional software development and infrastructure management processes. This speed enables organizations to better serve their customers and compete more effectively in the market.</p></blockquote><p>那么，研发效能 == DevOps 吗？<br>答案自然是否定 。</p><span id="more"></span><p>研发效能 明显是“问题域”。<br>DevOps 是一种解决方案，且是一种已经被验证、非常成熟的、可以提升软件研发效能的解决方案。<br>但就像人感冒发烧一样，吃 A 药可以痊愈，吃 B 药也可以痊愈，打针也可以痊愈，甚至有时候发现吃药效果不理想，最后还是去打了针。<br><code>研发效能低</code>，就像人感冒发烧一样，是个 “问题” 。<code>DevOps</code>, 是解决这个问题的一种 “药”。</p><p>因此，弄清楚了<code>问题域</code>和<code>解空间</code>的关系之后，我们来看看研发效能和它的解空间，并且主要聊一聊解空间（研发效能治理）。</p><h3 id="1-研发效能的定义">1. 研发效能的定义</h3><p>研发效能，即持续快速交付价值的能力。<br>将其拆解一下：<code>研发效能</code> = <code>效率</code> + <code>质量</code>+ <code>有效价值</code>，还有这三项可重复和稳定发生的<code>持续性</code>。</p><p>展开来讲，就是</p><ul><li>要在保证系统可靠性、不降低交付质量的情况下，尽量缩短从业务构想到功能上线的时间  （质量 + 效率）</li><li>从而使“最小化可行需求”能快速被验证，确保有效价值，减少浪费  （有效价值）</li><li>且整个过程效果可重复发生（持续性）</li></ul><h3 id="2-研发效能的治理">2. 研发效能的治理</h3><p>有了定义之后，就来看看如何对研发效能进行治理。<br>根据市面上大部分公司的软件工程能力状况，针对研发效能治理，这里提炼了一条“研发效能治理成熟度模型”。</p><p><img src="/2022/07/02/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-shang-pian/%E6%B2%BB%E7%90%86%E6%88%90%E7%86%9F%E5%BA%A6%E6%9B%B2%E7%BA%BF.png" alt="研发效能治理成熟度"><br>从左至右，研发效能治理分为5个阶段，每个阶段也必须包含它左边所有阶段的成果。<br>举个例子：某IT部门采购了一个 DevOps 平台服务，但日常仅仅当做 CI/CD流水线 甚至是“发布工具”来使用，对效能治理没什么概念，这时候该IT部门的治理成熟度自然是低的，可能只在“度量和评估”的位置。</p><p>接着，展开来看看效能治理成熟度每一个阶段。</p><h4 id="2-1-度量和评估">2.1. 度量和评估</h4><p>管理学之父彼得德鲁克曾经说过：“如果你无法度量它，就无法管理它”。<br>对管理如此，对效能治理亦是如此。因此，度量和评估，对于研发效能的治理必不可少。</p><p>那么，再来看看为何把“度量和评估”放在治理的第一步呢：</p><ul><li>首先，想要对研发效能进行治理，必须知道当前效能处于一个什么阶段，对现状有了度量评估和自我认知之后，才能明确之后治理的方向和力度。</li><li>同时，度量和评估模型在持续治理的过程中，可以阶段性地重复使用，用以呈现治理成果的效果和进行快速反馈。</li></ul><p>因此，度量和评估，作为研发效能治理的第一步不可或缺。</p><p><strong>接着，来看看如何做度量和评估？</strong><br><strong>从 “健康度指标” 和 “局部诊断性指标” 分两层来看。</strong></p><h5 id="健康度指标">健康度指标</h5><p>首先，借鉴于<code>DORA</code>(DevOps研究和评估组织) 的2021年报告中的Four Key Metrics，将其作为研发效能的4个关键 <strong><code>健康度指标</code></strong>:</p><p><img src="/2022/07/02/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-shang-pian/four_key_metrics.png" alt="four key metrics"></p><ul><li><strong>研发效率</strong>：<ul><li>部署频率</li><li>前置时间（Lead time）</li></ul></li><li><strong>研发质量</strong>：<ul><li>故障恢复时间 （MTTR）</li><li>部署失败率</li></ul></li></ul><p><code>特别注意</code>：区别于 DevOps 只关注于“从代码提交到功能发布”这个区间的前置时间，研发效能中的“前置时间”延伸了覆盖范围 —— 从业务构想到功能发布，涉及研发运营的整个研发周期。<br>其他三项，与 DevOps 报告相同。</p><p>至于，研发效能中的__<code>有效价值</code>__，其与业务关系紧密，度量数据模型需要根据具体业务来设计，因此目前仅给予该项 <code>健康度评估模型</code>：</p><blockquote><p>Measurement involves collecting factual information about the value of a deployed feature and evaluating it against the original hypothesis statement.<br>Rate your team’s ability to collect objective information about the actual value realized by deployed features so that it can inform strategic financial decisions.<br>Sit (1-2): We don’t define or measure the value of Features.<br>Crawl (3-4): We’ve defined what “value” is but don’t know how to measure it.<br>Walk (5-6): We capture qualitative feedback from the business about the value of our Features.<br>Run (7-8): We capture qualitative and quantitative feedback from the business and our monitoring systems about the value of our features.<br>Fly (9-10): We aggregate the quantitative and qualitative feedback to objectively validate the original hypothesis and inform pivot-or-persevere decisions.</p></blockquote><p>看到这里，是不是有点眼熟，如果原本预想的解决方案是 “DevOps一体化” 的话，加上有效价值的度量，是不是方案就要考虑<code>"BizDevOps"</code>?! 是不是仅仅一个DevOps的方案就不够匹配了？（重新再正视一下问题域和解空间的区别 :P）</p><h5 id="局部诊断性指标">局部诊断性指标</h5><p>也许有人会觉得，对比下其他类型的度量和评估报告上繁多的指标量，上面这几个指标未免有些简陋。<br>比如，连常见的评估应用架构维度的指标都没有。<br>其实，应用架构指标是有的，但并不属于效能“健康度指标”，而是“局部诊断性指标”。</p><ul><li>当发现健康度不理想，需要分析、定位和形成改进建议时，这时就要借助于局部诊断性指标。</li><li>当实施了改进建议，对局部指标进行了优化，最终效果又会传导到健康度指标上。<br>如果局部指标改进了，但健康度未提升，这时可能需要回过头来分析和反思一下：是诊断和改进建议的问题，还是本身局部指标需要调整。</li></ul><p><img src="/2022/07/02/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-shang-pian/%E5%B1%80%E9%83%A8%E8%AF%8A%E6%96%AD%E6%80%A7%E6%8C%87%E6%A0%87.png" alt="局部诊断性指标示例"></p><p>有了这两层指标，整个研发效能的度量和评估模型才大体完整。<br>而在整个研发的过程中，可以常常阶段性的使用模型进行度量和评估一下，比如每次发布周期完成 或者 每次sprint完成的时候等等。<br>使用指标值的时候，也需要注意：<strong>指标值本身并不重要，重要的是通过数据驱动出洞见。而在持续改进的过程中，数据趋势比数据值更重要。</strong></p><p><img src="/2022/07/02/liao-liao-yan-fa-xiao-neng-zhi-li-fang-an-de-li-lun-kuang-jia-shang-pian/key_metrics_report.png" alt="趋势图"></p><p>《下篇》讲接着聊剩下的4个成熟度阶段。</p>]]></content>
      
      
      <categories>
          
          <category> 敏捷精益软件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 精益 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库的ACID和分布式事务</title>
      <link href="/2022/05/10/shu-ju-ku-de-acid-he-fen-bu-shi-shi-wu/"/>
      <url>/2022/05/10/shu-ju-ku-de-acid-he-fen-bu-shi-shi-wu/</url>
      
        <content type="html"><![CDATA[<p>前面写了一篇关于<code>CAP原理</code>的博文，说到<code>一致性 Consistency</code>，有人往往会想到事务<code>ACID</code>特性中的<code>C: Consistency</code>，虽然都叫一致性，但完全是两个东西。</p><ul><li><code>CAP</code>的一致性指：数据库的同一复制集（replicaSet）之间数据相同。<br><em>这里的“数据库”，可以是主从、主备、集群架构，但没有单机架构。</em></li><li><code>ACID</code>的一致性指：在数据库单一实例中(暂不涉及多个数据源的分布式事务)，成功写入的数据不违反已定义的数据规则，如约束、级联规则等等。<br>接着，来通过本地事务的详细说一下<code>ACID</code>，以及跨多数据源的分布式事务。</li></ul><span id="more"></span><h3 id="1-本地事务ACID">1. 本地事务ACID</h3><p><code>本地事务</code>，这里指单个业务服务仅操作单一数据源，完全由 DBMS 提供的事务能力。<br>除去上面对<code>Consistency</code>的解释外，剩下的三项：</p><ul><li><code>Atomic(原子性)</code>：在事务边界内的所有写操作，要么一起成功，要么一起失败(也叫 All-or-Nothing）。<br>阻止出现只有部分更新的数据异常。</li><li><code>Isolation(隔离性)</code>：存在并发的情况下，不同的连接的读、写操作相互之间独立，尽量不受影响。<br>从低到高分为四个隔离级别：<code>Read uncommitted</code>、<code>Read committed</code>、<code>Repeatable read</code>、<code>Serializable</code>。各数据库厂商实现方式不同，造成标准的表现性有些许差别。比如 MySQL InnoDB采用 MVCC 机制实现事务隔离，Repeatable read 级别可以防止幻读。</li><li><code>Durability(持久性)</code>：保证所有成功提交的数据都能正确被持久化，不会被丢失。</li></ul><h3 id="跨多数据源的分布式事务">跨多数据源的分布式事务</h3><p><strong>（未完待续）</strong></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式架构必须重视的CAP理论</title>
      <link href="/2022/05/03/fen-bu-shi-jia-gou-bi-xu-chong-shi-de-cap-li-lun/"/>
      <url>/2022/05/03/fen-bu-shi-jia-gou-bi-xu-chong-shi-de-cap-li-lun/</url>
      
        <content type="html"><![CDATA[<p>CAP定理，说起来程序员们应该耳熟能详：C(Consistency)、A(Availability)、P(Partition Tolerance)，构成在分布式数据存储中的“不可能三角”，三者只能保证其二。<br>来，再展开说说？这时候，多数人的回答就会是是而非，模棱两可。<br>也许不少应用级开发工程师觉得 —— 我又不自研集群数据库，也不开发云平台，没必要那么了解 CAP 理论。<br>那么，你开发的应用系统，是否使用了分布式架构呢？如果是，CAP 理论可以说是指导构建系统的技术理论基石之一，必须要重视起来。</p><span id="more"></span><h3 id="1-CAP-定理到底讲了什么">1. CAP 定理到底讲了什么?</h3><p>CAP 定理对分布式数据存储系统的特性进行高度抽象，提炼成了3个维度：</p><ul><li><p><code>Consistency 一致性</code>, 每一次读取操作，要么系统返回最新的数据写入值（无论读取到哪一个数据节点），要么返回系统错误。<br>这里的一致性，代表的强一致性、线性一致性（Linearizability）。</p></li><li><p><code>Availability 可用性</code>, 每一次读取操作都能获得系统的返回，但不保证返回的是最新的数据写入值。</p></li><li><p><code>Partition Tolerance 分区容错性</code>，当数据节点之间发生网络分区（包括网络丢包、连接中断阻塞等），系统仍然要继续工作。</p></li></ul><p>这其中的底层逻辑是：分布式数据存储各节点之间通过网络连接，在运行期间不可避免存在网络分区的风险。<br>当网络分区发生时，无论是节点之间的状态同步还是数据复制，都会发生异常，部分节点的数据滞留在过去时刻的某种状态。</p><p>而保证<code>分区容错性</code>，就是当发生网络分区异常时，整个系统仍然运行并继续工作，这时候提供的服务维度只可能在 Consistency 和 Availability 中保证一项：</p><ul><li><p>确保一致性，牺牲可用性。<br>系统会通过内部策略，自动修复集群，最终确保<code>Consistency</code>声明的强一致性。在自动修复完成之前，外部请求会返回系统出错或者超时。<br><img src="/2022/05/03/fen-bu-shi-jia-gou-bi-xu-chong-shi-de-cap-li-lun/CAP_CP.png" alt="CP"><br><em>上图简化了集群中的一些问题描述，比如共识算法至少需要三个节点。</em><br><em>当节点 2 与 节点 1 之间因为通讯异常，未能对 x 的值达成一致，此时外部请求读取 x 的值，系统将返回“系统出错”或者超时。</em></p></li><li><p>确保可用性，牺牲一致性。<br>系统在自动修复集群期间，没有达成数据一致性的各节点仍会对外及时响应，确保<code>Availability</code>声明的高可用性。<br><img src="/2022/05/03/fen-bu-shi-jia-gou-bi-xu-chong-shi-de-cap-li-lun/CAP_AP.png" alt="CP"></p></li></ul><p>以上，即是 CAP 理论中 CP 和 AP 的由来。<br>然而，在分布式数据存储架构中，虽然网络分区是不可回避的风险，但也不意味着系统任何时候都处于网络分区的状态之下。在没有发生网络分区的时候，CA 应该是主要状态。</p><p>有人也许会对此产生质疑：即使分布式集群一切运行正常，没有发生网络故障，但节点间的数据传输也需要时间、存在网络延时，不可能在未完成数据同步的中间状态下，既保证可用，又保证所有节点数据一致性。<br>是的，这种问法很对。<br>因此，针对 CAP 理论中的 C，一些专家解释：Consistency，是忽略数据复制延时的，是假设数据复制不存在延时的理论场景。</p><p>然而数据复制的延时，在现实分布式系统运行期间始终存在，因此这时无 <code>P</code> 的 <code>CA</code> 很难与现实进行相互映射，使用时可能会造成困扰，不如理解为:</p><ul><li><code>Consistency</code> 是包含正常水平的复制延时的，这部分延时会计算在响应时间中，而不算影响 <code>Availability</code>。而当达成一致性的处理时长超出这个正常水平，才算作影响 <code>Availability</code>。<br>当然，更好的解释，也许应该看下 <code>PACELC 理论</code>，可以对此场景进行补充。</li></ul><h3 id="2-CAP-的扩展：PACELC-理论">2. CAP 的扩展：PACELC 理论</h3><p>通过上面对<code>CAP 定理</code>的了解，可以总结为在分布式数据存储架构设计中，至少需要一条 baseline 策略，应对出现网络分区这种危险状况。<br><img src="/2022/05/03/fen-bu-shi-jia-gou-bi-xu-chong-shi-de-cap-li-lun/CAP.png" alt="CAP"></p><p>在没有出现网络分区、正常运行的系统状态下，CAP 理论中的 CA 可以达成，但<code>数据一致性</code>的状态、以及隐藏在达成该状态背后的<code>延时时长</code> —— 这两个现实系统中过于常见的维度，如一双在 CAP 定理中说不清、道不明、又无处安放的小手，又该如何衡量和取舍呢？</p><p>这时候，就可以看一下 <code>PACELE 理论</code>。<br><code>PACELE</code> 是 <code>CAP 理论</code> 的扩展， <code>PAC</code> 各字母同 <code>CAP 理论</code>， <code>E (Else)</code> 仅是连接词，<code>L (latency) </code>、<code>C (consistency)</code>。意思就是，当没有出现网络分区、系统正常运行时，<code>低延时</code>（低于数据达成一致所需的平均延时水平） 和 <code>数据一致性</code>，二者需要选择其一，不能同时保证。<br><img src="/2022/05/03/fen-bu-shi-jia-gou-bi-xu-chong-shi-de-cap-li-lun/PACELE.png" alt="PACELE"></p><p>当有了基于<code>CAP</code>扩展出的<code>PACELE</code>，个人觉得，分布式数据存储的特性架构描述才比较完整。<br>比如，MongoDB 集群的就是典型的 <code>PA/EC</code> 系统：在出现网络分区时，MongoDB 集群优先保证可用性，数据可能不是最新；在集群正常状态下，优先保证数据一致性。<br>这也就防止了用户一听到 AP 架构就造成的恐慌 —— 以为系统状态正常下，程序员仍需要大量编码、自己处理数据一致性的问题。</p><p>下图是<code>PACELE 理论</code>中的特性搭配图，（横轴是发生 P 时的A or C 选择，纵轴是没有发生 P 时对 C or L 的选择）：<br><img src="/2022/05/03/fen-bu-shi-jia-gou-bi-xu-chong-shi-de-cap-li-lun/PACELE_2.png" alt="PACELE"></p><h3 id="3-为什么做分布式架构要重视-CAP-理论？">3. 为什么做分布式架构要重视 CAP 理论？</h3><h4 id="3-1-对分布式应用架构有借鉴和指导作用">3.1. 对分布式应用架构有借鉴和指导作用</h4><p>当前主流的分布式应用架构如微服务架构，在领域微服务之间不可避免地存在数据复制，比如：服务边界内实体、同时也是其他微服务的值对象；采用 CQRS 模式构建微服务；使用事件驱动架构搭建微服务等等。<br>只要存在数据在不同服务之间的复制：</p><ul><li>当复制机制出现连通故障、阻塞、高延迟等（比如消息组件消息堆积等），都可以近似的理解为 <code>网络分区</code>， 当发生<code>网络分区</code>时，需要有对应策略，无论是优先保证<code>数据一致性</code>，还是优先<code>可用性</code>？</li><li>当复制机制正常，数据同步仍存在时间成本。这时候，是优先保证<code>数据一致性</code>，还是优先<code>低延时</code>？<br>虽然以上的 “数据一致性” 不一定是 CAP 中的 “线性一致性” 这种强一致性，但 CAP 理论的这种思考维度和框架，以及扩展出的分布式算法和实践，在分布式应用架构设计中，也有很强的借鉴和指导作用。</li></ul><h4 id="3-2-指导数据存储方案的选型">3.2. 指导数据存储方案的选型</h4><p>分布式应用架构，不可避免地会面临对各种数据存储产品的选型，除了根据应用业务特性以及存储/读/写维度性能的需求，提供容量扩展、高可用的集群特性，也是必不可少的一个考察维度。<br>比如，业务特性需要的是一个 PA/EC 特性的集群能力，PA/EL 特性的产品自然是不匹配需求的。</p><h4 id="3-3-帮助完善数据存储方案落地">3.3. 帮助完善数据存储方案落地</h4><p>前面提了集群数据库的选型，但离方案可落地仍有一段距离，需要完美适配应用的业务场景，可能除了正确执行客户端调用以外，还需要一些额外配置 或者 二次加工，才能达到某些特性目标。</p><p>比如 MongoDB 的 readConcern 和 writeConcern，没接触过 <code>Quorum NWR</code> 算法策略的人，可能无法快速意识到 —— MongoDB 即使在 <code>AP</code> 状态下，依然可以通过客户端配置 readConcern/writeConcern 有选择地达成数据强一致性。<br>而不了解 <code>Quorum NWR</code> 的，可能会舍近求远地设计出一些复杂度较高的自研策略。</p><h3 id="参考资料">参考资料</h3><p><a href="https://en.wikipedia.org/wiki/CAP_theorem">CAP理论维基百科及链接</a><br><a href="https://en.wikipedia.org/wiki/PACELC_theorem">PACELC理论维基百科及链接</a></p>]]></content>
      
      
      <categories>
          
          <category> 分布式架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重启</title>
      <link href="/2022/04/29/chong-qi/"/>
      <url>/2022/04/29/chong-qi/</url>
      
        <content type="html"><![CDATA[<p>最近回忆过往工作经历，发现以往知识经验、林林总总，所思所想胡乱堆积，没有整理成一套逻辑明了的结构纲要。<br>因此，予以记忆而言，效率不高，且没有关联的知识块容易遗忘；予以表达而言，易思维阻塞，前后逻辑不顺；予以认清知识本质而言，重复颇多，而且只见云雾不见青山。<br>所以，现觉得对自身的知识储备进行重构，迫在眉睫。<br>那么，有没有一种看起来比较靠谱的架构解决方案可以达到此目的呢？<br>重读《金字塔原理》之后，我觉得使用“金字塔结构”可以一试。</p><span id="more"></span><p><strong>为何使用“金字塔结构”有利于知识重构？</strong></p><ol><li>金字塔纵向的“疑问/回答式”结构，符合软件构建的思路——从意图推导方案，从问题域到解决方案域。</li><li>金字塔的纵向结构，将知识和思想进行了不同层次的抽象和汇总。</li><li>金字塔的横向结构，强调了同一个主题思想下的子思想项之间必须符合逻辑关系。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker JVM通用工具诊断指南</title>
      <link href="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/"/>
      <url>/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/</url>
      
        <content type="html"><![CDATA[<p>Docker container 和 JVM的问题诊断，从来都不是静态的，所有来源数据都是一个动态的过程。<br>一个时间点的快照数据、或者一个单一数据项的字面值，并不能充分进行上下文分析，而是需要一段时间内持续的观测和数据获取，然后在时间维度上的纵向对比、不同实例间的横向对比等等手段，最终定位问题。</p><p>如下图中，资源利用率 —— 可能是docker CPU/Mem、JVM CPU/Mem、磁盘/网络IO、线程数等等。</p><ul><li><p>图1：在时间段上，根据使用量和压力峰值的分布，资源空闲量充足，无资源利用率瓶颈；所有实例表现一致。<br>一般，图1 这种正常态会作为基准值来参考。</p></li><li><p>图2：随着压力峰值时的量变，资源利用率超过阈值（80%），但峰值过后，资源得到逐渐释放，利用率得到回落；所有实例表现一致。<br>面对这种压力超过阈值的情况，一般就是开源 或者 节流的解决方式：1. 增加资源额度；2. 分析资源的top customers, 优化代码，节省资源的使用。</p></li><li><p>图3：相同应用的不同实例中，有一个实例的利用率明显区别于其他实例。<br>面对这种情况，在确认负载均衡、部署设施都一致的情况下，需要拿取问题实例的容器内、JVM内的各项细节数据进行横向对比和分析。</p></li><li><p>图4：资源利用率与使用量和压力峰值不呈现直接的正相关关系；所有实例表现一致。<br>这种情况，需要拿取容器、JVM内的细节数据与基准状态（比如升级前的线上版本）进行纵向对比和分析。</p></li></ul><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-graph-trend.png" alt="资源利用率趋势图"></p><p>docker JVM出现性能问题时，一般会表现为以下几个方面：</p><ul><li>内存利用率高出阈值</li><li>CPU利用率高出阈值</li><li>整体性服务请求响应变慢 或 超时</li></ul><p>注：由于此篇指南对应线上部署环境的Docker JVM，除了线上监控工具提供的监视数据以外，涉及到图形化分析工具的使用方式都是离线分析，<br>并且不涉及各云特色的诊断工具。</p><h2 id="1-Docker-container-CPU-内存高">1. Docker container CPU / 内存高</h2><p>当发生docker container CPU / 内存高的情况，首先需要确认，是哪些进程在占用容器资源。除了JVM外，是否还有其他大量占用容器资源的进程？<br>如果系统没有接入性能监控平台，或者监控平台数据不直观时，可以在docker container内使用一些 Linux 命令。<br>推荐Linux工具和命令：</p><ul><li>top</li><li>iostat</li><li>vmstat</li></ul><h3 id="1-1-top工具">1.1 top工具</h3><p>top是Linux下常用的性能分析工具，能够实时显示系统中各进程的资源占用状况。</p><pre class="line-numbers language-none"><code class="language-none">$ top -c$ top -Hp &lt;pid&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>含义：</strong></p><ul><li>top 罗列出当前系统中的资源状况，以及进程数量、列表，并且实时刷新，<code>-c</code> 选项，显示完整的进程启动命令行。<br>top 监控支持交互的形式，具体操作查询linux top使用方法。</li><li>当获取到 <code>pid</code> 后，想要查看具体 pid 进程的资源消耗，以及进程内的线程列表，可使用<code>-Hp &lt;pid&gt;</code>。<br>H代表 lightweight，切换到此模式，所有Task显示的进程内的Thread数量，清单列表显示的线程清单。</li></ul><p><strong>注意：</strong><br>在docker中运行top命令时，<code>CPU%</code> 和 <code>MEM%</code> 是基于docker host物理机的“总CPU”和“总物理内存”的百分比。</p><h3 id="1-2-iostat工具">1.2 iostat工具</h3><p>iostat是I/O statistics的缩写，用来动态监控磁盘的活动。</p><pre class="line-numbers language-none"><code class="language-none">$ iostat -d -x -k 1 10<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>含义:</strong></p><ul><li><code>-d -x -k 1 10</code> 显示磁盘，显示详情，以KB为单位。1秒刷新一次，刷新10次后退出。</li></ul><p>确定了主要占用资源的进程后，针对不同的进程服务类型，使用不同的分析工具。<br>下面主要列举了Java JVM性能诊断。</p><h2 id="2-JVM-内存利用率高">2. JVM 内存利用率高</h2><h3 id="2-1-JVM-Memory分配现状">2.1 JVM Memory分配现状</h3><p>JDK自带的两个工具的用法：</p><ul><li><p><code>$ jmap -heap &lt;pid&gt;</code></p></li><li><p><code>$ jstat -gccapacity &lt;pid&gt;</code><br><code>$ jstat -gc &lt;pid&gt;</code></p></li></ul><h3 id="2-2-内存泄露">2.2 内存泄露</h3><p>在不存在内存分配问题的前提下，内存持续偏高时，首先需要排除是否是内存泄露。</p><p>如何确认是否存在内存泄露：</p><ul><li>查看HeapDumpOnOutOfMemoryError</li><li>查看GC状态</li><li>多次主动生成dump</li><li>分析工具 MAT / VisuaVM / JProfiler</li></ul><h4 id="2-2-1-HeapDumpOnOutOfMemoryError（内存溢出）">2.2.1 HeapDumpOnOutOfMemoryError（内存溢出）</h4><p>当程序运行过程中，申请对象内存超出剩余可用内存时，则会发生内存溢出异常。<br>存在内存溢出时，原因上有一定可能 —— 程序中存在内存泄露，对象被错误引用而造成始终无法释放、占据内存。</p><p>一般在生产环境的 <code>JVM Options</code> 的配置中，都会带有几个如下配置。（如果没有，务必添加）</p>  <pre class="line-numbers language-none"><code class="language-none">-XX:+HeapDumpOnOutOfMemoryError-XX:HeapDumpPath=/heapdump/out_of_memory_error/logs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>含义</strong>：</p><ul><li>在运行时发生 <code>OutOfMemoryError</code> 时，会输出heapdump文件，文件地址位于 <code>/heapdump/out_of_memory_error/logs</code> 此路径下。</li></ul><p>存在内存溢出时，根因不一定是存在内存泄露，也有可能是资源压力遭遇瓶颈。<br>程序在抛出 OutOfMemryError 时，message中会注明原因，比如<code>Java heap space</code> 等。<br>通俗来讲，JVM会抛出 OutOfMemryError 的内存区，不只是堆，一共包含堆、非堆（Metaspace）、堆外（直接内存）、栈四个部分。</p><p><strong>关键概念</strong>:<br>JVM内存结构划分：<br><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-mem.png" alt="JVM 内存划分"></p><p>实际上，除去上面6块以外，还有一个程序计数器。但程序计数器占用内存较少，并且不会抛出OutOfMemoryError，这里忽略。<br>当抛出OutOfMemoryError时，从程序日志中获取errorMessage，从而可以快速定位是哪块内存区域出现了问题。<br>在不存在内存溢出的情况下，内存长期居高不下，这时可以根据不同内存区域的内存使用率和回收率进行预判。<br>如：</p><ul><li>图一，堆内存的利用量高，造成CPU频繁GC。</li><li>图二，Metaspace 和 堆对内存利用量正常，同时CPU并无频繁GC。JVM 总内存利用量依然很高，这时需分析栈内存的占用情况。</li><li>图三，JVM 总内存利用量正常，CPU无频繁GC。在排除了非JVM之外的程序占用外，需分析直接内存的占用情况。</li></ul><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-mem-gc.png" alt="JVM GC趋势图"></p><h4 id="2-2-2-查看GC状态">2.2.2 查看GC状态</h4><p>查看GC状态，可以在没有OutOfMemoryError来源的情况下，快速定位<code>堆</code>和 <code>MetaSpace</code> 的内存使用量、回收效果、平均常驻容量等等，以此来推断内存对象在新生代、老生代和 MetaSpace 的用量和瓶颈。<br>一般在生产环境的<code>JVM Options</code> 的配置中，会带有如下几个GC配置。</p>  <pre class="line-numbers language-none"><code class="language-none">-XX:+UseGCLogFileRotation-XX:NumberOfGCLogFiles=10-XX:GCLogFileSize=100M-Xloggc:/heapdump/gc/logs/gc.log-XX:+PrintGCDetails-XX:+PrintGCDateStamps<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>前三行：GC日志每个文件大小：100M，最多保留10个文件，超出则使用替换覆盖的策略。</li><li><code>-Xloggc:/heapdump/gc/logs/gc.log</code> ，GC日志路径在<code>/heapdump/gc/logs/</code>文件夹下，文件名以<code>gc.log</code>为前缀。</li><li>后两行：打印GC时的详情，打印GC日志的时间戳。</li></ul><p>有了这些配置之后，JVM在启动之后，会输出GC日志。</p><blockquote><p>2020-12-04T17:13:17.280-0800: 22845.509: [GC (Allocation Failure) [PSYoungGen: 581178K-&gt;16640K(611840K)] 925472K-&gt;909807K(1511936K), 0.5084573 secs] [Times: user=0.36 sys=0.57, real=0.50 secs]</p><p>2020-12-04T17:13:17.789-0800: 22846.017: [Full GC (Ergonomics) [PSYoungGen: 16640K-&gt;16388K(611840K)] [ParOldGen: 893167K-&gt;892384K(1358336K)] 909807K-&gt;908773K(1970176K), [Metaspace: 44412K-&gt;44412K(1091584K)], 0.5756780 secs] [Times: user=2.70 sys=0.19, real=0.58 secs]</p></blockquote><p>其中最需注意的是，GC类型-原因、一次GC后内存回收的效果、GC时长。</p><ul><li><p><code>GC (Allocation Failure)</code>：GC类型 - Young GC，原因 - 内存分配失败。</p></li><li><p><code>PSYoungGen: 581178K-&gt;16640K(611840K)</code>：新生代从 581178K 降到 16640K，当前新生代总大小 611840K。</p></li><li><p><code>925472K-&gt;909807K(1511936K)</code>: 堆从 925472K 降到 909807K，当前堆总大小 1511936K。</p></li><li><p>此次GC执行时长0.5084573秒。此时间是物理感知的绝对时间，与后面的real相同。</p></li><li><p><code>Full GC (Ergonomics)</code> GC类型 - Full GC，原因 - 内存调整，具体由垃圾回收器类型决定。</p></li><li><p><code>ParOldGen: 893167K-&gt;892384K(1358336K)</code>: 老生代从 893167K 降到 892384K， 当前老生代总大小 1358336K。</p></li><li><p><code>909807K-&gt;908773K(1970176K)</code>: 堆从 909807K 降到 908773K，当前堆总大小 1970176K。</p></li><li><p><code>Metaspace: 44412K-&gt;44412K(1091584K)</code>: metaspace 从 44412K 无下降，当前 metaspace 总大小 1091584K。</p></li></ul><p>关键概念：</p><ul><li><p>垃圾回收器类型。<br>-XX:UseParallelGC 是JDK9之前server模式下的默认回收器，使用的是Parallel Scavenge +  ParOld 的收集器组合进行内存回收。<br>即新生代是GC多线程、标记-整理的GC算法，老生代是GC多线程、标记-整理的GC算法。<br>此款垃圾回收器，是以吞吐量为目的，即在执行垃圾回收工作的同时，尽量让应用系统被阻塞更短的时间。<br><code>吞吐量 = （运行用户代码的时间）/ (运行用户代码的时间 + 运行垃圾回收的时间)</code><br>同时，在CMS/G1之前的通用垃圾回收器，都有JVM申请内存之后不会归还给系统的问题。在CMS得到缓解，G1已经可以做到及时归还。</p></li><li><p>MinorGC（YoungGC）\ MajorGC(Full GC)。<br>Full GC 实际上可以对堆（新生代+老生代）、metaspace、直接内存都产生垃圾回收效果。特别是直接内存，虽然直接内存使用的是JVM外部的内存空间，但对象句柄引用最终是放在JVM堆中，因此在full GC释放掉堆内的对象引用时，也可以造成直接内存释放的效果。</p></li></ul><p>查看GC状态也不是仅看某个时间点的快照值就可得出问题结论，也需要沿着时间轴观察一段时间下的GC效果。<br>比如，上面的例子中，可以看到第二次Full GC几乎没有什么回收效果，背后可能是大量耗费内存的请求压力造成的，这时候就需要在压力峰值降下来再次观察。</p><p>这时候，如果有线上GC的状态监视工具，可以直接查看此段事件的GC数据。如果没有监视工具 或者 GC分析数据不全，可以将GC logs导入到本地的离线分析工具，比如<a href="https://github.com/chewiebug/GCViewer">GCViewer</a>。</p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-gc-viewer.png" alt="gc viewer"></p><p>还有一些工具提供实时监控heap状态：</p><pre class="line-numbers language-none"><code class="language-none">$ jstat -gcutil &lt;pid&gt; 1000 100<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>含义：</strong><br>实时监控JVM 堆使用大小、GC的次数和时间。每1000毫秒刷新一次，一共刷新100次。</p><p>通过查看GC状态获知内存被大量分配的是哪几个区域，各区域的增长速率、gc触发的频率和耗时。</p><h4 id="2-2-3-手动生成-heapdump-文件">2.2.3 手动生成 heapdump 文件</h4><p>当无 <code>OutOfMemoryError</code> 产生，但内存利用率异常时，可以使用 <code>jcmd</code> 手动生成 / 获取heap dump文件。</p><p><code>heapdump</code> 文件是当前JVM容器的内存分析快照，一般尝试分析内存问题时，需要在不同维度多次生成 heapdump 文件，用以横向对比（不同JVM之间）或者 纵向对比（同一JVM不同时间阶段之间）。</p>  <pre class="line-numbers language-none"><code class="language-none">$ jcmd -l$ jcmd &lt;pid&gt; GC.heap_dump /tmp/java_pid&lt;pid&gt;.hprof <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>含义</strong>：</p><ul><li><code>jcmd -l</code> 展示所有 JVM 进程，通过该命令获取application的进程id。</li><li>根据pid，使用命令 <code>jcmd GC.heap_dump</code> 生成heap dump到目标文件路径。<br>该命令默认生成 <code>live objects</code> 的数据，因此在生成dump文件前，会执行一次full GC。如果不想强制执行full GC，则可以带上options <code>-all</code>, 这时会生成所有 <code>objects</code> 的数据。</li></ul><h4 id="2-2-4-分析Heap-dump文件">2.2.4 分析Heap dump文件</h4><p>分析heapdump文件的目的，是为了获取最有嫌疑的占用内存的大对象 或 多数对象以及上下文。</p><p>常用的开源免费工具有 MAT、VisualVM、JProfiler。</p><ul><li><p>MAT（Memory Analyzer Tool），出自eclipse，可以单独安装使用；</p></li><li><p>VisualVM，部分JDK自带。不带的版本，需要另行下载安装；</p></li><li><p>JProfiler，已经与Intellij IDEA集成，可以直接在Intellij IDEA上使用；</p></li></ul><p>对于离线分析，MAT优势比较大，优先推荐。MAT提供更详细和直观的 Leak Suspect report 和 Top Components report，在工具台中还可以交互进行更细节的定位。</p><p><strong>Lead Suspect report</strong> 中主要关注几个部分：</p><p><strong>1. Leak Suspect report的全局图</strong></p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-MAT-leaksuspect-1.png" alt="MAT leaksuspect report"></p><p><strong>图中含义</strong>:</p><p>在tomcat线程运行时，有一个对象实例 <code>Object[]</code> 拿住了456M内存，占用堆内存的97.41%。该实例不一定是内存泄露，但作为消耗内存的大对象，依然值得排查。</p><p>点击最下面的链接 <code>Details &gt;&gt;</code> 可以查看分析详情：</p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-MAT-leak-suspect-2.png" alt="MAT leaksuspect report details"></p><p><code>Details &gt;&gt;</code> 一般分为几项：</p><ul><li><p>Shortest Paths To the Accumulation Point：从GC roots 到达 <code>累积点</code> 的最短路径；</p></li><li><p>Accumulated Objects in Dominator Tree：显示累积对象的 <code>Dominator Tree</code> (统治者树)；</p></li><li><p>Accumulated Objects by Class in Dominator Tree：显示累积类的 <code>Dominator Tree</code>（统治者树）；</p></li><li><p>All Accumulated Objects by Class：显示累积类对应的实例数量和一共占用的Shallow Heap。</p></li></ul><p><strong>关键概念：</strong></p><ul><li><p>Shortest paths<br>在Java回收机制中，使用的是可达性分析算法。对象是否要被GC，需要运算从GC roots对象开始，搜索引用链，以此证明该对象不可达。不可达的对象，会被垃圾回收，如果该对象无法被回收，则存在内存泄露。</p></li><li><p>Dominator Tree<br>当对象<code>Object B</code> 被 <code>Object A</code> 引用而造成无法释放的情况，这时候<code>Object A</code> 就是 <code>Object B</code> 的统治者。</p></li><li><p>Shallow Heap &amp; Retained Heap<br>对象自身占用的内存大小，即是Shallow Heap。<br>如果：对象<code>Object B</code> 被 <code>Object A</code> 引用而造成无法释放的情况（Object B 不再引用其他对象），这时候<br><code>Object A Retained Heap = Object A Shallow Heap + Object B Shallow Heap</code></p></li></ul><p>当获取了Leak Suspect对象以及类型, 以及上面的 <code>Details</code> 项，在对这些类型背后的代码获得了解的情况下，很容易找到是哪部分代码执行过程中出现了偏差 —— 注意，仅是执行过程中出现偏差，不一定是问题的根因。<br>在JVM中所有线程和任务对于CPU、内存、磁盘的资源占用都是共享的，因此问题的根因需要再次推导。</p><p>当然，也有比较简单的场景，可以只指根因的。</p><p><strong>2. Top Customers</strong></p><p>在MAT  <code>Leak Suspect report</code> 中除了可以查看Lead suspect objects，还可以通过 <code>Top Customers</code> 目录查看更多的内存消费者排行。</p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-MAT-top-customers.png" alt="Top Customers 1"></p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-MAT-top-consumers-2.png" alt="Top Customers 2"></p><p><strong>3. 辅助查看部分Class Histogram和Thread Overview</strong></p><p><code>class Histogram</code> 类直方图，按Retained Heap排序，体现JVM class生成了多少实例，并且占据了多少内存。</p><p>由于展示图的顶层大部分是Java内部类型，缺少必要的诊断上下文，因此按内存占用大小挨个查看。<br>在有具体的聚焦对象时，可以作为辅助工具查看。</p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-MAT-class-histo.png" alt="类直方图"></p><p>比如，上图中shallow Heap占用特别大的<code>int[]</code>，在MAT工具中，可以通过点击<code>list objects-&gt; with incoming reference</code>，显示其实际被哪里引用，从而查找到 hold 住这块些内存的程序位置。<br>下图是最简单的API controller hold住内存，因此容易查找和定位。而如果是跨API的框架和基础设施代码，则需要进一步的分析和定位。</p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-list-incoming-objects.png" alt="list-incoming-objects"></p><p><code>Thread overview</code> 线程总览，可以看到所有线程的状态。<br>由于内存对象的GC roots并不一定是线程，所以此图仅对发现<code>Dominator</code>是线程的对象内存有效，一般作为辅助查看。<br><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-MAT-thread-overview.png" alt="list-thread"></p><h2 id="3-JVM-CPU-利用率高">3. JVM CPU 利用率高</h2><h3 id="3-1-首先查看JVM中是哪些线程对CPU的占用率高">3.1 首先查看JVM中是哪些线程对CPU的占用率高</h3><p>使用Top命令行：</p><pre class="line-numbers language-none"><code class="language-none">$ top -Hp &lt;pid&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查看CPU占用高的线程ID，记录下这些线程ID。</p><h3 id="3-2-使用jcmd-dump-thread">3.2 使用jcmd dump thread</h3><p>使用jcmd命令行：</p><pre class="line-numbers language-none"><code class="language-none">$ jcmd $pid Thread.print &gt; ./manual.tdump<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-3-将之前记录的线程ID，进行十六进制转换">3.3 将之前记录的线程ID，进行十六进制转换</h3><p>Linux原生命令行：</p><pre class="line-numbers language-none"><code class="language-none">printf "%x\n" &lt;tid&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-4-将Threaddump文件导入TMDA工具">3.4 将Threaddump文件导入<code>TMDA</code>工具</h3><p><a href="https://www.ibm.com/support/pages/ibm-thread-and-monitor-dump-analyzer-java-tmda">TMDA</a>工具，IBM线程离线分析工具。</p><p>打开 <code>Thread Details</code>, 使用16进制的 threadID 在<code>NativeID</code>（dump源文件中是<code>nid</code>）对应查找到线程状态、调用栈。</p><p><img src="/2021/01/18/docker-jvm-tong-yong-gong-ju-zhen-duan-zhi-nan/image-tmda-stack.png" alt="tmda-stack"></p><p>通过分析调用栈，获取相关线程执行的程序位置。<br>当可疑线程是GC线程时，结合内存分析工具一起诊断。</p><p>如果单次 threaddump 分析结果无可疑，可以通过多次生成 threaddump 文件进行时间上纵向对比。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微服务线上治理之监控</title>
      <link href="/2021/01/18/wei-fu-wu-xian-shang-zhi-li-zhi-jian-kong/"/>
      <url>/2021/01/18/wei-fu-wu-xian-shang-zhi-li-zhi-jian-kong/</url>
      
        <content type="html"><![CDATA[<p>微服务架构已经是时下后端应用开发的主流架构之一。微服务的整个生命周期包括<code>微服务拆分和定义（产品规划）</code>、<code>微服务研发</code>、<code>微服务构建与部署</code>、<code>监控与运维</code>几个阶段。</p><p>对于一般企业的微服务改造而言，极少部分企业认为用上微服务概念 + Spring cloud套件就是整活微服务架构了；一部分企业还能认识到针对微服务构建和部署所必需的DevOps流水线或平台；接着，越来越多的企业开始接受支持微服务拆分和设计思想的<code>Domain Driven Design</code>；在完成前三步的基础上，最终还有少部分企业意识到线上分布式系统带来的复杂性，需要进行微服务线上治理——分层次的监控、诊断及最终的治理方案。</p><p>这里就主要从可观测性、层次性、时效性上，聊聊微服务线上治理中的监控。</p><span id="more"></span><h3 id="1-系统运行时的可观测性">1. 系统运行时的可观测性</h3><p>微服务线上治理的前提——采集线上运行时数据，让系统状态与流程可被实时度量和监控。</p><p>管理学之⽗德鲁克曾经说过:“如果你无法度量它，就无法改进它。”</p><p>然而对于今天——在各系统存在各种五花八门、各式各样、大量指标数据的当下，如何整合这些指标，在度量的同时，提升整个系统运行时的可观测性，以达到及时地发现问题、定位问题的目的，才是微服务线上治理的基础。</p><p>理论上，问题越早发现、越早修复，可以越节省研发成本。一些微服务的问题，在规划、研发、构建等阶段，可以通过线下微服务治理的方式提前解决掉。</p><p>然而，对于微服务能力不同、或者理解不同的各企业和团队来说，部分团队需要等到系统被部署到线上运行时才能真正发现和正视问题。</p><p>当你面临的团队，不追求clean architecture、不写测试、不坚持重构、没有性能测试和联调测试、甚至没有太多有经验的开发，这时候，线上系统监控将成为最后的反馈堡垒。</p><p>因此，带有观测性的线上监控能力是各个微服务团队必不可少的“看家”工具之一。</p><p>业内能做到线上监控的开源产品和商业产品不一而足。大家可能见过下面这样的（监控微服务状态、微服务之间调用等）：<br><img src="/2021/01/18/wei-fu-wu-xian-shang-zhi-li-zhi-jian-kong/image-spring_boot_dashboard.png" alt="图1"><br><em>（图 1）</em></p><p>或者是，监控 服务对资源CPU、内存、磁盘等利用率趋势：</p><p><img src="/2021/01/18/wei-fu-wu-xian-shang-zhi-li-zhi-jian-kong/image-grafana_jvm_dashboard.png" alt="图2"><br><em>（图 2）</em></p><p>也有API调用量、失败率、延时时长的TopN统计：</p><p><img src="/2021/01/18/wei-fu-wu-xian-shang-zhi-li-zhi-jian-kong/image-app_api.png" alt="图3"><br><em>（图 3）</em></p><p>或者，是基于动态链路技术实现的链路图：</p><p><img src="/2021/01/18/wei-fu-wu-xian-shang-zhi-li-zhi-jian-kong/image-dynamic_invoking_graph.png" alt="图4"><br><em>（图 4）</em></p><h3 id="2-监控需要分层次">2. 监控需要分层次</h3><p>看过上面四种监控示例图，相信有不少做过线上问题诊断的同事会认为：不少指标过于细，或者过于底层，对于发现实际问题和定位问题毫无帮助。</p><p>当经过详细调研分析和使用之后，本人发现这些监控模型是应该分层次来理解和使用的。</p><p><img src="/2021/01/18/wei-fu-wu-xian-shang-zhi-li-zhi-jian-kong/image-layers.png" alt="图5"></p><p>一共分为<code>基础状态层</code>、<code>资源占用层</code>、<code>API层</code>、<code>链路层</code>。</p><ul><li>基础状态层：各微服务和基础设施服务（比如数据库）的生效配置及实时状态，如健康度、熔断器状态、限流阀状态、灰度状态等等。（示例图1）</li><li>资源占用层：各微服务和基础设施服务对资源的占用，比如微服务对系统CPU、内存、磁盘等的占用率，微服务内部堆栈对内存的利用率等等。（示例图2）</li><li>API层：各微服务的API性能，API方式包括且不限于http restful API、messageQueue consumer等等；同时，基础设施服务，比如数据库，SQL本身可以理解为一种特殊的API，因此慢SQL统计和监控，也可以算入API层。（示例图3）</li><li>链路层：统计和追踪由服务请求发起的整个系统内部链路的流转，包括微服务之间、微服务与基础设施服务之间的链路。微服务之间的调用方式包括且不限于http restful、messageQueue等等。（示例图4）</li></ul><p>越靠近<code>技术底层</code>，指标越孤立，对服务的影响面越广，越难直接定位问题；</p><p>越靠近<code>应用层</code>，指标越具象，影响面越小，越容易定位问题。</p><p>当然也有人会认为，在这种分层结构中，应该将基础设施服务单独拎出来作为一个单独分类  —— 的确也是无不可，除了链路层以外，基础设施服务可以独立完成另外三层的纵向切片。</p><h3 id="3-监控需要时效性">3. 监控需要时效性</h3><p>在搭建监控工具 或者 接入监控平台时，面对于采集日志、指标的实时运算方式，大多数情况团队都默认监控是实时的 —— 这样能及时发现和响应问题。</p><p>并且大部分监控工具，做到了监控自动化，进行实时预警，及时通知到相关人员处理问题；或者，有部分DevOps监控平台甚至可以做到自动化AI管控，针对<code>基础状态层</code>、<code>资源占用层</code>出现的问题，使用资源临时扩容、资源切换/重启等策略进行线上自动恢复。</p><p>然而，随着Q/TPS、数据量的增长，监控服务资源升级的滞后 或 架构的不合理，监控延时的误差会越来越大。</p><p>当监控的时效性越来越偏离实时，团队对于系统运行时快速发现和响应问题的效率将大打折扣。</p>]]></content>
      
      
      <categories>
          
          <category> 微服务治理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微服务治理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL InnoDB 聚集索引数据结构</title>
      <link href="/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/"/>
      <url>/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/</url>
      
        <content type="html"><![CDATA[<blockquote><p>关系型数据库系统的世界是非常复杂的 —— 如果我们思考一下我们需要做哪些事情才能满足SQL语句的查询需求，就能意识到这种复杂是必然的。但具有讽刺意味的是，书写SQL是如此简单，表、行与列的概念也非常容易理解。</p><p>​—— 《数据库索引设计和优化》</p></blockquote><span id="more"></span><h3 id="1-页-Page">1. 页 (Page)</h3><p>页，是数据库数据存储方式的逻辑结构。</p><p>Innodb 采用将存储数据按表空间（tablespace）的方式进行存放。如果没有开启 <code>innodb_file_per_table</code> 设置，新的表的创建会保存进默认的系统共享表空间。</p><pre class="line-numbers language-none"><code class="language-none">mysql&gt; show variables like 'innodb_file_per_table';+-----------------------+-------+| Variable_name         | Value |+-----------------------+-------+| innodb_file_per_table | ON    |+-----------------------+-------+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当 <code>innodb_file_per_table</code> 等于 <code>ON</code> 时，会给每个表创建独立的数据文件。</p><p>比如，在数据库 <code>test</code> 中创建一个表 <code>show_index</code> ，在mysql 的 dataDirectory 目录下就回出现一个名为 <code>show_index.ibd</code> 的数据文件。</p><p>在单个表的数据文件中，数据就是以多个页的形式进行排列。MySQL默认配置下，每16K，即为一个页。</p><p>借用了《MySQL技术内幕Innodb存储引擎》作者的工具<code>py_innodb_page_type.py</code>，可以查看到单表数据文件的页组成：</p><p><img src="/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/image-py-innodb-page-info.png" alt="图1 file_per_table tablespace结构图"></p><p>MySQL中数据页和索引页，都被归类为B Tree Node类型，严格来说应该是B+ Tree Node。</p><h3 id="2-B-Tree-Node">2. B+ Tree Node</h3><p>B+ Tree概念，需要区分二叉树（Binary Tree）、二叉查找树（BST）、B-Tree（B: Balance）。</p><p>在MySQL innodb中，叶子节点页的page level为0，非叶子节点页的page level &gt; 0。</p><p><img src="/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/image-B+tree.png" alt="图2 聚集索引的B+ Tree图"></p><p>上图是一个聚集索引的B+ Tree图。</p><p>1个B+ Tree Node，占据一个页。</p><ul><li>在索引页，页的主要记录部分(<code>User Records</code>)存放的<code>Record</code> = <code>record header</code> + <code>index key</code> + <code>page pointer</code>。</li><li>在数据页，则是按表创建时的<code>row_format</code>类型存放完整数据行记录。<br>row_format类型分别有：<code>Compact</code>、<code>Redundant</code>、<code>Compressed</code>和<code>Dynamic</code>。</li></ul><p>因此，在聚集索引中，非叶子节点都为索引页，叶子节点为数据页；</p><p>在辅助索引中，非叶子节点和叶子节点都为索引页。不同的是，叶子节点里记录的是聚集索引中的主键ID值。</p><p>注意，在索引页的Record中的<code>page pointer</code>，指向的是页，而非具体的记录行。并且Record的<code>index key</code>，为指向的page records的起始键值。</p><h4 id="2-1-聚集索引-Cluster-index">2.1. 聚集索引 (Cluster index)</h4><p>MySQL将数据存放在聚集索引的叶子节点中，由索引进行组织。因此也可称为，数据即索引，索引即数据，在整个页分类中，都被列为<code>B+ Tree Node</code>。</p><p>图2 即是一个完整的聚集索引的B+ Tree结构展现。</p><p>在叶子节点是如何实现双向链接的结构，可以详细看下页内的组织分布。</p><p>在表空间文件的一个页的结构上，内容布局为：</p><p><img src="/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/image-page-structure.png" alt="图3 页的结构组成图"></p><p>在聚集索引中，数据页内除了按照主键大小进行记录存放以外，在<code>File header</code>中，有两个字段：<code>fil_page_prev</code> 和<code>fil_page_next</code>, 分别记录了上一页/下一页的偏移量（offset），用以实现数据页在B+ Tree叶子位置的双向链表结构。</p><h3 id="3-数据检索">3. 数据检索</h3><p>通过B+ Tree结构，可以明显看到，通过B+ Tree查找，可以定位到索引最后指向的数据页，并不能找到具体的记录本身。</p><p>这时，数据库会将该页加载到内存中，然后通过<code>Page Directory</code>进行二分查找。</p><h4 id="3-1-Page-Directory">3.1. Page Directory</h4><p><code>Page Directory</code>是该页存放的<code>User Records</code>的一个稀疏目录，存放的内容是Record在页内的相对位置。每两个字节，记录一个相对位置，从邻近<code>File Trailer</code>的位置开始倒排存放。</p><p><img src="/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/image-page-directory.png" alt="image-20210107214107410"></p><p><code>Page Directory</code>中每两个字节，代表一个目录槽。在上图中，一共有6个槽。</p><p>在页首的<code>Page Header</code>部分有一个<code>Page_N_Dir_Slots</code>的字段 —— 同样记录了目录槽的数量。</p><p>一个目录槽，对应按序的多条记录。记录的相对位置，指向这批记录的第一条记录。</p><p>每条记录都有<code>Record header</code>, 但目录槽 指向的第一条记录的<code>Record Header</code>中第4~8位（bits），是<code>n_owned</code>值，代表该目录槽中拥有的记录数量。</p><p><code>Record header</code>的组织结构：</p><p><img src="/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/image-record-header.png" alt="image-20210107214322598"></p><p>比如下图，一共有6个目录槽，大部分目录槽中有4条记录。</p><p><img src="/2020/12/27/mysql-innodb-ju-ji-suo-yin-shu-ju-jie-gou/image-page-slots.png" alt="image-20210107204730744"></p><h3 id="4-总结">4. 总结</h3><p>MySQL Innodb通过页组织成的B+ Tree Nodes结构 和 Page Directory，完成了具体记录的检索。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>研发效能之层级测试</title>
      <link href="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/"/>
      <url>/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/</url>
      
        <content type="html"><![CDATA[<p>研发效能不等于研发效率。</p><p>在我司的<code>研发平台解决方案</code>的定义中，研发效能 = 可持续快速交付价值的能力 = 效率 + 质量 + 用户价值。</p><p>如果不能达到相应的质量标准和用户价值，再高的研发效率也是枉然。</p><p>这里我专门聊一下效率和质量之间的结合一个点。</p><h3 id="1-在对质量的追求中，如何优化研发效率？">1. 在对质量的追求中，如何优化研发效率？</h3><span id="more"></span><p>在敏捷团队里，开发人员往往被要求编写单元测试、集成测试、契约测试等等自动化测试，并且在 CI 流水线上创建对应的<code>test stage</code>，通过每次提交代码后重复运行 —— 来获取测试情况，以此来增添交付质量的保证。</p><p><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/CI%E6%B5%81%E6%B0%B4%E7%BA%BF.png" alt="CI流水线"></p><p>CI 流水线上运行的自动化测试，大家一定不陌生 —— 一次编写、重复运行、变更时及时维护。</p><p>对团队而言，<strong>可视化</strong>、最直观的就是，测试的运行效率、运行时长。</p><p>因此，团队会尽量缩短测试集的运行时长，以达到快速反馈和提高流水线的及时使用率。</p><p>同时，快速的测试运行效率，也可以缩短开发人员进行代码预提交的检查时间。</p><p>在一般__不可视化__的角落，其实还有日常的测试编写和维护的效率。</p><p>当团队要求较高的代码覆盖率时，往往一个 story 的开发时间中，可能有一半左右用以编写上述自动化测试。</p><p>所以，在研发效能度量中，自动化测试的效率包括两个部分：</p><p><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E7%9A%84%E6%95%88%E7%8E%87.png" alt="自动化测试的效率"></p><p>不仅要优化测试集的运行效率，同时还要优化测试编写的效率。</p><h3 id="2-测试金字塔是个合适的策略">2. 测试金字塔是个合适的策略</h3><p><a href="https://martinfowler.com/bliki/TestPyramid.html">测试金字塔</a>主导思想就是，通过不同的测试类型组合，来达到质量与投入产出比的一个平衡取舍 —— 以合适的投入产出比，来获取一个较高的质量。</p><p>除开硬件资源的投入（如 CI 资源），投入产出比与研发效率是线性的关系。</p><p>测试金字塔中，底层的单元测试拥有反馈快、代价低、单一职责的特点，因此作为基数最大的基层测试 —— 用以覆盖绝大部分代码逻辑。</p><p>基于单元测试上的其他上层测试，主要以其他角度弥补单元测试的不足，如组件完整性等等，同时它们面临的问题越来越复杂、范围越来越广，启动和运行的过程也会越来越重，编写和维护成本也越高。</p><p>因此，运用测试金字塔，利用大量的底层单元测试来尽量覆盖代码逻辑，是同时优化<code>测试编写效率</code>和<code>测试集运行效率</code>的一把有利钥匙。</p><h3 id="3-单元测试覆盖所有代码逻辑-——-不可能做到？">3. 单元测试覆盖所有代码逻辑 —— 不可能做到？</h3><p>以服务架构举例，从传统的分层架构说起。（代码术语以Java/Spring为背景。）<br><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/%E4%BC%A0%E7%BB%9F%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84.png" alt="传统分层架构"></p><p>从技术实现角度来讲，只有其中的 application 层和 domain 层可以实现真正意义的单元测试 —— 只测试单元本身，仅使用 Junit + mokito，测试反馈总时长在秒级以内。</p><p>从代码实现来看，user interfaces 和 persistence 其实也可以仅使用 Junit + mokito 来编写单元测试。<br>但问题是：这两层只使用单元测试来测方法体本身，没有意义。</p><h4 id="3-1-是否要单独测试-user-interfaces-和-persist-层？">3.1. 是否要单独测试 user interfaces 和 persist 层？</h4><p>这里有块示例代码，见下。<br>user interfaces 里面定义的基于 Spring MVC 的 controller，看起来方法体内只有一两行代码，同时下层 applicationService 和 mapper 逻辑已经由自身单元测试覆盖了。</p><pre class="line-numbers language-none"><code class="language-none">@GetMapping("/customers/{customerId}/projects/{projectId}")@PreAuthorize("hasRole('USER')")@ResponseStatus(HttpStatus.OK)Set&lt;LatestPipelineInfoResponse&gt; fetchLatestUploadInfo(@PathVariable @Min(0) Long customerId, @PathVariable Long projectId){    Set&lt;LatestPipelineInfoDTO&gt; dtos = this.service.fetchLatestUploadInfo(customerId, projectId);    return LatestPipelineInfoResponseMapper.MAPPER.fromDto(dtos);}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果使用单元测试，仅仅测的是 controller 对 service 和 mapper 的成功调用，意义很小。</p><p>我们这看一下上面这个controller method背后覆盖了多少逻辑：</p><ul><li><p>监听http request</p></li><li><p>将http request中的数据反序列化转换成Java objects, 注入到方法调用的入参中</p></li><li><p>验证入参</p></li><li><p>验证 security 权限</p></li><li><p>调用业务逻辑</p></li><li><p>将业务逻辑返回的Java objects序列化返回到response中</p></li><li><p>处理以上环节中发生的异常</p><p>一共7项，虽然代码实现起来很简单，这是因为 Spring 框架帮开发人员简化了很多代码量。<br>单独测试user interfaces层，并不是说要测 Spring 提供的框架能力，而是要测这块定制代码最终实现的是 —— “正如你所愿”。</p></li></ul><p>相同道理，在persist层，如果代码里有复杂的逻辑，比如动态查询，或者直接HSQL、SQL。如：</p><pre class="line-numbers language-none"><code class="language-none">public interface PipelineHistoryJpaRepository extends        JpaRepository&lt;PipelineHistory, String&gt; {    @Query(nativeQuery = true, value = "SELECT * FROM pipeline_histories p, " +            "(SELECT max(id) AS id FROM pipeline_histories " +            "GROUP BY customer_id, project_id, pipeline_name) tmp " +            "WHERE p.id = tmp.id " +            "ORDER BY customer_id, project_id, pipeline_name")    public List&lt;PipelineHistory&gt; fetchAllExistsPipeline();}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>persist层逻辑，也需要使用测试覆盖。<br>当然，如果是JPA自动生成的findBy、save等等系列，不在这块范围之内。</p><h4 id="3-2-如何单独测-user-interfaces-和-persist-层？">3.2. 如何单独测 user interfaces 和 persist 层？</h4><p>user interfaces 和 persist 层因为框架和工具的原因，只能带上Spring application context一起启动测试。<br>正常来说，它们已经算是集成测试了，集成了 Spring 容器。</p><p>用过 @SpringBootTest 的人，一定对其造成的测试编写效率和运行效率印象深刻 —— 可能只是添加了几个 Bean，就会让 context 的启动时间延长几秒，不恰当地使用某些test annotation也会造成context的重新加载和刷新。</p><p>本人也用过很长一段时间 —— 通过 API 调用整个组件（<code>controller </code>-&gt; <code>servcie</code>-&gt;<code>repository</code>-&gt;<code>memory db</code>）, 以实现对user interfaces 和 persist 层的覆盖。即使在成功优化Spring加载机制 —— 每次批量运行测试用例仅加载一次 application context，但每次编写新的API测试、修复API测试仍然痛苦不已 —— 每次运行单条测试进行反馈时，依然要等待一次完整的 context 启动。</p><p>因此，这里推荐使用Spring提供的切片测试工具（Tests Slices）: @WebMvcTest、@DataJpaTest。其原理是仅创建简化的application context，少量的bean，使用轻量级、有针对性范围的方式，降低反馈时间、提升测试性能。<br>在编写测试、运行测试的性能上，切片测试的反馈效率的确赶不上单元测试，但对比 @SpringBootTest 加载几乎完整 context 的情况已经优化不少。</p><h4 id="3-3-最终的目的：利用基层的测试来整体覆盖代码逻辑">3.3. 最终的目的：利用基层的测试来整体覆盖代码逻辑</h4><p>回到之前的问题：技术意义上的单元测试的确不能覆盖所有代码逻辑。</p><p>但，<code>单元测试</code> + <code>轻量级的、快速反馈的 slice tests</code> 可以尽量覆盖到所有代码逻辑。</p><p>因为<code>单元测试 + slice tests</code>的目标是为了完成分层架构内的逻辑测试，为了避免语义上的冲突，因此这里将两者一起称为<code>层级测试</code>。<br>除了传统的分层架构，也来看看六边形架构、或者叫接口适配器架构是不是适合进行<code>分层测试</code>呢？<br>其实不然，六边形架构在宏观意义上，其实可以看成是“两层” —— domain 和 infrastructure。<br><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/%E5%85%AD%E8%BE%B9%E5%BD%A2%E6%9E%B6%E6%9E%84.png" alt="六边形架构"><br>正好对照了 unit tests 和 slice tests 的分界。<br>而这两层的区别，在于 unit tests 测试的是系统中稳定的业务层，可以尽量多的追求代码覆盖率；而slice tests 测试的是对基础设施的依赖适配和定制逻辑，追求定制逻辑的功能覆盖。<br>最终同样得以完成对 ”代码逻辑“ 的整体测试覆盖。</p><h3 id="题外：">题外：</h3><h4 id="1-API集成测试（API-Integration-Tests）">1. API集成测试（API Integration Tests）</h4><p><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/API%E9%9B%86%E6%88%90%E6%B5%8B%E8%AF%95.png" alt="API集成测试"><br>在完成前面的层级测试、覆盖了所有逻辑细节之后，就轮到跨层级的连通性测试了。<br>这里虽然命名为“API集成测试”，其实也叫“组件测试”。由于系统架构由来已久，到微服务架构的时候，一个组件的边界已经是一个微服务的边界，针对微服务的API特性, 这篇文章里称其为“API集成测试”。</p><p>基于测试运行的可重复性，API集成测试中需要降低对外界的依赖，比如微服务在真实环境中对数据库、外部服务的依赖。</p><p>数据库可以替换成能力相同的内存式、或嵌入式数据库，比如生产mysql\mariaDB 可替换成 mariadb4j 实现嵌入式数据库；外部服务依赖，使用服务边界mock进行统一管理。</p><p>借用**<a href="http://github.com/tobyclemson">Toby Clemson</a>** 的一张微服务组件测试的图，橙色的虚线正是组件测试的边界。<a href="https://martinfowler.com/articles/microservice-testing/">原图来源</a></p><p><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/%E7%BB%84%E4%BB%B6%E6%B5%8B%E8%AF%95.png" alt="组件测试"></p><p>使用 API 集成测试实现组件内部的连通性测试，一般测试路径选择覆盖层级完整的 happy path，不要企图去测试各逻辑分支。</p><p>举个例子：</p><p>一般写API集成测试的时候，常会遇到层级间“传递参数缺少校验“的问题，如 controller 调用 applicationService 时，入参传递了一个未预料的<code>null</code> 值，这个<code>null</code>值的校验，应该由具体代码 controller 与 applicationService 之间进行约定：可以是接收方编写防御性校验，也可以由调用方前瞻性校验。</p><p>因此，此处<code>null</code>值校验的逻辑完全是可以在 Layer tests中由测试覆盖。不要试图在API集成测试中覆盖这个<code>null</code>和<code>非null</code>分支。</p><h4 id="2-契约测试-Contract-Tests">2. 契约测试(Contract Tests)</h4><p>之前测完各层级逻辑、组件内的调用连通性，接着来看一下微服务边界的契约测试。</p><p><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/%E5%A5%91%E7%BA%A6%E6%B5%8B%E8%AF%95.png" alt="契约测试"></p><h5 id="契约-vs-API">契约 vs API</h5><p>对于契约测试，首先要避免进入 —— 一条API就应该是一个契约的误区。</p><p>记住，契约测试有个“首要精神“：<code>消费者驱动契约（Consumer Driven Contracts）</code>。</p><p>举个例子：</p><p><img src="/2020/06/30/yan-fa-xiao-neng-zhi-ceng-ji-ce-shi/%E5%A5%91%E7%BA%A6.png" alt="契约"></p><p>服务producer，本身实现了一条API，返回资源 —— 每个会员的详细信息，包括：<code>id</code>、<code>age</code>、<code>name</code>。</p><p>服务consumer I、II、III知道 producer 服务可以提供会员信息资源，于是分别来与producer谈需求、谈集成，最终形成两份需求约定，见上图。</p><p>差别是：一份约定必须返回<code>id</code>和<code>age</code>字段，另一份约定必须返回<code>id</code>和<code>name</code>字段。</p><p>这也就形成了两份契约 —— 是根据消费者的需求直接驱动的。</p><p>从 consumer 角度来看，根本不关心 producer 的API是否是复用，这里只是恰好多个契约可以共用一条API而已，因此每个consumer的基本诉求就是 —— 无论之后API的实现如何变动，都不能影响自己契约内的数据。</p><p>接着在需求发布以后，consumer III的需求需要变动 —— 将返回的<code>name</code>字段，分切成<code>firstName</code>和<code>lastName</code>，这时候就形成了第三份<code>契约C</code>。无论具体API如何变更，都有两个基本的安全校验阀在那里：<code>契约A</code>和<code>契约B</code>。</p><p>也许有人会说不需要<code>契约C</code>，为了省事儿consumer III拿上<code>name</code>字段自己拆嘛。这种思路在现实谈需求、谈集成中其实经常会碰到。 这里一个小的玩笑：请告诉我，你觉得”金城武“是姓”金城“，还是姓”金“？</p><h5 id="契约测试需要双方维护">契约测试需要双方维护</h5><p><code>契约（contract）</code>以满足consumer需求为目的，以consumer定义为主导，但 producer / customer 双方都有校验契约交付物的权利和义务 。</p><p><code>契约测试</code>，首先运行在producer的<code>auto test</code>中，以保证任何时候 producer 代码变更之后都满足契约。</p><p>同时该契约需要生成stub，提供给 consumer 以作为test double，consumer 依赖此契约的场景使用测试覆盖，以保证契约被变更时 consumer 能够及时获知。</p><h5 id="不要滥用契约测试">不要滥用契约测试</h5><p>契约中主要约定是三部分：<code>调用方式</code>、<code>数据类型</code>、<code>数据格式</code>。因此契约测试主要校验的是这三部分，不包括数据值。</p><p>并且每一份契约的形成和变更，都会涉及到两方团队的沟通、协议和实现，比单元测试、API 集成测试 —— 代价高，效率低。</p><p>因此，契约测试在测试金字塔中位于 API 集成测试上方。</p><p>除了<code>调用方式</code>、<code>数据类型</code>、<code>数据格式</code>外，需要使用单元测试、API 集成测试的方式覆盖。</p><h4 id="3-E2E测试">3. E2E测试</h4><p>在软件研发阶段的 E2E 测试，一直有<code>无法稳定重复运行</code>、<code>代价高</code>、<code>效率低</code>等等问题，因此一直被放在测试金字塔的顶端。</p><p>在微服务架构、多微服务环境部署中，在 E2E 是基于环境、运行时的情况下，这些问题就更加突出。</p><p>因此，E2E 测试的目标和范围在团队中需要仔细的被定义。</p><p>在本文的上下文——研发阶段的质量内建，推荐仅将 E2E 测试作为基于几个关键业务场景的服务连通性测试。</p><p>当然，如果团队有一票专门来写E2E测试的人手，愿意承担高代价的成本、觉得这种ROI可以接受，也是可以多写写E2E测试的。</p>]]></content>
      
      
      <categories>
          
          <category> 敏捷精益软件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 敏捷测试 </tag>
            
            <tag> 研发效能 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在gradle管理可共享的依赖版本管理</title>
      <link href="/2020/06/05/zai-gradle-guan-li-ke-gong-xiang-de-yi-lai-ban-ben/"/>
      <url>/2020/06/05/zai-gradle-guan-li-ke-gong-xiang-de-yi-lai-ban-ben/</url>
      
        <content type="html"><![CDATA[<p>“可共享的依赖版本管理” —— 用过 Maven 的小伙伴们可能说，这不就是BOM么。<br>对，这里聊的就是如何使用 gradle 实现 BOM 生成和导入。<br>没用过 Maven 的小伙伴们也不用被劝退，想想在使用Spring plugin <code>io.spring.dependency-management</code>时，<br><code>imports.mavenBom</code>到底在做什么，有没有想要了解一下？</p><span id="more"></span><h3 id="1-BOM是什么？">1. BOM是什么？</h3><p>在说 BOM 之前，先了解一下 Maven 的一些基本概念。<br>Maven <strong>POM</strong>，全名 <code>Project Object Model</code>, 是 Maven 使用中的重要配置文件，xml格式，主要用来导入依赖和进行项目构建。<br>Maven <strong>BOM</strong>，全名 <code>Bill Of Materials</code>, 是一种特殊的 POM，主要用来集中管理项目依赖的版本，更加灵活地维护所有依赖的版本信息。<br>配置好的 BOM，可以放在单个项目中自用，也可以传阅和分享给其他项目进行公用。</p><p>讲的直观一点，效果就是（见下图）：<br><img src="/2020/06/05/zai-gradle-guan-li-ke-gong-xiang-de-yi-lai-ban-ben/Spring-dependencies-management.png" alt="Spring-dependencies-management"><br>dependencies中依赖的那些库为何可以不用标明版本？<br>正是因为使用了<em>dependency-management</em> 插件，当 gradle plugin <em>org.springframework.boot</em> 检测到此插件启用时，会自动导入Spring boot dependencies BOM，这样依赖库们会主动使用 BOM 中推荐的版本。<a href="https://docs.spring.io/spring-boot/docs/current/gradle-plugin/reference/html/#managing-dependencies">链接</a></p><p>下面是Spring Cloud BOM的一部分展示(完整见<a href="https://github.com/spring-cloud/spring-cloud-release/blob/vHoxton.SR5/spring-cloud-dependencies/pom.xml">链接</a>)：</p><p><img src="/2020/06/05/zai-gradle-guan-li-ke-gong-xiang-de-yi-lai-ban-ben/Spring-cloud-dependencies.png" alt="Spring-cloud-dependencies"></p><p>看到这里，是不是觉得有 BOM 的情况下便捷不少，再也不用一条条dependency分别查阅、选择和维护版本了？<br>日常开发中，我们已经见识过了Spring boot / Spring Cloud /junit 这些常用 BOMs。</p><p>当有了已经被验证过的依赖版本管理，setup projects时候直接拿来复用，是不是感觉省事不少？<br>同时 BOM 不可避免地还支持版本升级。<br>下面我们就来看看如何在 gradle 中定义我们自己的 BOM。</p><h3 id="2-gradle-Java-platform-plugin">2. gradle Java platform plugin</h3><p><code>gradle Java platform plugin</code>是 gradle 对定义、发布 BOM 提供的一款实用插件。<br>引入它，我们就可以开始动手工作了。<a href="https://docs.gradle.org/5.6.3/userguide/java_platform_plugin.html#header">官方链接</a></p><p><em><code>build.gradle</code></em></p><pre class="line-numbers language-none"><code class="language-none">plugins {    id 'maven-publish'    id 'java-platform'}version '0.1.1-SNAPSHOT'javaPlatform {    allowDependencies()}dependencies {    api platform('org.springframework.boot:spring-boot-dependencies:2.2.6.RELEASE')    api platform('org.springframework.cloud:spring-cloud-dependencies:Greenwich.SR3')    api platform('org.springframework.cloud:spring-cloud-contract-dependencies:2.2.3.RELEASE')    api platform('org.junit:junit-bom:5.3.2')    constraints {        api 'com.google.guava:guava:27.0.1-jre'        api 'ch.vorburger.mariaDB4j:mariaDB4j-springboot:2.4.0'        api 'org.mariadb.jdbc:mariadb-java-client:2.2.5'        api 'org.mockito:mockito-core:2.22.0'        api 'org.mockito:mockito-junit-jupiter:2.22.0'        api 'org.assertj:assertj-core:3.11.1'    }}publishing {    repositories {        maven {            credentials {                username = 'jfrog'                password = 'jfrog123456'            }            def releasesRepoUrl = 'http://localhost:8082/artifactory/libs-release/'            def snapshotsRepoUrl = 'http://localhost:8082/artifactory/libs-snapshot/'            url = version.endsWith('SNAPSHOT') ? snapshotsRepoUrl : releasesRepoUrl        }    }    publications {        myPlatform(MavenPublication) {            from components.javaPlatform        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当然, 作为一个服务级的 BOM，自然无需从零开始逐条定义，可以直接先 import 框架级的 BOMs，如上例中的Spring boot / Spring cloud / Spring cloud contract / Junit。<br>但由于需要使用第三方platform bom, 则不得不打开配置约束 ——<code>javaPlatform.allowDependencies</code>。具体使用请见<a href="https://docs.gradle.org/5.6.3/userguide/java_platform_plugin.html#sec:java_platform_bom_import">官方链接</a></p><p>这里，通过gradle生成的 BOM 会发布到一个我本地自己搭建的JFrog artifactory OSS中。<br>(为什么不在云上搭一个？啊哈哈，因为JFrog artifactory OSS最低预配是4核4G内存，自己掏钱就手短了。。)<br>当然,也可以生成本地的 POM 文件，手动复制传阅，但这样就不容易进行后续的版本管理和保持更新了。</p><p>maven publish 成功后，我们就可以来使用 BOM 导入依赖版本了。</p><h3 id="3-gradle-platform">3. gradle platform</h3><p>导入方式也非常简单，直接使用platform组件即可。<a href="https://docs.gradle.org/current/userguide/platforms.html">官方链接</a></p><p>创建一个example项目试一下, 编写<code>build.gradle</code>文件。</p><pre class="line-numbers language-none"><code class="language-none">repositories {    maven {        credentials {            username = "jfrog"            password = "jfrog123456"        }        url "http://localhost:8082/artifactory/libs-snapshot/"    }}dependencies {    implementation platform('com.ellendan.service.template:dependencies-bom:0.1.1-SNAPSHOT')    implementation 'org.springframework.boot:spring-boot-starter-web'    implementation 'org.springframework.boot:spring-boot-starter-security'}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对，就是使用platform()引入即可。</p><p>也许有人会问：大家用 spring-dependency-management 习惯了，这个 BOM 是否支持 spring-dependency-management 的 <code>imports.mavenBom</code>。<br>理论上是支持的。<br>但本人在写代码的时候，发现自定义 BOM 中spring boot dependencies BOM 无法被成功引入，而其他 BOMs 都没有此问题、可以成功导入。<br>因此，我这里并不推荐通过spring-dependency-management的<code>imports.mavenBom</code>来导入。</p><h3 id="4-为什么要做“可共享的依赖版本管理”">4. 为什么要做“可共享的依赖版本管理”</h3><p>这还要从本人最近的一个任务说起。<br>任务本身是做 —— “启动模板”。<br>但“启动模板”，这四个字，怎么看都觉得非常的静态。<br>结合Rebecca《演进式架构》中“服务模板”的概念（虽然“模板”这命名还是怎么看怎么静态）。在构建服务的过程中，为了防止有害的重复，如果技术上的适当耦合避免不了，那就尽量让其黑盒复用。</p><blockquote><p>通过在服务模板中定义适当的技术架构耦合点，并让基础设施团队管理这些耦合，就能使各个服务团队免于这些苦恼。</p></blockquote><p>所以，这里决定尝试做一个“服务模板”。<br>依赖版本管理只是其中的一个小的部分, 并且使用 gradle 来实现也非常简单。<br>具体代码地址：<a href="https://github.com/ellendan000/service_template">https://github.com/ellendan000/service_template</a></p><h3 id="PS-废话篇">PS. 废话篇</h3><p>眼看2020就要过半，由于2020开局乱来，受种种因素影响，计划一团混乱变更。<br>一鼓作气，再而衰，三而竭，各种计划目标债。期望2020后半段能走好吧~</p><h3 id="参考资料">参考资料</h3><ol><li><a href="https://docs.spring.io/spring-boot/docs/current/gradle-plugin/reference/html/#managing-dependencies">https://docs.spring.io/spring-boot/docs/current/gradle-plugin/reference/html/#managing-dependencies</a></li><li><a href="https://docs.gradle.org/5.6.3/userguide/java_platform_plugin.html#header">https://docs.gradle.org/5.6.3/userguide/java_platform_plugin.html#header</a></li><li><a href="https://docs.gradle.org/current/userguide/platforms.html">https://docs.gradle.org/current/userguide/platforms.html</a></li><li><a href="https://docs.spring.io/dependency-management-plugin/docs/current/reference/html/#introduction">https://docs.spring.io/dependency-management-plugin/docs/current/reference/html/#introduction</a></li><li><a href="https://www.baeldung.com/spring-maven-bom">https://www.baeldung.com/spring-maven-bom</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 微服务治理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gradle </tag>
            
            <tag> 微服务治理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DDD概念概览</title>
      <link href="/2020/02/09/ddd-gai-nian-gai-lan/"/>
      <url>/2020/02/09/ddd-gai-nian-gai-lan/</url>
      
        <content type="html"><![CDATA[<p>软件的核心，是为其用户解决领域相关问题的能力。</p><h3 id="1-何为DDD">1. 何为DDD</h3><p>DDD是Domain Driven Design的简称。<strong>领域驱动设计</strong>，“<strong>领域</strong>”指业务领域，“<strong>设计</strong>”指软件设计。<br>DDD可以看成一种开发思想体系，促成了一种新的以领域为中心的思维方式，使得团队可以高效管理——用于复杂问题域的软件的构造和维护。</p><span id="more"></span><h3 id="2-为什么DDD">2. 为什么DDD</h3><p>对于一个复杂业务系统，无视业务复杂度而割裂式地进行软件设计，往往会造成软件的<strong>大泥球模式（BBoM）</strong>，后果就是：</p><ol><li>对统一语言和问题域知识缺乏重视，导致代码库可用但无法揭示业务意图。</li><li>缺乏基于问题域模型的应用程序设计的重视，让代码库缺乏与业务行为的协同效应，当有后续功能的扩展就会变得棘手。领域复杂性和技术复杂性混合在了一起。</li><li>会扼杀开发。对开发人员来说，软件杂乱、变更易出错。对企业来说，降低了软件快速实现商业价值的能力。</li><li>缺乏对问题域的关注和正确认识，构建出来的软件系统往往会失败。<br>注：<strong>问题域</strong> ，涉及你当前正在构建软件的主题领域。是确定软件价值的关键点。</li></ol><h3 id="3-DDD模式">3. DDD模式</h3><p>DDD具有两种模式类型：战略模式和战术模式。<br>战略模式影响的是解决方案，战术模式用于实现富领域模型。<br><img src="/2020/02/09/ddd-gai-nian-gai-lan/ddd-summary.png" alt="Domain Drive Design Summary.png"></p><h4 id="3-1-DDD战略模式">3.1. DDD战略模式</h4><p>领域驱动设计的战略模式会提炼问题域并塑造应用程序的架构。</p><ol><li>提炼问题域以揭示重要之处是什么 —— 核心子域。核心域是编写软件的原因，保留最大价值的关键区域，决定软件成功与否的关键。并非一个系统的所有部分都需要被精心设计，团队可以更专注于核心领域。</li><li>在解空间构建一个软件模型，以处理领域问题并让软件与业务保持一致。</li><li>运用统一语言（Ubiquitous Language），开启建模协作。首先，确保的是领域专家和开发团队协作工作，其次，是将分析模型绑定到代码模型，以便开发团队和领域专家能够在模型设计方面进行协作。</li><li>限界上下文（Bounded Context），定义了模型的适用性并确保保留其完整性和独立发展的能力。统一语言和模型的适用边界应该是要在具体的限界上下文内。</li><li>上下文映射（Context Map）。上下文映射提供了整个系统各上下文边界之间的宏观状况，揭示了上下文之间的关系和交互方式，同时表现出各上下文内模型的有多少差异，以及它们的交换哪些数据来实现业务处理过程。</li></ol><p><strong>问题空间 &amp; 解空间</strong><br>战略模式中强调问题空间和解空间的区别。只有明确确定了问题空间，才能分析出对应的解空间，最终才能构建出满足解决业务问题的成功软件。<br>上1，是解决问题空间复杂度的管理模式。问题空间将问题提炼成更多可管理的子域。<br>上2、3、4、5， 是解空间的管理模式。</p><p>战略模式强调了DDD的侧重点是：知识消化、知识提炼、协作沟通、统一语言、上下文、模型持续发展。<br>后面战术模式，其实只是支持其实现而推荐的手段。</p><h4 id="3-2-DDD战术模式">3.2. DDD战术模式</h4><p>DDD的战术模式（也称模型构造块）是一个帮助创建用于复杂有界上下文的有效模型的模式集合。<br>许多模式都早于DDD概念的出现，但依然有一些被推荐为DDD战术的标准模式。<br>在战略模式提供的架构和原则的基础上，共用这些标准模式可以让设计有序进行，也使项目组成员能够更方便地了解彼此的工作内容。</p><ol><li>实体（Entity）</li><li>值对象（Value Object）</li><li>领域服务（Domain Service）</li><li>工厂(Factory)和验证器(Validator)</li><li>聚合(Aggregation)</li><li>资源库(Repository)</li><li>领域事件(Domain Event)</li><li>模块(Module)</li><li>集成限界上下文</li><li>六边形架构</li></ol><h3 id="参考文献">参考文献</h3><ol><li>《领域驱动设计：软件核心复杂性应对之道》，Eric Evans 著</li><li>《实现领域驱动设计》，Vaughn Vemon 著</li><li>《领域驱动设计模式、原理与实践》，Scott Millett / Nick Tune 著</li></ol>]]></content>
      
      
      <categories>
          
          <category> DDD </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DDD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从精益来看价值交付是什么</title>
      <link href="/2020/02/08/cong-jing-yi-lai-kan-jie-zhi-jiao-fu-shi-shi-me/"/>
      <url>/2020/02/08/cong-jing-yi-lai-kan-jie-zhi-jiao-fu-shi-shi-me/</url>
      
        <content type="html"><![CDATA[<p>前一段时间在做U内的价值交付。<br>个人也从最开始的可意会不可言传的状态，到后来可以聊些概念和措施的阶段。</p><p>老实说，曾经在我司经常听到Dev challenge BA：“你这个需求的价值是什么？”现在反而听到越来越少。<br>曾经我们坚持要去做有价值的事情，直到我们现在不得不 highlight 出 <code>价值交付</code> 这个标题。<br>并且常常会被问到 —— 价值交付，它到底指什么？</p><span id="more"></span><h2 id="1-“价值交付是什么？”">1. “价值交付是什么？”</h2><p>首先，我不会尝试直接回答这个问题。<br>作为一个交付型U，我们先从一些耳熟能详的理论和方法实践中，尝试找到“价值”这个词。</p><ol><li>敏捷软件开发宣言</li></ol><blockquote><p>我们一直在实践中探寻更好的软件开发方法，身体力行的同时也帮助他人。<br>由此我们建立了如下价值观：</p><p>个体和互动 高于 流程和工具<br>工作的软件 高于 详尽的文档<br>客户合作 高于 合同谈判<br>响应变化 高于 遵循计划</p><p>也就是说，尽管右项有其价值，<br>我们更重视左项的价值。</p></blockquote><ol start="2"><li>相互依赖声明（敏捷项目管理宣言）</li></ol><blockquote><p>敏捷和自适应的方法把人、项目和价值联系起来<br>我们是一群能够非常成功地交付成果的项目领导者所组成的团体。为了能成功交付：</p><p>我们通过关注持续的价值流，以此来提高投资回报率。<br>我们通过与客户的频繁交互和分享所有权，以此来交付可靠的结果。<br>我们预先考虑不确定性的因素，并通过迭代、预防和适应的方式管理它。<br>我们承认个人是价值的最终源泉，努力建立一个人尽其才的环境，以此释放创造力和创新力。<br>我们通过团队结果问责制以及团队责任分享制，以此来提升绩效。<br>我们按照具体情况制定策略、过程和实践，以此来提高效率和可靠性。</p></blockquote><ol start="3"><li>精益<br>好吧。无论是精益软件开发7原则，还是丰田精益方法的14原则都没有提到“价值”这两个字。<br>但是，在《精益思想》进行了这样的总结 —— 5个原则：</li></ol><blockquote><p>精确地定义特性产品的价值；<br>识别出每种产品的价值流；<br>使价值不间断地流动；<br>让客户从生产者方面拉动价值；<br>永远追求尽善尽美。</p></blockquote><p>从前两组概念 —— 敏捷和敏捷项目管理，来直接追溯价值交付，看起来总是有些刻意。<br>而精益思想的第一原则“精确地定义特性产品的价值”，直接从用户受众的角度入手，就看起来直观的多，因此我这里就直接从精益来看价值交付是什么。</p><h3 id="1-1-价值交付的具象产出部分-——-产品">1.1. 价值交付的具象产出部分 —— 产品</h3><p>说到精益，如果用一句话来描述它是用来干什么的话，那应该是：<code>杜绝浪费，降本增效。</code><br>当然，如果提到它诞生的背景的话，它解决了工业化大生产中的提前批量性生产、生产时间周期过长、生产可预测性不准等问题，但解决问题的终极思路就是：<code>在保证价值的同时，持续不断、稳定地消除浪费，从而降低成本提升效能。</code></p><p>说到“浪费”：丰田模式中，将生产活动中的各环节分为3类步骤：</p><ul><li>明确能创造价值的步骤</li><li>虽然不能创造价值，但是在现有技术和生产条件下不可避免的步骤（<strong>1型浪费</strong>）</li><li>不创造价值，并且可以去掉的步骤（<strong>2型浪费</strong>）<br>针对产品制造的第一要务就是首先定义价值，从而识别整个生产活动中能够创造价值的步骤、1型浪费和2型浪费。然后消除2型浪费，并将1型浪费逐渐转化成2型浪费从来最终消除。</li></ul><h4 id="1-1-1-首先定义价值">1.1.1 首先定义价值</h4><p><img src="/2020/02/08/cong-jing-yi-lai-kan-jie-zhi-jiao-fu-shi-shi-me/value.png" alt="价值"></p><p>同样的道理，在软件交付中，首先的出发点就是价值，并不是一堆一堆的功能集、features 或者 看起来非常 fashion 但不解决自身问题的前沿方案。</p><p>然而无论是制造业还是软件业，价值只能由产品的使用者 —— 最终用户来确定。<br>一般在交付团队中，会有两种情况：</p><ul><li>客户就是用户</li><li>客户只是尝试设计产品，用户是另外的群体。<br>在客户不是用户的情况下，如果客户并没有收集和分析用户的真实需求，整个交付过程就会变成 —— 提前生产、没有以需求来拉动生产，最终价值交付物是否能产生价值只能凭玄学的地步。一旦不能产生价值，就变成了最大的浪费。<br><img src="/2020/02/08/cong-jing-yi-lai-kan-jie-zhi-jiao-fu-shi-shi-me/pull-push.png" alt="用户拉动 vs 提前生产后推动"></li></ul><p>交付价值，只有在用 —— <code>具有特定价格、能在特定时间内满足用户需求的特定产品</code>（无论商品或者服务）来表达时才有意义。<br>所以，在交付之前，先确定产品的价值 —— 开发的人力成本、时间成本、机会成本，和最重要的一点 —— 这是否解决了用户的真实问题吗？以及是否“更好地”解决了用户的真实问题？<br>为什么这里有“更好地”一说？<br>就比如同样是员工打卡系统，在开发各成本投入产出比相似的情况下，上AI人脸识别 —— 自然是比手工签到的价值要大的。</p><p>也许有人会说，“我们使用敏捷，就是因为当下无法定义出明确产生价值的需求，才使用敏捷软件交付 —— 实现增量性发布、快速实验和反馈。”<br>这里要分两种情况来看这个问题：</p><ul><li>第一种情况：只是短视的一种借口。懒于、或者能力不足直接放弃努力，造成无法通过问题收集、需求分析和商业洞见对各种业务方案进行过滤，从源头上就开始产生软件开发的大量浪费。</li><li>第二种情况：已经有了需求收集和分析渠道，但行业方案较新，无法完全避免产品实验开发的浪费。这种，在更下游、更靠近用户的地方，是否建立了有效的用户反馈、价值追踪和核定机制 —— 实验的效果是什么样的，生成了哪些价值，是否帮助我们更好地逐渐形成价值定义？</li></ul><p>实现完价值定义之后，我们针对当前价值定义来看看“交付”这个动作。</p><h4 id="1-1-2-从需求到产品的快速研发能力">1.1.2. 从需求到产品的快速研发能力</h4><h5 id="“识别出每种产品的价值流”">“识别出每种产品的价值流”</h5><p>用过 Scrum 或者 Kanban board 的人应该都理解，一张卡（无论 EPIC 卡还是 story 卡），其承载的就是一个价值点（这里不涉及到估算）。</p><p>而将 board 上的各个 columns 对应的步骤连接起来，其实就组成了完成此类卡的一条粗粒度的“价值流”。其中，有产生价值的In Dev、In QA等，也有1型浪费Dev Done / Ready for QA 等等，当然个别团队可能还存在2型浪费的 columns。<br>价值流的目标就是让团队识别出流程步骤，为之后消除这些浪费做准备，最终降低开发成本、缩短lead time。<br>那从这种粗粒度的”价值流“中如何逐渐暴露浪费和执行改进呢？</p><h5 id="“使价值不间断地流动”">“使价值不间断地流动”</h5><p>也许有人会觉得这句话理解起来很难，其实在部分团队内非常常见。<br>比如：见过一些客户团队，所有 story 的开发只要开发人员开发完毕，就推进Dev Done column 中，等到整体功能开发的差不多了，才引入 QA 来开始测试，在此之前 QA 资源可能在忙于另一个团队的测试工作。一种类似制造业批量化生产的模式，生产步骤之间存在大量库存，批量满额之后，才会推进到下一个生产环节。<br>也有一些敏捷团队，由于 QA 资源不足，出现相同的Dev Done之后在Ready for QA中形成批量等待，始终无人解决，甚至大家对此已经习以为常 —— QA会在下一个sprint整体测试这批卡。<br>“使价值不间断地流动”，其实不仅是行动、更是从思想和意识上认识到 —— 价值要流动起来。就像最后那些敏捷团队的例子，即使使用了敏捷流程和工具，思想和意识不到位，依然用出了批量的样子。</p><p>有人会说：“这种批量有什么不好？团队上所有的人都在工作，并没有空转，人力没有被浪费。“<br>如果一定要从项目人力运营的知识域中来看价值交付，我只想说：是的，大家看起来都忙忙碌碌，行色匆匆，努力“做事”，但是人力花完就代表创造了价值么？<br>另一方面，我也可以从”测试前置“、”一次性把事情做好“、”缺陷越晚修复，修复的成本越高“、”开发周期越长，越容易返工“等等方面来聊一聊不关注价值流会造成的种种人力成本、时间成本、机会成本上的浪费。</p><p>只有让价值尽量不间断地流动起来，从需求到生产，才会暴露问题 —— 让团队观察和思考这种端到端的整条价值生产活动中，哪些是产生价值的，哪些是浪费？持续地逐渐优化和消除浪费后，降低开发成本、提升研发效能。</p><h5 id="“让客户从生产者方面拉动价值”">“让客户从生产者方面拉动价值”</h5><p>当研发效能提升、单个价值点能被快速完成端到端交付时，提前预测性质的功能设计（是否能最终产生价值靠玄学的那种）就可以完全被避免，由最下游的终端用户直接提出需求，从来拉动交付。</p><h4 id="1-1-3-方案、技术先进性的加持">1.1.3 方案、技术先进性的加持</h4><p>在前面我讲board上面的价值流的时候，始终特指其是”粗粒度“的价值流。<br>为何？<br>因为无法从这些columns中看到：用A框架开发会比B节省多少开发成本、使用某个自动化测试方案可以节省多少测试成本，诸如此类的“细粒度”的价值流才会发现的浪费对比。<br>这种时候，各团队面临的问题各不相同，需要团队一线人员自身的方案和技术能力去扩展优势、消除浪费，不再局限于敏捷软件开发流程、scrum / kanban board来宏观指导和描述开发流程。</p><p>这里就涉及到精益思想的最后一个原则：<em>“永远追求尽善尽美”</em>。</p><h3 id="1-2-价值交付的土壤-——-团队能力-学习型组织">1.2. 价值交付的土壤 —— 团队能力 / 学习型组织</h3><p>精益思想前四大原则都只是在讲 —— 如何消除产品生产过程的浪费，最终形成高效有价值的生产流程。一般完成前四原则，基本可以收获 <code>突破性改善</code>（指初次改革，调整生产活动后，一次性获取到的改善效果）。<br>精益思想用最后一个原则<code>“永远追求尽善尽美”</code>，才提到了如何 <code>持续性改善</code> 。</p><p>而《丰田模式》用了一整本书，来讲如何实现“追求尽善尽美”、实现“持续性改善” —— 即使完成了前面四个原则，或用了大量的精益工具和实践，只要没达到一点，就不是精益。精益 —— <code>打造一个真正的学习型组织。</code></p><p>这个“学习型组织”，不是说 —— 只是在组织内培养学习氛围，今天去学几种对价值流毫无帮助的语言或架构，明天去做一些对当前主业务毫无扩展的社区活动。也不是说，当某个团队需要一个大数据工程师时，需要从零开始培养，当第二个团队又需要一个大数据工程师时，再次另外培养。<br>而是说 —— 培养学习氛围、过程中不断创建“标准化”以达到“稳定”，然后让成员发挥创造性思维和创新能力以持续改进价值流的组织。</p><p>为什么说“团队能力/学习型组织”是价值交付的土壤呢？<br>假设某团队前四原则背后的工作并不是团队自发形成完成的，是由一个外部人员引入并督促实践完成，本团队并没有掌握其能力。当用户需求拉动生产越来越快时，必然会暴露进一步需要解决的瓶颈和浪费，这时候团队离开了外部人员根本无力继续持续改进从而稳定交付价值。</p><p>为了真正实现精益的持久性改善和价值交付，这需要一个自下而上的过程。<br>仅靠上级制定几个衡量指标，没有培养团队的学习和自组织能力，你永远也想像不到真正实践时会长成什么样子。<br>将团队的指标呈现想像成地上的树，如下图。<br>上级也许期望是扎根价值交付、持续性改进指标背后的问题。但团队也许只是做了一些流于表面的工作让指标变得好看。<br><img src="/2020/02/08/cong-jing-yi-lai-kan-jie-zhi-jiao-fu-shi-shi-me/how-tree-grow.png" alt="你以为和实际的区别"></p><h2 id="2-最后">2. 最后</h2><p>何为价值交付？<br>以打造学习型组织或团队为基石 —— 精确定义产品用户价值，尽可能以追求价值卓越为目标，从需求提出开始到产品上线被终端使用，持续消除或者减少阻碍产品研发的浪费，最终实现产品价值。</p><p>看起来，精益贯穿始终。<br>再回来看看《敏捷宣言》和《相互依赖声明》，发现和精益很多方面都很相似。只不过在我看来，精益可以更好的端到端描述整个价值流思路。</p>]]></content>
      
      
      <categories>
          
          <category> 敏捷精益软件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 价值交付 </tag>
            
            <tag> 精益 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么越身处团队越难改进</title>
      <link href="/2020/01/16/wei-shi-me-yue-shen-chu-tuan-dui-yue-nan-gai-jin/"/>
      <url>/2020/01/16/wei-shi-me-yue-shen-chu-tuan-dui-yue-nan-gai-jin/</url>
      
        <content type="html"><![CDATA[<p>“为什么越身处团队越难改进？”</p><p>最开始我意识到这个问题的时候，那时候我读了一本叫《咨询的奥秘》的书，里面有一个“普雷斯科特腌黄瓜原则”。<br>好吧，不要较真，不要记住这个别扭的原则名字。名字根本无关紧要，这本书的风格是在讲故事，里面的名词大部分对应的故事叙事主题。<br>这个原则的名字，并没有分享性，更没有Brook’s Law这样带有明确的理论体系。<br>因此，每次我提到它的时候，只说成“腌黄瓜原则”。</p><span id="more"></span><h5 id="腌黄瓜原则">腌黄瓜原则</h5><p><em>故事大体是这样的：</em></p><blockquote><p><em>从前有一根倔强的黄瓜，被普雷斯科特爷爷放在了卤水桶里。它看了看其他的黄瓜，对它们身上发生的事情十分厌恶。</em><br><em>“真是要了命了”，它骂道，“你们这帮黄瓜都怎么啦？一点骨气都没了吗？有自尊的黄瓜不会随随便便不经过抗争就被腌了。”</em><br><em>“那我们能做啥呢？”黄瓜们问到。</em><br><em>“你可以抵抗啊，这就是你能做的。这也是我要做的，我不会让卤水进入我的皮肤的。”</em></p><p><em>而若干时间之后，普雷斯科特爷爷的腌黄瓜就做成了。</em><br><em>“孩子，别傻了。如果你在卤水里呆得够久，就变成腌黄瓜了。”</em></p></blockquote><p><em>这个故事的最后，书中给了一个总结：</em></p><blockquote><p><em>黄瓜被卤水腌的多，卤水被黄瓜染的少。</em><br><em>如果小系统试图通过长期和持续接触来改变大系统，那么最后更可能是自己发生变化。</em></p></blockquote><p><em>所以，作为咨询顾问，要时不时地跳出客户的环境，不要让自己被“腌”。</em></p><p>看到这一段的时候，我本人正身处于绝对的交付一线中，并不能像咨询顾问一样，时不时跳出项目环境。<br>因此，那时候我总是渴望有几个新的“新鲜黄瓜“进来，搅动这桶卤水，我们这些”身残心不残的黄瓜们“也顺势可以做一些项目和团队改进的事情。</p><p>也许有人要问：“为什么不渴望的是一个外部的咨询顾问过来，搅动你们从而完成改进？”<br>作为一个专业服务以及咨询公司中的一员，我深知在所有的改进和持续完善中，真正能依赖、最后落地的 —— 其实是冲在一线的这个团队成员们自身。<br>于是，这个“卤水效应”，仿佛让自我救赎变成了一个不可能完成的事实。</p><p>再后来的一段时间，我真的获取到了跳出“卤水”的机会，接触到了有意思的环境和机会。当再次回头来做改进的事情的时候，我又读到了《丰田模式》。<br>在其“拨云见日”中，提到了人类的适应能力。</p><h5 id="人类的适应能力">人类的适应能力</h5><p><em>书中有这样一段（源自章节“拨云见日”）：</em></p><blockquote><p><em>乍一看到某个作业流程，我们很容易将所看到的景象与有益的或必需（创造价值）的工作混为一谈。人们都在忙碌，他们行色匆匆，他们努力“做事”，因此看清他们的真实状态绝非易事。</em></p><p><em>如果作业流程混乱不堪，我们很容易对真实的状况、什么可以做到及什么不可以做到得出错误的结论。适应周围环境的能力是人类生存必需的特征之一，所幸我们都具备这一能力，然而，正是这种适应能力，使创建精益流程的工作异常艰难。</em></p><p><em>从本质上而言，我们会适应周围的环境，并在很短的时间里接受环境，并视之为“正常”而不再予以考虑。在很多情况下，我们会把这种情况当做我们“应该做的事情”。幸运的是，我们可以摆脱这种模式，当从另外一个角度来看待这种情况时，我们的理解便会更深一步。运用精益理念和工具将迫使我们从不同的视角重新审视环境。如果我们的头脑能够接受新的信息，那么真正的转变就可能发生。</em></p></blockquote><p><em>还有相似的这样一段（源自章节“站在圆圈内的练习”）</em></p><blockquote><p><em>具有讽刺意味的是，如果你对练习中的流程已十分熟悉，那么这项练习的难度就更大。因为，你已了解浪费存在的“原因”，所以你更倾向于使其合理化，并得出无法改进的结论。在练习中，最好的方法是承认存在浪费，而无须对其做出解释或思考解决之法。</em></p></blockquote><p>书中这两处描述的场景，看起来跟前面“腌黄瓜的卤水效应”有异曲同工之处。然而，《丰田模式》这本书讲述的跟《咨询的奥义》不同的正是 —— 不只是自己跳出卤水之外，而是身处环境中如何完成自我救赎的事。</p><p>所以，当深处团队中改进，我们需要的是什么？“不同的视角重新审视环境”，找到正确的理念和工具，当然还有一系列整体优化等后续。虽然我最近的背景主要是在价值交付，这篇文章我就不延伸讲了。稍微大白话来说的话，就是“不仅要低头做事，还要抬头看路”；精益一点，就是“要定义价值，消除浪费”。</p><p>也许，有人说到 —— 这篇文章前面讲到的我都懂，但当冲在一线的时候，往往那巨大的压力就是没办法、也没有时间去做好价值定位、改善的事情，那些总是排不上优先级。<br>好吧，我这里再次借用曾经看过的另一本书中的一个理论：首先支付自己。（由于不是跟软件开发的书籍，这里就不引用了。有兴趣的小伙伴可以使用关键词查询）<br>这里借鉴一下，改为“首先投资自己”。</p><h5 id="首先投资自己">首先投资自己</h5><p><em>原本“首先支付自己”的故事是这样的：（是一条财富的增长思路）</em></p><p><em>每个月的薪资发下来的时候，人们习惯于先还信用卡、缴房租、缴各种费用、支付，最后剩下来的才考虑投资、理财。而往往最后却剩下的可能只是空气，这样月复一月、年复一年，选择这样做的人们仍然是靠着每月薪资度日，永远与资本性盈利增长绝缘，一旦失去工作，基本几个月断粮，或者吃存款的份儿。<br>因此，为了避免人们是为了生存而工作，日复一日别无选择，就提出了“首先支付自己”的思路。<br>也就是，在每个月薪资发下来的时候，先划出优先投资、理财的那部分，剩下的才考虑还款、缴费、支付。不仅可以保障长期的财务投资的同时，在剩下的钱不够用的时候，也可以激励人去创造更多的价值盈利。</em></p><p>这里借鉴一下。<br>在一线的时候，团队总是被盲目地BU、stories、bugs追着跑，耗掉了大部分的时间，总说用剩下的时间来做价值审视和改进。往往最后剩下的时间可能都是负数，引以为傲的敏捷、精益、价值交付都被抛之脑后。团队在养活自己的边缘挣扎，每日忙忙碌碌、行色匆匆、“努力”做事，最后我们把自己从专业服务做成了外包，日复一日别无选择。团队里的客户也把自己从企业数字化方案推动者做成了外包人员manager。<br>所以，当有压力来的时候，请先抗住压力，确保有效的时间来投资团队和价值体系。</p><h4 id="总结">总结</h4><p>克服”腌黄瓜原则“，克服”人类的适应能力“，保证”首先投资自己“。<br>至于怎么做？这不是本篇文章的范围，也许下一篇涉及价值交付的文章中提及。</p><p>最后放一张本人最近画的团队改进图 —— 借鉴自”精益持续改进的螺旋循环图“。<br>随便看看，这里不会有说明。就是为了凑图来的 😁<br><img src="/2020/01/16/wei-shi-me-yue-shen-chu-tuan-dui-yue-nan-gai-jin/continuous_improvement_spiral_graph.png" alt="精益持续改进的螺旋循环图"></p>]]></content>
      
      
      <categories>
          
          <category> 咨询 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 咨询 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>敏捷测试四象限之三四</title>
      <link href="/2019/12/01/min-jie-ce-shi-si-xiang-xian-zhi-san-si/"/>
      <url>/2019/12/01/min-jie-ce-shi-si-xiang-xian-zhi-san-si/</url>
      
        <content type="html"><![CDATA[<p>接着上篇《敏捷测试四象限之一二》，这里主要讲下剩下的三四象限。<br>这篇就没有上篇那些吐槽生活中的小例子了。</p><p><img src="/2019/12/01/min-jie-ce-shi-si-xiang-xian-zhi-san-si/agile_testing_quadrant.png" alt="敏捷测试四象限"></p><p>在四象限图的右边部分，区别于“支持团队”，主要目的是来“评价产品”。<br>所谓评价产品，就是以用户体验的角度去测试系统 —— 在测试中尽量重现最终用户的实际体验，或者如beta测试，直接邀请终端用户参与测试。</p><span id="more"></span><h4 id="1-第三象限，“面向业务”、“评价产品”的测试">1. 第三象限，“面向业务”、“评价产品”的测试</h4><p>面向业务的测试实例帮助团队设计期望的产品，但可能业务某些测试实例本身是错误的 —— 业务专家可能遗漏了某些功能；或者是因为该功能不是他们的实际领域、并没有正确的了解这个功能；团队误解了某些实例；开发编写的代码可以通过之前一二象限的测试，但并没有产生客户想要的东西，等等。<br>这就是使用第三象限测试的地方。</p><p>第三象限中测试的主体，是手动完成。<br>当然，如果没有将象限一和象限二中的测试实现自动化，那么测试人员根本没有时间进行第三象限的测试。<br>而对于第三象限的测试，实现自动化是很困难的，因为这类测试依赖于人们的智力、经验和直觉。</p><p>比如，探索性测试，就是敏捷测试中，对于用户故事测试和自动化回归测试集的重要补充。<br>使用探索性测试时，首先，测试人员对现存系统有整体了解，然后，不按照原有的验收测试项剧本，将“测试设计”、“测试执行”和“学习”同时进行。最终能设计新的测试，并能引出不少对新特性的想法，而这些新特性往往会演变成新的故事。</p><p>可用性测试。注意这里是Usability，不是availability。后端开发人员估计第一反应是后者。<br>这里的第三象限的可用性测试，是指对于用户来说的可用性，包括 —— 是否易于学习、记忆、操作，是否提升用户效率等等。</p><p>UAT、alpha、beta 测试，都算是用户验收测试，基于系统的全量评测，发现并反馈问题，修复或者获取新的用户故事想法来以此改进。<br>由于本人作为一个开发人员，参与的不多，就不仔细描述了。</p><h4 id="2-第四象限，跨功能性需求测试">2. 第四象限，跨功能性需求测试</h4><p>第四象限的目的是评价产品的跨功能性需求，比如性能、安全、可靠性、可扩展性等等。</p><p>这是一个敏捷开发比较容易忽视的测试维度。<br>为什么会忽视呢？<br>其中一部分原因是 —— 敏捷流程中一个很重要的步骤是，让业务（PO）编写用户故事并对其优先级排序。一般非技术的业务团队成员通常会“假定”开发人员会考虑性能、安全等因素，但开发们只是专注于客户给出的优先级高的功能。<br>而有时候跨功能需求可能比实际的功能更重要。比如，如果一个在线商城的响应时间是一分钟，那么客户将不会等待欣赏它的任何功能。<br>因此，应该在开发周期的每一步都要考虑评价产品的面向技术的测试，而不是留到最后。不然，可能会太迟而不能修正这些问题。在很多情况下，这些测试甚至应该在功能测试之前进行，比如性能指标的不同，会驱动出不同的技术解决方案。</p><p>跨功能性需求，最好准备一个核对的表单，让团队对其有所了解，同时也能让 PO 给出每项的重要级别。开发团队有义务解释清楚不重视这些跨功能需求所导致的后果，PO 应该仔细思考所有这些重要质量因素并进行权衡，必要时候，在涉及的功能、用户故事上对其进行特别强调。</p><p>最后，具体第四象限的执行，团队可能需要借助固定专家的帮助，比如DBA、安全小组等，同时也会使用一些开源或者需购买的工具来完成。</p><h4 id="3-最后">3. 最后</h4><p>终于将敏捷测试四个象限写完了。<br>至于作为一个开发人员，为啥会跑去写一篇测试的博文、还跑去把《敏捷软件测试》这本书翻了一遍。<br>其中最主要的一个原因是，想要让开发人员充分了解“质量”的重要性，专注于质量。<br>而“质量”，对于开发团队来说，是用来获取客户信任的一个重要政治资本。<br>另外，敏捷测试每个象限其实承担了保持“技术债”在一个可管理的水品的角色。</p>]]></content>
      
      
      <categories>
          
          <category> 敏捷 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 敏捷测试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>敏捷测试四象限之一二</title>
      <link href="/2019/11/28/min-jie-ce-shi-si-xiang-xian-zhi-yi-er/"/>
      <url>/2019/11/28/min-jie-ce-shi-si-xiang-xian-zhi-yi-er/</url>
      
        <content type="html"><![CDATA[<p>本来这篇博文我是想这样开头的：</p><p>也许有人看见这篇文章的标题会觉得 —— 这跟开发人员无关。<br>不，你错了，这跟开发人员有关，并且有部分工作是需要开发人员去做的。</p><p>但，最近遇到了一些事情，我想换一个开头方式：</p><p>人在工作和生活中，风平浪静时，就像在实现 stories。而那些突如其来的、打断风平浪静的局面的事情，就像一个个 bugs。作为一个 Tech，我已经习惯了去解决这些 ”bugs“，但又不免内心会吐槽，这些突如其来的问题，作为产品和服务提供商，就不能重视一下质量建设？</p><p>说到质量建设，就不得不来看一下敏捷测试四象限。（这个转接是不是还蛮丝滑顺畅的）</p><p><img src="/2019/11/28/min-jie-ce-shi-si-xiang-xian-zhi-yi-er/agile_testing_quadrant.png" alt="敏捷测试四象限"></p><p>四象限左边部分，用以”支持团队“ —— 帮助团队开发产品。<br>与左边相异的右边部分，用以”评价产品“ —— 对交付的产品增量进行评测。</p><p>四象限下边部分，用以”面向技术“ —— 面向技术领域。<br>与下边相异的上边边部分，用以”面向业务“ —— 面向业务领域。</p><p>先声明，敏捷测试四象限可以认为是一个模型，或者工具，大家参照它来划分和搭建项目中的测试“架构”。因此，对于具体的项目而言，并不是每一个部分都必须采用和执行，但至少不要漏掉真正需要的维度和实践。</p><span id="more"></span><h4 id="1-第一象限，开发们最熟悉的部分">1. 第一象限，开发们最熟悉的部分</h4><p>四象限中左下方的象限代表了测试驱动开发。<br>估计有人会说，明明象限图上面写的只是”单元测试“、”组件测试“，怎么扯到测试驱动开发上去了？<br>测试驱动开发，可以分狭义（TDD）和广义，狭义是指开发时小步开发、先写测试、再写实现的开发方式；广义是指，加上业务、测试参与，以终为始，团队明确最终交付验收测试项，使用测试前置策略，以此出发进行功能设计、开发和构建的整个过程。当然，如果认可了狭义和广义两种方式之后，会觉得并无区别，就是”测试驱动开发“。当然较真一点的，会觉得广义中其实还包含了ATDD、BDD等。</p><p>老实说，早期的时候，我也认为先写测试，还是后写测试（我不是指开发完了之后补测试），没有明显的区别。<br>但经历了更多项目之后，深刻地感受到 —— 要使一个团队（对，我说的并不是特指的某个人，我指的是团队），能写出有效、高质量的测试，那还是一起来用TDD吧。<br>首先，以测试先行的方式开发的代码，自然会被要求设计为可测试的。<br>并且，伴随着开发过程中编写的测试，在帮助设计开发、保证质量的同时，在开发完成以后这些测试也承担着频繁回归和重构安全网的作用。<br>最后，当然附加作用就是这些测试是一份产品代码的使用指南。</p><p>至于开发完了之后补测试这种 —— 首先它顶多是只能算是一种回归测试，补上的测试一般会分支覆盖不全；就算最好的情况，分支都覆盖全了，它顶多也只能算另一种白盒测试，对“支持团队进行产品开发”中的设计和开发并无反馈和指导作用。更别说，大部分开发会”产品代码都写完了，赶紧补完测试后，赶去下一个story”的敷衍感。或者，只要没有强制要求，“以后加测试” —— 只是一句自己骗自己的谎言。</p><p>因此种种，敏捷测试第一象限中，测试驱动开发构建出的单元测试、组件测试，用以确保产品代码的内部质量。<br>内部质量，不是通过客户判断的，是由开发们定义的。当内部质量下降时，直观的可见损失比如：开发速率越来越慢，越来越多的bugs需要修复，不断被推迟的紧急重构等等。当然，如果除了第一象限外的其他象限测试也都同时翻车，这些产品质量缺陷将会被用户感知。</p><blockquote><p>举个现实生活中有趣的例子：本人最近使用了支某宝办理ETC，ETC设备被邮寄过来收到之后，需要车主安装、激活。<br>我打开产品说明书，使用支某宝激活引导小程序进行安装和激活。<br>当到达激活这个步骤的时候，提示“OBU设备故障，请联系客服处理”。<br>找到客服，客服直接告知：寄回更换设备。<br>依样寄回，过了两三天后，手机突然收到一条提示 —— ETC已成功激活？这是在做线上debug？<br>联系客服，客服说是技术人员在检修设备。“检修”设备。<br>过了两天，快递收到之前那台设备，已被激活。<br>总结一句：设备出厂有缺陷，新品寄回仅检修，线上debug激活，用户收到设备仍然一脸蒙圈 —— “账号”不仅被线上debug进行了写操作，到底修好没有还需用户自己开去一个ETC入口检验。<br>看，作为一个用户，我虽然看不到内部质量，但同时我也没有看到任何质量构建发挥作用。</p></blockquote><p>支持团队开发过程的面向技术测试，是所有将要进行的测试的重要基础。如果团队没有对这个象限中的测试做足够多的工作，其他类型的测试将会更加困难。因为团队的代码缺少内部质量，每项任务将需要更长的时间。</p><p>ps：第一象限的内容并非只有单元测试、组件测试，只要是“支持团队开发过程的面向技术测试”都可以放在其内，比如：契约测试。<br>第一象限的测试是自动化的，支持快速反馈的。</p><h4 id="2-第二象限，更高层次的支持团队开发">2. 第二象限，更高层次的支持团队开发</h4><p>第二象限也可以叫面向用户的测试，它们确定外部质量和用户需要的功能，包括验证用户故事、功能、界面、交互等等。<br>但既然是敏捷测试，这里强调的就又是 —— 测试驱动开发，只不过是从一个更高的层次上，包含了ATDD、BDD。</p><p>第二象限需要测试人员参与，开发人员提供技术支持，产品人员提供业务和用户故事。<br>测试人员需要对产品系统有全面的了解、关注全局、故事的业务和技术方面，而且始终考虑最终用户体验，以激发和揭示需求中的边界和隐藏假定，最终同业务和开发们明确验收测试项，以此来帮助团队开发正确的需求。<br>在必要情况下，测试人员使用业务领域语言DSL将验收测试转化为能够执行的测试代码，实现BDD，以驱动开发。一些较常见的工具比如cucumber。</p><p>当然，如果有人说，团队测试人员忙的没时间，只能在开发整体完成了之后才能以“测评”、“查bugs”的形式进行用户故事测试、功能测试。<br>那我只能送两老话：<br>“你无法把质量测试进产品中”、“一次性把事情做好，可以杜绝浪费”。<br>简单点说，就是测试人员发现了bugs，还是需要返工给开发人员修复，开发修复后，测试人员再重测，更何况bugs发现的越晚，修复的成本越高。这些种种，其实造成一些时间和效能的浪费，无法实现及时的支持团队开发。</p><blockquote><p>再举一个最近生活中碰到的有趣的例子：本人最近申请了某讯王卡升级5G的业务。<br>10月31日出的某讯王卡5G宣传，本人满足上面所有前置条件，看着广告上11月30日之前办理可以半年月租享受7折的优惠，同时想支持一把5G事业，<br>于是果断买了5G手机，接着点击了王卡助手的申请升级5G。<br>结果，第一次短信反馈，申请失败 —— 因为有一个王卡福利0元1G流量包。<br>手动上联通app注销了该业务，显示流量包将在11月30日失效。<br>再次点击申请升级，第二次短信反馈，申请失败 —— 因为这个流量包失效时间在11月30日，因此只能在12月才能办理。<br>一看，哪有这样的说法，这要是开通不了，不等于广告虚假宣传么，于是马上联系了王卡客服和联通客服。<br>历经3天的沟通和协作，最后王卡客服 + 我 + 联通电话客服，才成功完成这次5G套餐的升级。<br>主要原因 —— 王卡客服的账号权限根本完成不了这些流量包的立即取消失效，也就无法在广告优惠期内完成办理5G套餐。<br>最后是依靠联系联通电话客服这条workaround才完成办理5G套餐。<br>看看，整个功能测都没有测试，就上线了。虽然对于5G刚商用，必然有些手忙脚乱表示理解，但另一角度也说明“面向业务”的测试有多重要。<br>当然能做到测试驱动开发，就更敏捷了。</p></blockquote><p>第二象限的测试一般是自动 + 手动，BDD的测试可以实现自动，另外基于界面的End to End、或者是只基于API的重复性回归测试都尽量自动化，将手动测试放在分析 或者 其他自动测试弥补不了的工作上。并且手动测试时的前置条件、测试数据准备等等，其实也可以借助自动化完成以提高效率。</p><h4 id="3-最后">3. 最后</h4><p>这篇文章里面的两个生活中有趣的例子，放在第一象限、第二象限有人也许会觉得有些硬靠的感觉。<br>我想说 —— 没错🤣。这两个例子硬写进来，就是想吐下槽他们为啥不好好做测试？</p><blockquote><p>我这还有第三个例子：<br>在安和某康做体检预约，小程序填入工号后，接收手机验证码进行登录。<br>第一次登录成功，完成预约，之后几天token失效了。再进行登录，手机就再也接收不到验证码了。<br>反馈给安和某康客服，客服联系了技术部，最后就扔给我一个系统内部日志，告知我已经发送成功。。<br>由于想解决问题，本人愿意协助他们线上debug，并联系联通客服排除了手机和联通设置的一切问题，第二次安和某康技术部还是扔给我一个系统内部日志。。<br>我是一个用户，与其之间隔了电信供应商、短信渠道商、之后可能才到安和后台，给我看后台内部日志。。<br>最后还是客服人员上场，询问我是否完成了预约，没有完成可以人工帮我的哟~ 收不到短信验证码，也可以后台人工查的哟~<br>基于安和某康貌似只是个体检资源协调服务公司，可能科技不是他们的核心领域，直到最后我依然无法再登录，那也只能这样了。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 敏捷 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 敏捷测试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Scrum形外之神</title>
      <link href="/2019/10/23/scrum-xing-wai-zhi-shen/"/>
      <url>/2019/10/23/scrum-xing-wai-zhi-shen/</url>
      
        <content type="html"><![CDATA[<p>什么是Scrum?<br>Scrum是敏捷软件开发过程的一种框架，用以实现迭代式增量开发。<br>好吧，很抽象。</p><p>那是不是 —— 只要有了sprint、IPM、Showcase、Retrospective、可视化卡墙、每日站会，这些流程和工具，就已经实现Scrum了呢？<br>也许有人会说是。这看起来基本就是一个Scrum的MVP(Minimum viable product)。</p><p>好，那假设我们的团队已经实现了Scrum流程的MVP。<br>现在，我们来进行一下每日站会。请每个人依次对三个问题进行描述。<br>三个问题，哪三个问题？</p><ol><li>你昨天做了什么？</li><li>今天计划做什么？</li><li>遇到什么阻碍或问题？<br>一般大家都认为是这三个问题是不是？</li></ol><p>很多人都容易把每日站会视为一个简单的个人报告会。<br>但其实，Scrum的原版三个问题是：</p><ol><li>你昨天做了什么去帮助团队完成冲刺？</li><li>今天你打算做什么来帮助团队完成冲刺？</li><li>什么因素阻碍了团队的前进之路？<br>请注意，有两个字在这三个问题中一再出现 —— “团队/团队/团队”。<br>也许有人会认为区别不大 —— 每个人做好自己的工作，就是在推进团队整体的进度。</li></ol><span id="more"></span><h3 id="1-团队之力">1. 团队之力</h3><p>实行scrum的目标之一，提升团队能效，项目进展速度应该是越来越快的。</p><h4 id="1-1-团队学习和知识共享">1.1. 团队学习和知识共享</h4><p>假设有一堆3个月以上工作量story卡，有两种选择：</p><ol><li>分给5个工程师，他们各自都有充足的业务上下文来开发，但这5个工程师相互之间都不在同一个team，需要每人独立完成工作。</li><li>分给一个有5个工程师的team，团队性完成工作。<br>从做卡速率来考虑，你会倾向于哪一种选择？</li></ol><p>估计在有的PM看来，如果这些工程师的技能Level都相同的话，这两种选择根本没有太大区别。<br>但是其实不然。</p><p>如果可以选择，将这里的工程师都替换成10倍效率工程师，选择一的整体做卡速度会提升10倍；而选择二中即使替换成5倍效率工程师，整个团队整体做卡速度也会远远大于10倍。<br>为什么？</p><p>一个简单的场景：假设story卡中涉及到新的技术知识，选择一，整体花费的从零开始独立的学习时间是5人份；而选择二，只需要团队中一个人从零开始学习，然后通过有效的知识分享和传递，快速的让整个团队所有人掌握此项技术。</p><h4 id="1-2-消除单人进度的瓶颈">1.2. 消除单人进度的瓶颈</h4><p>当然也不只是学习新技术的场景，联想一下平时有没有这样的场景：<br>A工程师在站会上表示当前进度被一个技术性问题困扰，正好B有相关经验，于是B主动表示今天会跟A pair来为其加速和传递相关知识。</p><p>每个个体都有长短板和瓶颈，团队正是相互之间以己之长、补彼之短。<br>即使很不巧，一个团队中长短板都相同，这里可以想象一下鸣人利用影分身学习的场景————多线程不同角度的试错，再通过交流和知识共享，最终还是能让团队快速克服瓶颈、获得更全面的成长。</p><h4 id="1-3-小规模的加持">1.3. 小规模的加持</h4><p>从上面两点可以观察到团队之中相互之间信息透明、沟通交流非常重要。<br>Scrum团队中，每个成员都必须知道其他人在做什么。同时每个人自己正在做什么工作，正面临着哪些挑战，取得了哪些进步等等，都必须透明，让别人知道。<br>这里其实会花费一些沟通成本，如果团队过大，固然是会让沟通成本增加，同时会给每个成员关注的沟通渠道数带来很大的压力。<br>团队成员增加之后，相互之间沟通渠道就会大幅增加。</p><pre class="line-numbers language-none"><code class="language-none">团队总沟通渠道数 = n * (n - 1) / 2# n为成员数量<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果是7人，团队总沟通渠道数是21，9人是36，10人则是45。<br>人类的大脑可能根本无法应付这么多的沟通渠道。<br>相信大家都在站会和code review的时候有这样的感觉，当人数上升之后，越来越不能充足的了解其他成员正在干什么，更别说主动发现并给予帮助了。</p><h3 id="2-快速反馈和改进之力">2. 快速反馈和改进之力</h3><p>Scrum的目标是为了实现迭代增量开发，从而产生反馈，从中学习，之后调整我们正在构建的东西和我们的构建方式。<br>sprint为团队提供了相应的机制。</p><p>我们先过一下sprint整体流程。<br><code>sprint之初 —— IPM</code>：在每次冲刺之初，都会举行一次会议，产品负责人讲解需求，并由开发团队规划冲刺内容，即在未来两周内能完成多少工作，明确sprint结束时可交付的产品增量目标。<br><code>sprint运行中</code>：在sprint中，团队有两项工作：完成在当前sprint计划的工作以及准备下一个sprint。<br><code>sprint结束之前 —— review（showcase）</code>: 不展示成果，就没有效果。每次sprint的交付物应该是潜在可交付的产品增量，在showcase上展示已明确完成的增量成果，与sprint开始之前的完成目标进行对比，接受评审反馈。<br><code>sprint最后 —— team Retrospective</code>: 团队回顾会议，在会议中回顾整个sprint过程，反思过去以改善将来的sprint。</p><h4 id="2-1-快速反馈">2.1. 快速反馈</h4><p>每个sprint可看做是一种实验。<br>通过迭代sprint这种短期的time-box，每一次sprint结束之后，潜在可交付的产品增量可以让客户和团队快速评估该实验，获得反馈。<br>他们可以根据在上一个sprint中的发现来判断自己的前进方向是否正确，以及判断他们下一步打算做的事情是不是恰当的。<br>失败得快，才能迅速改正。</p><h4 id="2-2-检查和调整">2.2. 检查和调整</h4><p>Scrum的一个重要意义就是改变团队对时间的看法。实行sprint和每日站会一段时间之后，团队就不会再把时间看成一支径直飞向未来的箭，而是从周期性的视角去看待时间。</p><p>利用这一个个周期，形成戴明PDCA循环（Plan-Do-Check-Action）。<br>Review和Retrospective，就是scrum中形成检查和调整的一环。<br>不只是”检查和调整“团队构建的东西，还要”检查和调整“团队构建的过程。</p><p>每经过一次sprint，检验一下团队做的事情，看看是否朝着正确的方向前进？结果是不是真正希望看到的？是否有什么办法能改善目前正在做的事情？如何才能做得更快更好？存在哪些潜在的障碍？这一点看似容易，做起来并非易事，需要有思想，善于自省，有实事求是基于事实的数据和依据、自我约束的意识。</p><p>有人曾经发问：如果团队成员都不想开Retrospective，作为PM你打算怎么办？<br>当时的一个答案是：其实敏捷实践施于团队，都是可以根据团队实际情况进行剪裁的。如果团队觉得没有必要开，那就可以不开。<br>但我想说的是，对于Scrum，如果没有其他手段形成周期性最后的”检查和调整“闭环，那Retrospective就一定要开。即使是团队成员对于当前的Sprint状态、速度、步调非常满意，因为 —— 即使是这种情况，在Retrospective meeting上，团队也要回答一个重要问题：”你们如何才能做得更好？“</p><h3 id="3-短期详细计划，消除浪费之力">3. 短期详细计划，消除浪费之力</h3><p>在最早的软件开发方法 —— 瀑布式软件开发中，前期会做大量的分析、设计和计划，编写大量详细的文档文档、绘制大量的甘特图报告企图体现和控制软件的开发进度。而当现实进度与计划报告有矛盾时，认为往往认为问题出在现实上，认为图表是正确的。<br>本身这种长期计划和进度控制办法，建立的这种制度 —— 无异于强迫自己一味地空想。<br>首先，这种付出大量努力去规划细节，限制潜在变化，并预知未知因素的长期计划，最后往往会徒劳无功。每一个项目在开发过程中都需要人们去发现新问题，去激发自己的灵感。<br>其次，企图回避现实的不确定性。<br>另外，无法响应外在环境和商业的不断变化。<br>最后，是非常现实的一个问题 —— 人类其实非常不擅长于预测一件事情需要耗费的时间。</p><p>而在scrum中团队只需要对下一个sprint做详细计划，使用短周期来增加确定性、应对变化、快速反馈。节省长期计划中起不到作用的分析、设计、沟通协调的时间。</p><h3 id="4-专注目标、可持续的步调之力">4. 专注目标、可持续的步调之力</h3><p>sprint之所以叫冲刺，是可以让人产生一种紧张激烈的感觉。<br>但它强调的并不是 —— 长跑马拉松始终以最后200米冲刺的不可持续的节奏进行开发，反而十分强调可持续性开发节奏。</p><p>首先，不要改变当前sprint的目标。<br>一旦一个团队决定要完成某些任务，那么这些任务就锁定了，团队之外的任何人都不能再给他们增加任务，干预和扰乱团队只会大幅放缓团队的工作进度。<br>即使一些人质问敏捷不就是要拥抱变化吗？Scrum的拥抱变化不意味着可以在同一个sprint内进行改变。<br>其实，很少有企业身处“变化迅猛以至于企业不能在2周sprint的开始就设定优先级然后保持这些优先级不变”这样的行业中。许多企业也许认为他们就处于那样的环境，但事实上不然。<br>要达到不要轻易改变当前sprint的目标，这通常要求我们慢慢习惯于“提前思考”，不要“缺乏远见”。</p><p>其次，不要台球短跑。<br>台球短跑指，团队刚完成一个sprint，还没准备开始下一个，下一个sprint又开始启动。第二个sprint经常只是所谓的开始，实际上团队还根本没有准备好做这个sprint的工作，以致于他们不得不花费几天时间学会要干什么。<br>要记住，在当前sprint中，团队有两个目标：完成在当前sprint计划的工作以及准备下一个sprint。<br>特别PO、UED这些团队对其有前置依赖的角色，需要及时提前准备下一个sprint。这样可以让整个团队的交付步伐一直处于顺畅、可持续的状态。</p><h3 id="5-可预测之力">5. 可预测之力</h3><p>团队内，需要知道自己的速度。<br>每个团队都应该准确知道自己在每个sprint阶段中完成了多少工作，并且应该知道如何以更加聪明的方法去消除障碍，加快工作速度。<br>知道自己的工作速度之后，就能计算出交付日期，<code>速度 × sprint次数＝交付工作量</code>。</p><p>团队外，稳定、短期的交付频次，可以带给客户明确的”可预测性“ —— 基本上提出的需求和问题只要等待一个固定周期就可以上线。<br>当然如果客户在明知”可预测性“的基础上，仍然总是要求”快速响应“，没有耐心等待一个固定周期时间过去，那就可以考虑缩短这个固定周期的时间长度。比如，如果是2次sprint才release一次，则可以考虑是否能1次sprint就release。</p><h3 id="6-总结">6. 总结</h3><p>学习Scrum框架，使用其进行软件开发过程管理，往往很容易。<br>但，是不是总有那么一些团队，明明用了Scrum仍然每日疲于奔命？<br>是否是只见Scrum其形，不见其神呢？<br>如果是，可以检查一下是否有 其神中未发挥出来的力量？<br>如果是，可能团队需要考虑有一位专职的Scrum守护者 —— Scrum master。</p><h3 id="7-参考文献">7. 参考文献</h3><ol><li>《敏捷革命》，Jeff Sutherland 著</li><li>《Scrum 敏捷软件开发》，Mike Cohn 著</li><li>《硝烟中的 Scrum和 XP》，Henrik Kniberg 著</li></ol><p><img src="/2019/10/23/scrum-xing-wai-zhi-shen/cover.png" alt="封面"></p>]]></content>
      
      
      <categories>
          
          <category> 敏捷 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 敏捷 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么不鼓励加班</title>
      <link href="/2019/10/15/wei-shi-me-bu-gu-li-jia-ban/"/>
      <url>/2019/10/15/wei-shi-me-bu-gu-li-jia-ban/</url>
      
        <content type="html"><![CDATA[<p>首先，此篇文章有个大前提，主要针对知识性工作。<br>“知识性工作”与“可重复性的生产活动”对立。</p><p>看到这个标题的时候，大概很多人都会想——这是一篇996员工 ICU 的软文：不鼓励加班，是为了让员工过平衡的生活。<br>欧美不少公司不鼓励加班，是因为——他们重视员工的工作和生活。<br>我只想说：图样图森破。当然，也有可能仅仅是公司不想付加班费。</p><p>Scrum 之父杰夫·萨瑟兰 ，直接指出：“<strong>工时越长，效率越低。</strong>”<br>在一些管理者眼中：加班加点地工作不是敬业的标志，而是失败的标志。让员工早点下班，不是想让他们过一种平衡的生活，而是为了他们可以完成更多的工作。</p><span id="more"></span><h3 id="1-工时越长，效率越低">1. 工时越长，效率越低</h3><p>这个观点看起来貌似没有根据，是不是？<br>当然，有人会有预见性地说：完成知识性工作的主体是人，一天中人的集中力是有限的。即使当天工时延长，总的集中力的时长并不会相应延长。<br>说的不错。</p><p>同时，知识性工作中，其实伴随着大量的决策。有令人不安的证据显示，人们做决策的能力很有限，精力消耗得越多，休息时间越短，做出的决策就会越糟糕。<br>在 Scrum 之父的《敏捷革命》中有这样一个有趣的举证：</p><blockquote><p>2011年4月，以色列一组科研人员在《美国科学院院报》上发表了一篇关于决策科学的论文，非常值得关注。他们的论文题目是《司法裁决中的外部因素》。</p><p>这篇论文分析了8名以色列法官做出的1000多项司法判决。这8名法官主持着两个不同的假释裁决委员会。他们裁决的犯人有男性也有女性，有犹太裔以色列人也有阿拉伯裔以色列人。所犯罪行包括贪污公款罪、故意伤害罪、谋杀罪和强奸罪。法官们所审理的绝大多数案子都是假释申请。</p><p>这类工作似乎很简单，对吗？这些受人尊敬的法官运用自己多年来的经验和智慧做出至关重要的决定，不仅影响犯人与受害者的生活，还会影响整个社会的福祉。他们每天都会审理14~35个案件。</p><p>以色列的研究人员分析了法官做出裁决的时间、是否批准假释以及上一次吃点心的时间。如果法官刚吃完点心休息好，或者刚吃完午餐后开始上班，那么，有利于犯人的裁决就会占到60%；但是快到下一轮休息时间时，有利于犯人的裁决比例就会下降到零。</p><p>基本上，在短暂休息后，法官的态度都会比较积极，也比较容易做出宽大的裁决。对于这个世界发生犯罪行为的可能性以及犯人改过自新的可能性，他们会表现出较多想象力与包容心。但随着精力逐渐耗尽，维持现状的裁决便越来越多。</p><p>我敢肯定，如果你问这些法官是否相信自己每次都能做出同样良好的裁决，他们就会觉得受到了侮辱，但数据不会撒谎。当我们精力耗尽的时候，我们很容易做出荒谬的决定。</p><p>这种现象被称为“自我损耗”，意思就是，做出任何选择都需要耗费一定的精力。这是一种奇怪的损耗，因为你感觉不到身体的疲惫，但做出良好决定的能力会下降。你的自我控制能力、自我约束能力、思考能力以及预见能力等都会趋于减弱。</p></blockquote><p>是不是联想一下平时日常生活中的例子，会有一些感同身受？<br>很多时候，延长工时并不能继续增加产出——<code>正常不加班时的效率</code> x <code>延长的工时</code>。</p><p>记得这次在十一之前，与我方项目集成的一个乙方 team，由于进度落后的原因，许诺甲方会十一加班 7 天。<br>老实说，刚听到这个消息的时候我惊呆了——这种伤其团队根本的决策，都有勇气去做。<br>后来十一假期之后，我方项目与其集成联调，得到消息 —— 彼方这 7 天对于进度来说，并没有显著效果改善。</p><h3 id="2-工时越长，自我改进的标准越低">2. 工时越长，自我改进的标准越低</h3><p>这里主要是，想聊一下知识性工作中的软件开发这个行业。<br>持续改进，是软件开发中敏捷项目的一大特色。</p><p>当每日交付工时由于feature延长时，对于陈旧或者不合理地流程设计、架构设计、质量提升、可重构的代码等改进决策、创新决策，项目往往会采取保守的态度、更倾向于先维持现状。<br>直至于——自我改进的标准降低到不见——能完成feature功能交付就不错了。</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 敏捷 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>写业务代码真的有那么无聊吗</title>
      <link href="/2019/07/19/xie-ye-wu-dai-ma-zhen-de-you-na-me-wu-liao-ma/"/>
      <url>/2019/07/19/xie-ye-wu-dai-ma-zhen-de-you-na-me-wu-liao-ma/</url>
      
        <content type="html"><![CDATA[<blockquote><p><em>前面先写一点废话。</em><br><em>由于最近在整理一些DDD、微服务、架构相关的知识总结，一边看一边回忆一些经历，又由于本人看的东西有时候很杂，记忆力又大不如前，本打算仅用私人手账的形式记录一下。</em><br><em>但回看了一下2019年年前立的flag —— 50篇博客（应该是完不成了吧。。），又想到最近一段时间接触到的咨询同事的写作能力，唉。</em><br><em>虽然对自身写作和语言表述能力有些萎靡不振，但，人不能不上进。</em><br><em>因此，准备开始简书。</em></p><p><em>这里有人可能要问了：你不是跑去搞区块链了吗，怎么又跑回来微服务、DDD了？</em><br><em>嗯。。这个问题问的好。这里就不得不提到本人去搞区块链之前的一段近两年的项目经历了。</em><br><em>怎么说呢，这个项目虽然在我的项目经历中已经完结了，但它遗留在我心中的问题还没有完结。</em><br><em>就是这样。</em></p></blockquote><h4 id="1-有时候你不得不去写的业务代码">1. 有时候你不得不去写的业务代码</h4><p>最近出差回来，遇到一些之前项目上的同事聊到自己当前的新项目，无不感叹——不用再像以前一样不停地写业务代码了。<br>嗯，可以多玩一些技术、或者新的技术，总是可以让搞技术的人兴奋很久。<br>但是，比较可惜，所谓技术要盈利，就要交付产品。要交付产品，必然就会有业务。即使是DevOps平台这种纯技术型的产品，技术上的CI/CD就是它的业务。<br>写业务代码，对每个开发来说，基本上都必不可少。<br>这时候，技术需要通过实现业务，来展现价值。</p><h4 id="2-写了这么多业务代码，你是否真的会写业务代码">2. 写了这么多业务代码，你是否真的会写业务代码</h4><p>一定会有人觉得这个问题很奇怪，业务代码不就是一个不断累加的过程么，有什么会与不会？<br>说实话，在没有之前那次两年经验的时候，我也是这样想的。但通过那两年的经历，我意识到 —— <strong>复杂业务系统</strong>，业务绝对不是 1+1=2 这么简单。<br>但即使这样，在我经历最近一个短期项目，跟客户合作开发的时候，又意识到 —— 即使是 <strong>简单业务系统</strong>，如果开发人员没有 建模意识、或者面向对象的经验、甚至说是没有业务的理解消化能力，写出的代码甚至连 1+1=2 都做不到。</p><span id="more"></span><p>这个事情是这样的。<br><strong>背景</strong>：项目是做一款区块链的手机钱包（当然这里要说的与区块链知识无关）。<br>可以简单的理解一下 —— 每一个该APP的<strong>User</strong>可以通过”手机号+验证码“登录该APP，而每个User下可以有一批账户<strong>Account</strong>。<br>可以想象比对为，某银行app的一网通账号 -&gt; User，一网通账号下有多张银行卡、信用卡账户 -&gt; Account。<br><strong>业务需求</strong>：进入APP首页的时候，首页展示的**”当前Account“**默认为最近一次使用的Account。<br><strong>实现背景</strong>：后台保存数据状态，使用的MySQL数据库。（有一些其他背景，我这里就不另描述为何不采用APP前端保存等方式）<br><strong>表结构类似</strong>：<br><img src="/2019/07/19/xie-ye-wu-dai-ma-zhen-de-you-na-me-wu-liao-ma/question.png" alt="现有表结构"></p><p>看到这里，每个人应该内心都有自己的实现方式了。<br>基于这是一个业务简单的系统，可以尝试直接用数据模型的形式表述一下。<br>是不是很简单？</p><p>相信许多人都会觉得很简单，它的确也挺简单。<br>甚至，当时在项目上第一版代码实现出来的时候，即使code review没有通过，我也没有觉得它是个问题，即使实现方是客户方的Dev。直到正式team code review，在与客户方Dev的沟通中，我才发现，对一些Dev来说，它的确是一个问题。</p><p>那，看一下你实现的数据模型是下面哪一种：<br><img src="/2019/07/19/xie-ye-wu-dai-ma-zhen-de-you-na-me-wu-liao-ma/answers.png" alt="现有表结构"></p><p>很不幸，当时的第一版代码实现是 <strong>1</strong>。犯了将 Account 的属性泄露到User中的大原则问题。<br><strong>(排除)</strong></p><p>再看下 <strong>2</strong>，<strong>“默认账户”</strong>，这是个什么鬼？也许有人会说，这只是字段起名的问题。或者也有人会说，就是”默认要显示的账户“啊。相比于<strong>1</strong>，User 和 Account 之间的关联使用了id，比 <strong>1</strong> 要好很多。但是，User 需要关心是哪个 Account 要显示吗？这种双向关联的设计是必要的吗？好，我们先把 <strong>2</strong> 放一下。</p><p>那看下 <strong>3</strong>，每个 account 都有一个 bool 标记，用以标记自己是不是当前 User 下的默认账号。好处是，User 完全不用关心旗下的 Account 被选择的问题。但，先不提 <strong>默认账户</strong> 关键字的问题，可以想象一下，当每次 User 切换了当前的 Account，系统就需要整体检查一遍当前 User 下所有的 Account 的 <code>is_default</code>值，并且进行修改。虽然在并发竞争低的场景下，貌似也勉强勉强接受，再想一下是不是有更好的办法？</p><p>最后看下 <strong>4</strong>，在 <strong>3</strong> 的基础上再想一下，到底是什么决定了当前 User 所属的所有 Account 中那唯一一条true标记？这个时候 —— <strong>请把，需求拿出来再仔细看一遍。</strong><br><strong>这很重要。</strong></p><blockquote><p>”进入APP首页的时候，首页展示的<strong>当前Account</strong>默认为 <strong>最近一次使用</strong> 的 Account。“</p></blockquote><p><strong>如果觉得不确定，甚至可以拉上 team 上的 BA 再认真聊一下</strong>。<br>DEV：最近一次使用，意思是账号的最近一次使用的时间点很重要？<br>BA：我不确认”最近一次使用的时间点“是不是很重要。首页这个场景下，我只关心显示的是最后一次使用的账号。但对于首页上手动点击切换 Account 的弹出层上，Account List 我觉得倒是可以采用根据各自的 <strong>最近一次使用的时间点</strong> 来排序展示。</p><p>到这里，可以再拿出之前还没完全排除掉的<strong>2、3、4</strong>，事情就很好解决了。<br><strong>2</strong> 和 <strong>3</strong> 莫名其妙地突出了一个<strong>默认账号</strong>的问题，并且让事情变得复杂 —— <strong>2</strong> 多了双向关联，<strong>3</strong> 多了批量更新，同时都遗漏对了每个“<strong>最近一次使用的时间点</strong>”的记录。<br>而 <strong>4</strong> 在抓到“<strong>最近一次使用的时间点</strong>”这个关键信息，并且得到业务认可的同时，解决了首页展示的业务case，并且能很好的支持扩展。</p><h4 id="3-知识消化、理解业务意图、分析建模、或者是whatever">3. 知识消化、理解业务意图、分析建模、或者是whatever</h4><p>上面的例子有点长，本人也比较担心自己的表述不太好，让举证方向发展到比较奇怪的地方。或者，有时候不同的人的经历总是可以看出不一样的味道。</p><p>当然，这篇博客的目的也并不是为了直奔DDD主题。<br>只是想要强调一点：写业务代码其实也没那么简单和单调。Dev在开发之前，或者是开发的过程中，都要确保自己对业务知识进行了消化，掌握了业务意图，然后进行建模、实现开发。<br>即便是在不需要运用DDD的简单业务系统中。</p><p>最后引用《领域驱动设计与模式、原理与实践》中的一句话：</p><blockquote><p>代码输入并非交付产品的瓶颈；编码是开发过程中最简单的一部分。在非功能性需求之外创建并维持一个能够满足业务用例的领域的有用软件模型才是难点所在。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> DDD </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DDD </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
